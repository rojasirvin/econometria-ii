---
title: "Respuestas a la tarea 4"
lang: es
---

# Respuestas

```{r setup}
#| echo: false
#| warning: false 
#| message: false
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE,
                      indent = "   ")
library(tidyverse)
library(janitor)
library(sandwich)
library(clubSandwich)
library(plm)
library(stargazer)
library(lmtest)
library(AER)
library(quantreg)
library(np)
library(bacondecomp)
library(did)
library(lfe)
library(modelsummary)
```


## Pregunta 1

Considere los datos en el archivo *capital_trabajo.csv*. Con una función de producción Cobb-Douglas las participaciones del capital y el trabajo en el valor de la producción se pueden estimar usando una regresión lineal. En algunas aplicaciones es de interés conocer el cociente de las participaciones estimadas.

a. [10 puntos] Usando 500 repeticiones bootstrap estime el error estándar del cociente capital-trabajo. Para ello realice el siguiente procedimiento:
    i. Genere una matriz vacía de 500 filas para coleccionar sus relaciones estimadas.
    i. En cada una de las repeticiones obtenga una muestra con remplazo a partir de la muestra original.
    i. Estime por MCO los coeficientes sobre el log del capital y el log del trabajo. La variable dependiente es el log del valor de la producción. Calcule el cociente de los coeficientes estimados. Guarde el cociente en la matriz.
    i. Repita ii. y iii. 500 veces.
    i. Calcule la desviación estándar de los cocientes estimados.

   *En cada repetición bootstrap debemos estimar el siguiente modelo y obtener el ratio de los coeficientes:*
    
```{r}
data.kl <- read_csv("../files/capital_trabajo.csv") 

summary(m1 <- lm(lvalor ~ lcapital + ltrabajo, data=data.kl))

``` 
   *Fijamos una semilla y los parámetros de la rutina:*
   
```{r}
set.seed(120)
B=500
obs <- nrow(data.kl)
beta <- data.frame(beta=matrix(ncol = 1, nrow = B))
```

   *Realizamos la regresión y el cálculo del cociente en cada una de las $b$ repeticiones:*
   
```{r}
for (i in 1:B)
{
  data.b <-data.kl[sample(nrow(data.kl),obs, replace = TRUE),]
  
  #Corremos regresión
  
  m<-lm(lvalor ~ lcapital + ltrabajo,
        data=data.b)
  
  #Guardamos en cada entrada el ratio estimado
  beta[i,1] <- as.numeric(m$coefficients[2] / m$coefficients[3])
}
```

   *El error estimado es simplemente la desviación estándar de los B estadísticos estimados:*

```{r}
sd(beta$beta)
``` 

   *El error estándar estimado es de 0.0509.*
    
a. [10 puntos] Calcule ahora el error estándar jackknife, para lo que realizará $N$ estimaciones de la ecuación del valor de la producción y en cada una de ellas calculará el cociente de interés. En cada una de las $i=1,\ldots,N$ repeticiones, eliminará de la muestra la observación $i$, por lo que cada regresión será estimada con $N-1$ observaciones. Obtenga la desviación estándar de los $N$ cocientes estimados.

   *Fijamo utina:*
   
```{r}
beta.jackknife <- data.frame(beta.jackknife=matrix(ncol = 1, nrow = nrow(data.kl)))
```

   *En cada repetición eliminamos la $i$-ésima observación, estimamos la regresión y calculamos el cociente de interés:*
   
```{r}
for (i in 1:nrow(data.kl))
{
  data.j <- data.kl %>%
    filter(!row_number() == i )
  
  #Corremos regresión
  
  m <-lm(lvalor ~ lcapital + ltrabajo,
         data=data.j)
  
  #Guardamos en cada entrada el ratio estimado
  beta.jackknife[i,1] <- as.numeric(m$coefficients[2] / m$coefficients[3])
}

```

   *Obtenemos el error estándar. En clase quizás nos faltó ver la fórmula del error estándar, pero es la siguiente:*
   
   $$ee(\hat{\theta}_{jackknife})=\sqrt{\frac{N-1}{N}\sum_{i=1}^{N}(\hat\theta_{-i}-\bar{\hat\theta})^2}$$
   
   *donde $\hat\theta_{-i}$ es el estadístico estimado usando la muestra que omite la $i$-ésima observación y $\bar{\hat\theta}$ es la media de los $N$ estadísticos estimados.*
   
```{r}
beta.jackknife <- beta.jackknife %>% 
  mutate(mean.beta = mean(beta.jackknife),
         sq.desv = (beta.jackknife - mean.beta)^2)

sqrt(((nrow(data.kl)-1) / nrow(data.kl))*sum(beta.jackknife$sq.desv))
``` 
   *El error jackknife resulta ser 0.048.*

a. [10 puntos] Compruebe que sus cálculos aproximan el error estándar obtenido con el Método Delta. Para ello, después de estimar la ecuación del valor de la producción con la muestra original, use la función *deltaMethod* del paquete *car*.

   *Si usamos el método Delta para calcular el error estándar de la combinación no lineal, obtenemos algo muy parecido, 0.052*

```{r}
deltaMethod(m1, "lcapital/ltrabajo")
``` 

## Pregunta 2

Considere los datos en *MunichRent.rda*. Estos archivos contienen información sobre rentas en la ciudad de Munich, **rent**. Se desea explicar la renta en función de la antiguedad de los edificios en renta, controlando por el área, **area**. La variable **yearc** indica cuándo fue construido el edificio. Construya la antiguedad como *antiguedad=2023-yearc*. Para leer los datos basta con ejecutar *load("MunichRent.rda")*.

a. [10 puntos] Estime por MCO la relación entre la renta, **rent** y la antiguedad del edificio, controlando por **area** y efectos fijos de **bath** y **kitchen**. Interprete el coeficiente sobre la antiguedad.

   *Primero por MCO obtenemos una relación positiva entre la renta y el área y una relación negativa entre la renta y la antiguedad, como era de esperarse. Ambos coeficientes estimados son estadísticamente significativos.*

```{r}
load("../files/MunichRent.rda")

MunichRent <- MunichRent %>% 
  mutate(antiguedad=2023-yearc)

#Por MCO
summary(r.mco <- lm(rent  ~ area + antiguedad,
                    data=MunichRent))
```

a. [10 puntos] Estime la misma relación que en la parte a., pero con una regresión mediana. Interprete el coeficiente sobre la antiguedad.

   *Ahora realizamos un modelo LAD*:

```{r}
summary(r.q50 <- rq(rent  ~ area + antiguedad,
                    data=MunichRent,
                    tau=0.5))
```
    
   *Los coeficientes estimados son de una magnitud similar a los de MCO.*

a. [10 puntos] Estime ahora una regresión cuantil para cada uno de los deciles de la distribución condicional de la renta y represente en una gráfica los coeficientes por regresión cuantil junto con el coeficiente de MCO para las variables del área y la antiguedad. ¿Concluye que vale la pena modelar la relación de las rentas en función del área y la antiguedad usando regresión cuantil?

   *Regresión cuantil para cada decil:*

```{r}
r.q1_9 <- rq(rent  ~ area + antiguedad,
                    data=MunichRent,
                    tau= 1:9/10)

plot(summary(r.q1_9), parm=c("area","antiguedad"))

```

   *Los efectos de la antiguedad en la distribución de precios son no lineales. Los efectos en los cuantiles superiores crecen más rápido con la antiguedad. Quizás esto sugiera una preferencia por edificios viejos. La regresión cuantil sí fue útil para revelar esta característica.*
   
a. [10 puntos] Suponga que no está dispuesto a imponer una relación lineal entre la antiguedad y la renta. Considere entonces el siguiente modelo:

   $$rent_i=\beta_0+\beta_1 area + \lambda(antiguedad_i)+\varepsilon_i$$
   
   Use el estimador de Robinson (1988) para estimar este modelo parcialmente lineal. Grafique sus resultados e interprételos.
   
   *Seleccionamos el ancho de banda:*

```{r}
#| echo: false
#| warning: false
#| message: false
#| include: false
bw <- npplregbw(formula=rent ~ area | antiguedad,
                data=MunichRent,
                regtype="ll")
```

```{r}
#| echo: true
#| warning: false
#| message: false
#| eval: false
bw <- npplregbw(formula=rent ~ area | antiguedad,
                data=MunichRent,
                regtype="ll")
```

   *Implementamos el estimador de Robinson:*

```{r}
model.pl <- npplreg(bw)
summary(model.pl)
```

   *Para obtener el gráfico usamos npplot:*

```{r}
#| cache: true
g.robinson <- npplot(bw,
       perspective=F,
       plot.errors.method="bootstrap",
       plot.errors.boot.num=5,
       plot.behavior="plot-data")

g <- fitted(g.robinson$plr2)
se <- g.robinson[["plr2"]][["merr"]]
lci <- g - se[,1]
uci <- g + se[,2]

#Este objeto nos dicen dónde fueron evaluados
antiguedad.eval <- g.robinson[["plr2"]][["evalz"]][["V1"]]

fitted <- data.frame(antiguedad.eval, g,lci,uci)

ggplot() + 
  geom_point(data=MunichRent, aes(antiguedad,rent), color='black', alpha=0.5) + 
  geom_line(data=fitted, aes(antiguedad.eval, g), linetype='solid')+
  geom_line(data=fitted, aes(antiguedad.eval, uci), linetype='dashed')+
  geom_line(data=fitted, aes(antiguedad.eval, lci), linetype='dashed')
```


## Pregunta 3

[Stevenson & Wolfers (2006)](https://academic.oup.com/qje/article-abstract/121/1/267/1849020) estudian los efectos de la introducción de leyes que permiten el divorcio unilateral. La librería *bacondecomp* incluye los datos usados en dicho artículo. Usaremos los datos de 1964 a 1996 para mostrar cómo impactan las leyes de divorcio express (unilateral) a la tasa de suicidios en mujeres. Comience llamando los datos:

```{r}
wd <- divorce %>% 
  filter(year>1964 & year<1996 & sex==2) %>% 
  mutate(suicide_rate=suicide*1000000/(stpop*fshare),
         year=as.numeric(year))
```

a. [5 puntos] Estime el efecto de diferencia en diferencias asumiendo tendencias paralelas y el estimador de *two-way fixed effects*. Obtenga los errores estándar primero asumiendo errores clásicos y luego usando una matriz agrupada a nivel estado.

```{r}
m.twfe <- felm(suicide_rate ~ unilateral | factor(st) + factor(year),
                data = wd)

m.twfe.cl <- felm(suicide_rate ~ unilateral | factor(st) + factor(year) | 0 | st,
                data = wd)

modelsummary(models = list("TWFE"=m.twfe,
                           "TWFE, agrupada"=m.twfe.cl),
             coef_map = c('unilateral'),
          output = 'gt',
          stars = c('***' = .01, '**' = .05, '*' = 0.1),
          gof_map = "nobs")
```
a. [5 puntos] Realice la descomposición de Goodman-Bacon (2021). Construya un gráfico donde muestre en el eje el peso otorgado a cada comparación 2x2 que el estimador de TWFE realiza mecánicamente y en el eje el efecto estimado correspondiente a cada comparación. Interprete el gráfico obtenido.

   *Implementamos la descomposición:*

```{r}
df_bacon <- bacon(suicide_rate ~ unilateral,
                  data = wd,
                  id_var = "st",
                  time_var = "year")
```

   *La tabla anterior nos da los valores de los estimadores $2\times 2$ con sus correspondientes pesos. El promedio ponderado es exactamente el estimador de efectos fijos:*

```{r}
coef_bacon <- sum(df_bacon$estimate * df_bacon$weight)

print(paste("Suma ponderada de la descomposición =",
            round(coef_bacon, 4)))
```

   *Construimos el gráfico:*

```{r}
df_bacon %>% 
  ggplot(aes(x=weight,
             y=estimate,
             shape=type,
             color=type)) +
  geom_point() +
  geom_hline(yintercept = round(m.twfe$coefficients, 4))

```

   *Las comparaciones que más pesan en el estimador de efectos fijos son las de estados tratados con los que siempre estuvieron tratados en el panel, recibiendo dos de esas comparaciones alrededor de 12.5 y el 6% del peso (los dos triángulos verdes más hacia la derecha). otra comparación que recibe alrededor de 6.5% del peso es la de los tratados con los nunca tratados (cruz morada más hacia la derecha). En total, las comparaciones con estados que iniciaron siendo tratados se llevan el 40% del peso. Las comparaciones entre los tratados tarde y los tratados temprano también reciben un peso alto de 27%.*

a. [10 puntos] Implemente el estimador de Callaway & Sant’Anna (2021) para estimar los efectos del tratamiento específicos para cada cohorte, usando el paquete *did*. Utilice como grupo de comparación los estados *que nunca son tratados*. La columna **stid** es un identificador numérico de los estados (lo requerirá cuando use *att_gt* del paquete *did*).


```{r}
atts_nt <- att_gt(yname = "suicide_rate",
                      tname = "year",
                      idname = "stid",
                      gname = "divyear",
                      data = wd,
                      control_group = "nevertreated",
                      est_method = 'reg',
                      bstrap = TRUE,
                      biters = 1000,
                      print_details = FALSE,
                      panel = TRUE)


summary(atts_nt)

ggdid(atts_nt)
```
a. [10 puntos] Reporte los resultados agregados obtenidos a partir del estimador Callaway & Sant’Anna (2021), usando una agregación dinámica que muestre los efectos promedio para cada periodo antes y después del tratamiento. Grafique e interprete los resultados.

```{r}
agg.es <- aggte(atts_nt,
                type = "dynamic")

summary(agg.es)

ggdid(agg.es)

```

   *Se obtiene una reducción en la tasa de suicidios que es estadísticamente significativa a partir de 5 años después de la introducción de la legislación.*

