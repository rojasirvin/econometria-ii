[
  {
    "objectID": "tareas/tarea-4.html",
    "href": "tareas/tarea-4.html",
    "title": "Tarea 4",
    "section": "",
    "text": "Fecha de entrega: 6 de diciembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los lenguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-4.html#pregunta-1",
    "href": "tareas/tarea-4.html#pregunta-1",
    "title": "Tarea 4",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nConsidere los datos en el archivo capital_trabajo.csv. Con una función de producción Cobb-Douglas las participaciones del capital y el trabajo en el valor de la producción se pueden estimar usando una regresión lineal. En algunas aplicaciones es de interés conocer el cociente de las participaciones estimadas.\n\n[20 puntos] Usando 500 repeticiones bootstrap estime el error estándar del cociente capital-trabajo. Para ello realice el siguiente procedimiento:\n\nGenere una matriz vacía de 500 filas para coleccionar sus relaciones estimadas.\nEn cada una de las repeticiones obtenga una muestra con remplazo a partir de la muestra original.\nEstime por MCO los coeficientes sobre el log del capital y el log del trabajo. La variable dependiente es el log del valor de la producción. Calcule el cociente de los coeficientes estimados. Guarde el cociente en la matriz.\nRepita ii. y iii. 500 veces.\nCalcule la desviación estándar de los cocientes estimados.\n\n[20 puntos] Calcule ahora el error estándar jacknife, para lo que realizará \\(N\\) estimaciones de la ecuación del valor de la producción y en cada una de ellas calculará el cociente de interés. En cada una de las \\(i=1,\\ldots,N\\) repeticiones, eliminará de la muestra la observación \\(i\\), por lo que cada regresión será estimada con \\(N-1\\) observaciones. Obtenga la desviación estándar de los \\(N\\) cocientes estimados.\n[10 puntos] Compruebe que sus cálculos aproximan el error estándar obtenido con el Método Delta. Para ello, después de estimar la ecuación del valor de la producción con la muestra original, use la función deltaMethod del paquete car."
  },
  {
    "objectID": "tareas/tarea-4.html#pregunta-2",
    "href": "tareas/tarea-4.html#pregunta-2",
    "title": "Tarea 4",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nConsidere los datos en MunichRent.rda. Estos archivos contienen información sobre rentas en la ciudad de Munich, rent. Se desea explicar la renta en función de la antiguedad de los edificios en renta, controlando por el área, area. La variable yearc indica cuándo fue construido el edificio. Construya la antiguedad como antiguedad=2023-yearc. Para leer los datos basta con ejecutar load(“MunichRent.rda”).\n\n[10 puntos] Estime por MCO la relación entre la renta, rent y la antiguedad del edificio, controlando por area. Interprete el coeficiente sobre la antiguedad.\n[10 puntos] Estime la misma relación que en la parte a., pero con una regresión mediana. Interprete el coeficiente sobre la antiguedad.\n[10 puntos] Estime ahora una regresión cuantil para cada uno de los deciles de la distribución condicional de la renta y represente en una gráfica los coeficientes por regresión cuantil junto con el coeficiente de MCO para las variables del área y la antiguedad. ¿Concluye que vale la pena modelar la relación de las rentas en función del área y la antiguedad usando regresión cuantil?\n[20 puntos] Suponga que no está dispuesto a imponer una relación lineal entre la antiguedad y la renta. Considere entonces el siguiente modelo:\n\\[rent_i=\\beta_0+\\beta_1 area + \\lambda(antiguedad_i)\\]\nUse el estimador de Robinson (1988) para estimar este modelo parcialmente lineal. Grafique sus resultados e interprételos."
  },
  {
    "objectID": "tareas/tarea-3.html",
    "href": "tareas/tarea-3.html",
    "title": "Tarea 3",
    "section": "",
    "text": "Fecha de entrega: 16 de noviembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los lenguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-3.html#pregunta-1",
    "href": "tareas/tarea-3.html#pregunta-1",
    "title": "Tarea 3",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nEn este ejercicio continuaremos usando los datos del estudio de Card (1993) para estudiar los rendimientos a la educación. Los datos ingresos_iv.dta contiene una muestra de hombres de entre 24 y 36 años de edad. lwage es el logaritmo del ingreso y educ es la educación acumulada.\n\n[3 puntos] Estime una regresión por MCO para explicar el logaritmo del salario (lwage) en función de la educación educ y los siguientes controles: exper, expersq, black, south, smsa, reg661, reg662, reg663, reg664, reg665, reg666, reg667, reg668 y smsa66. Reporte errores clásicos y errores robustos. ¿Qué problema encuentra en la estimación de esta relación? ¿El coeficiente sobre educ tiene una interpretación causal del efecto de la educación en el salario?\n[3 puntos] Se propone usar una variable dicotómica que indica si el individuo vivía cerca de una universidad cuando era niño, como instrumento de los años de educación. ¿Qué condiciones debe cumplir la variable propuesta para funcionar como instrumento válido?\n[4 puntos] ¿Cómo juzga la propuesta de usar la variable antes descrita como instrumento?\n[3 puntos] Estime la relación entre el logaritmo del salario y la educación usando la variable dicotómica de acceso a una universidad, nearc4, como instrumento. Emplee las mismas variables de control que en el modelo de MCO. Reporte errores clásicos y errores robustos.\n[4 puntos] Interprete la primera etapa en términos del coeficiente sobre el instrumento. Obtenga el estadístico \\(F\\) del instrumento excluido e interprete su magnitud.\n[3 puntos] Interprete el coeficiente sobre la variable de educación en el modelo estructural. Compare la magnitud del efecto estimado con el resultado de MCO.\n[3 puntos] Realice ahora el siguiente procedimiento. Primero, estime la primera etapa usando una regresión por MCO. Obtenga los valores ajustados de educación y llámelos educ_hat. Luego, estime la segunda etapa empleando educ_hat como variable independiente, además del resto de variables de control. ¿Cómo cambian sus resultados en comparación con la parte d.?\n[3 puntos] ¿A qué se deben las discrepancias que encuentra? ¿Cuál de las dos estrategias prefiere para estimar el modelo de variables instrumentales?\n[3 puntos] Reestime el modelo de variables instrumentales añadiendo un segundo instrumento, nearc2, y reporte errores robustos (no es necesario usar gmm, puede seguir con ivreg, por lo que no estaría obteniendo el estimador de MGM óptimo). ¿Cómo cambian sus resultados para la ecuación estructural con respecto al caso exactamente identificado?\n[3 puntos] Con el objeto que resulta de la estimación del modelo sobreidentificado, realice summary(OBJETO, vcov = sandwich, diagnostics = TRUE) para obtener las tres pruebas diagnóstico más usadas en variables instrumentales: prueba de instrumentos débiles, prueba de Hausman y prueba de Sargan. Interprete cada una de las pruebas.\n[4 puntos] Considere la primera etapa del modelo sobreidentificado. Compruebe que si realiza una prueba de significancia conjunta para los instrumentos obtiene la prueba de instrumentos débiles que se reporta en el resumen que obtuvo con summary.\n[4 puntos] Compruebe que si realiza el procedimiento de regresión auxiliar para la prueba de Hausman obtiene el mismo valor \\(p\\) que se reporta en el resumen que obtuvo con summary."
  },
  {
    "objectID": "tareas/tarea-3.html#pregunta-2",
    "href": "tareas/tarea-3.html#pregunta-2",
    "title": "Tarea 3",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nConsidere los datos comportamiento_wide.csv, que contienen información individual de niñas y niños, incluyendo su género, edad, raza e información de sus madres. Además, se incluye una medida auto reportada de autoestima (self) y una evaluación de comportamiento antisocial (anti). Se quiere conocer cómo influye la autoestima en el comportamiento antisocial. Para cada niño o niña hay tres observaciones en el tiempo. Se busca explicar el comportamiento antisocial en función de la autoestima y la condición de pobreza (pov):\n\\[anti_{it}=\\alpha_i+\\beta_1 self_{it}+\\beta_2 pov_{it}+\\varepsilon_{it}\\]\n\n[2 puntos] La base se encuentra en formato wide. Ponga la base en formato long, donde haya una columna para cada variable y donde las filas representen a un individuo en un periodo.\n[2 puntos] Estime la ecuación de comportamiento antisocial empleando MCO pooled. ¿Cuáles son los supuestos que se deben cumplir para que \\(\\hat{\\beta}_1^{MCO}\\) sea consistente?\n[3 puntos] Estime la ecuación de comportamiento antisocial empleando el estimador within. ¿Cuáles son los supuestos que se deben cumplir para que \\(\\hat{\\beta}_1^{FE}\\) sea consistente?\n[3 puntos] Estime la ecuación de comportamiento antisocial empleando efectos aleatorios. ¿Cuáles son los supuestos que se deben cumplir para que \\(\\hat{\\beta}_1^{RE}\\) sea consistente?\n[3 puntos] Se desea incorporar en el análisis el género (gender) y una variable dicotómica para los hispanos (hispanic). Indique qué modelo usaría y estime dicho modelo.\n[2 puntos] Regrese al modelo que incluye solo la autoestima y el estado de pobreza como covariables. Realice una prueba de Hausman para determinar si se prefiere un modelo de efectos fijos o uno de efectos aleatorios."
  },
  {
    "objectID": "tareas/tarea-3.html#pregunta-3",
    "href": "tareas/tarea-3.html#pregunta-3",
    "title": "Tarea 3",
    "section": "Pregunta 3",
    "text": "Pregunta 3\nRetome los datos de la pregunta 2 y el modelo del comportamiento antisocial en función de la autoestima y la pobreza. En esta pregunta mostraremos la equivalencia del estimador within con otros estimadores.\n\n[3 puntos] Compruebe que el estimador de efectos fijos es equivalente a MCO con dummies de individuos.\n[2 puntos] Compruebe que en un modelo de efectos fijos las características que no varían en el tiempo no pueden ser identificadas. Añada la variable black para comprobarlo.\n[5 puntos] Compruebe que el estimador de efectos fijos es equivalente a MCO sobre el modelo en diferencias con respecto a la media. Para esto, conserve dos periodos consecutivos de datos y solo observaciones que tengan datos para las variables dependientes e independientes en los dos años que elija. Luego estime por MCO el modelo con variables transformadas.\n[5 puntos] Compruebe que el estimador de efectos fijos es equivalente a MCO sobre el modelo en primeras diferencias. Parta de la muestra con dos años de la parte d. para estimar por MCO el modelo con variables transformadas."
  },
  {
    "objectID": "tareas/tarea-3.html#pregunta-4",
    "href": "tareas/tarea-3.html#pregunta-4",
    "title": "Tarea 3",
    "section": "Pregunta 4",
    "text": "Pregunta 4\nConsidere los datos mlbook1.csv con información sobre 2287 estudiantes en 131 escuelas. Nos interesa la relación entre una medida de aptitud verbal, (iq_vert) y el resultado de un examen de inglés (langpost). Las variables schoolnr y pupilnr identifican a las escuelas y los estudiantes, respectivamente. El modelo a estimar es el siguiente:\n\\[langpost_{i}=\\alpha+\\beta iqvert_{i}+BX_{i}+\\varepsilon_{i}\\] donde \\(i\\) indexa y \\(X_i\\) son tres características usadas como control: el sexo, sex, si el estudiante es de una población minoritaria, minority y el número de años repetidos, repeatgr.\n\n[3 puntos] ¿Por qué es posible que estemos frente a una situación de errores agrupados?\n[2 puntos] Estime la ecuación de calificación usando MCO ignorando la agrupación de datos. ¿Qué concluye respecto a la relación entre la aptitud verbal y la prueba de inglés?\n[3 puntos] Estime ahora los errores robustos a heteroscedasticidad del tipo HC1. ¿Qué cambia y por qué en la interpretación de la relación entre la prueba de aptitud y el examen?\n[2 puntos] Estime la ecuación de calificación usando MCO y efectos fijos de escuela. ¿Qué resuelve este procedimiento?\n[5 puntos] Estime la ecuación de calificación usando MCO y con errores agrupados a nivel escuela (sin efectos fijos de escuela). ¿Qué resuelve este procedimiento?\n[5 puntos] Estime la ecuación de calificación usando MCO, variables indicadoras de escuela y con errores agrupados a nivel escuela. ¿Qué resuelve este procedimiento?"
  },
  {
    "objectID": "tareas/tarea-2.html",
    "href": "tareas/tarea-2.html",
    "title": "Tarea 2",
    "section": "",
    "text": "Fecha de entrega: 2 de octubre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los lenguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-2.html#instrucciones",
    "href": "tareas/tarea-2.html#instrucciones",
    "title": "Tarea 2",
    "section": "",
    "text": "Fecha de entrega: 2 de octubre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los lenguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-2.html#datos",
    "href": "tareas/tarea-2.html#datos",
    "title": "Tarea 2",
    "section": "Datos",
    "text": "Datos\nphd_articulos.csv\nmotral2012.csv"
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-1",
    "href": "tareas/tarea-2.html#pregunta-1",
    "title": "Tarea 2",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nConsidere el modelo Poisson visto en clase y un vector de variables explicativas \\(x\\), todas continuas, usadas para parametrizar la media.\n\n[3 puntos] ¿Cuál es el efecto de un cambio en el \\(j\\)ésimo regresor sobre \\(E(y│x)\\)?\n[8 puntos] Usando esta expresión, muestre que si el \\(j\\)ésimo regresor es \\(x_j\\), entonces \\(100 \\beta_j\\) es la semielasticidad de \\(E(y│x)\\) con respecto a \\(x_j\\). Nota: Este punto es muy útil para la interpretación de los coeficientes de un modelo Poisson.\n[4 puntos] ¿Cómo se interpreta \\(\\beta_j\\) si reemplazamos \\(x_j\\) por \\(\\log(x_j)\\))?"
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-2.-modelo-en-dos-partes-o-de-valla",
    "href": "tareas/tarea-2.html#pregunta-2.-modelo-en-dos-partes-o-de-valla",
    "title": "Tarea 2",
    "section": "Pregunta 2. Modelo en dos partes o de valla",
    "text": "Pregunta 2. Modelo en dos partes o de valla\nEn esta pregunta mostrará cómo para un modelo en dos partes Poisson la log verosimilitud del problema es la suma de log verosimilitud para un proceso binario y la log verosimilitud de un proceso Poisson truncado en cero. Considere una variable aleatoria \\(Y\\) con observaciones iid que sigue una distribución Poisson con parámetro \\(\\lambda\\) tal que\n\\[f(y,\\lambda)=P(Y=y)=\\frac{\\lambda^y exp(-\\lambda)}{y!}\\]\n\n[4 puntos] Obtenga la distribución Poisson truncada en cero, definida como \\(P(Y=y|Y&gt;0)\\).\n[5 puntos] Considere además un proceso binomial que modela la probabilidad de que la variable \\(Y\\) tome un valor cero o un valor positivo, como sigue:\n\\[P(Y=y)=\\begin{cases} \\pi \\quad\\quad y=0 \\\\ 1-\\pi\\quad\\quad y=1,2,3,\\ldots \\end{cases} \\]\nEn clase vimos la forma general del modelo en dos partes:\n\\[\ng(y)=\n\\begin{cases}\nf_1(0) \\quad\\text{si }y=0 \\\\\n\\frac{(1-f_1(0))f_2(y)}{1-f_2(0)}\\quad\\text{si }y\\geq 1\n\\end{cases}\n\\]\nEspecialice forma general del modelo de dos partes usando la distribución truncada derivada en a. y el proceso binomial definido arriba para obtener una función de masa de probabilidad no condicional para \\(Y\\), \\(g(y)\\).\n[6 puntos] Obtenga la log verosimilitud para la \\(i\\)ésima observación. Se sugiere que continúe sus cálculos con una ecuación en dos partes.\n[6 puntos] En este problema, parametrizaremos \\(\\lambda_i\\) como \\(\\lambda_i=exp(x_i'\\beta_2)\\), como regularmente lo hemos hecho en una regresión Poisson. Por otro lado, podemos trabajar con una parametrización general de la probabilidad \\(\\pi\\), \\(\\pi=F(x_i'\\beta_1)\\). Escriba la función de log verosimilitud del problema usando la parametrización para \\(\\pi_i\\) y para \\(\\lambda_i\\) que acabamos de describir. Presente esta función en una sola parte.\n[4 puntos] Agrupe los términos para mostrar que \\(\\mathcal{L}=\\mathcal{L}_1(\\beta_1)+\\mathcal{L}_2(\\beta_2)\\). Así, mostrará que la log verosimilitud del problema se puede descomponer en una log verosimilitud para el modelo binario y otra para el conteo truncado en cero. Por tanto, no perdemos información si estimamos los parámetros de la probabilidad binomial por un lado, y los de la distribución Poisson truncada en cero, por el otro."
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-3",
    "href": "tareas/tarea-2.html#pregunta-3",
    "title": "Tarea 2",
    "section": "Pregunta 3",
    "text": "Pregunta 3\nUse los datos phd_articulos.csv, los cuales contienen información sobre el número de artículos publicados para una muestra de entonces estudiantes de doctorado. Nuestra variable de interés será el número de artículos art.\n\n[5 puntos] Estime un modelo Poisson que incluya variables dicotómicas para estudiantes mujeres (female) y para estudiantes casadas o casados (married), el número de hijos mejores de cinco años (kid5), el ranking de prestigio del doctorado (phd) y el número de artículos publicados por su mentor (**mentor*). Realice la estimación de la matriz de varianzas primero a partir de la varianza teórica que resulta de la igualdad de la matriz de información y luego usando una matriz de sándwich. Interprete los coeficientes estimados.\n[5 puntos] Obtenga la razón de tasas de incidencia (IRR) para los coeficientes e interprete los resultados.\n[5 puntos] Considere ahora que las mujeres han tenido carreras profesionales más cortas que los hombres, es decir, han estado menos expuestas a la ocurrencia de los eventos publicar. Incorpore esto al análisis y reinterprete los resultados. Pista: explore la opción offeset en glm de R. La columna profage mide la duración efectiva de las carreras profesionales de cada individuo.\n[5 puntos] Emplee ahora un modelo negativo binomial con sobredispersión cuadrática en la media para estimar la relación entre el número de artículos publicados y las variables explicativas antes enumeradas. Interprete el coeficiente asociado al número de hijos y a la variable dicotómica para estudiantes mujeres. ¿Qué puede decir sobre la significancia del \\(\\alpha\\) estimado?"
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-4",
    "href": "tareas/tarea-2.html#pregunta-4",
    "title": "Tarea 2",
    "section": "Pregunta 4",
    "text": "Pregunta 4\nRetome los datos del archivo motral2012.csv usado en la Tarea 1. Estimará un modelo Tobit para explicar los factores que afectan la oferta laboral femenina. En este archivo de datos la variable hrsocup registra las horas trabajadas a la semana.\n\n[2 punto] ¿Qué proporción de la muestra femenina reporta horas trabajadas iguales a cero?\n[3 puntos] Se desea estimar el efecto de los años de educación (anios_esc) sobre la oferta laboral femenina controlando por el estado marital (casada), la edad (eda) y el número de hijos (n_hij) como una variable continua. En la base, e_con toma el valor de 5 para las personas casadas. Genere la variable dummy casada que tome el valor de 1 para las mujeres casadas y cero en otro caso. Estime un modelo de MCO para hrsocup mayor que cero, usando solo la población femenina. Reporte errores robustos. ¿Cuál es la interpretación sobre el coeficiente de los años de escolaridad?\n[3 puntos] ¿Qué problema existe con el modelo planteado en el punto anterior en términos de la selección? ¿Considera que se trata de un caso de censura o de truncamiento?\n[8 puntos] Estime un modelo Tobit de datos censurados. ¿Qué resuelve el modelo Tobit en este caso? Interprete nuevamente el coeficiente sobre los años de escolaridad.\n[4 puntos] ¿Cuál es el efecto marginal de un incremento de un año de educación en la oferta laboral? ¿Cómo cambia su respuesta si, en lugar de considerar la variable latente, considera la variable censurada?"
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-5",
    "href": "tareas/tarea-2.html#pregunta-5",
    "title": "Tarea 2",
    "section": "Pregunta 5",
    "text": "Pregunta 5\nUsando los mismos datos del archivo motral2012.csv implementará un ejercicio en el mismo espíritu del famoso estudio de Mroz (1987)1 sobre la oferta laboral femenina. El propósito es estimar la relación entre el salario y el número de horas trabajadas, concentrándonos en la muestra de mujeres.\n\n[5 puntos] El primer problema al que nos enfrentamos es que el salario no se observa para las mujeres que no trabajan. Estime un modelo lineal para el log del salario por hora, ing_x_hrs, usando las variables anios_esc, eda, n_hij, el cuadrado de n_hij, busqueda y casada, usando la submuestra de mujeres con salario por hora positivo. Dichas variables representan los años de escolaridad, la edad, el número de hijos, el cuadrado del número de hijos, si la persona buscó trabajo recientemente y si la persona es casada, respectivamente. Use los coeficientes estimados para imputar el ingreso por hora, faltante para las mujeres que reportan 0 en las horas trabajadas.\n[5 puntos] Use heckit de la librería sampleSelection para estimar por máxima verosimilitud un heckit para las horas trabajadas hrsocup. En la ecuación de selección (si la persona trabaja o no) incluya como variable explicativa el salario por hora (imputado para las mujeres que no trabajan), además de anios_esc, eda, n_hij, el cuadrado de n_hij, casada y busqueda (esta última es un indicador de si se buscó trabajo en la última semana). En la ecuación de horas, incluya los mismos regresores, excepto n_hij, su cuadrado y busqueda.\n[10 puntos] Estime ahora el heckit en dos pasos, a mano. Es decir, siga los siguientes pasos: i) estime un probit para la ecuación de selección y obtenga el índice \\(x_i'\\hat{\\beta}\\); ii) calcule el inverso de la razón de Mills \\(\\lambda_i(x_i'\\hat{\\beta})\\); y iii) estime por MCO la ecuación para las horas trabajadas con la submuestra que tiene horas trabajadas positivas, incluyendo como regresor el inverso de la razón de Mills estimado y el resto de los regresores. Compare los coeficientes y los errores estándar obtenidos en esta parte con los de la parte b. ¿Por qué son iguales o por qué difieren?"
  },
  {
    "objectID": "tareas/tarea-2.html#footnotes",
    "href": "tareas/tarea-2.html#footnotes",
    "title": "Tarea 2",
    "section": "Notas",
    "text": "Notas\n\n\nMroz, T. A. (1987). The sensitivity of an empirical model of married women’s hours of work to economic and statistical assumptions. Econometrica: Journal of the econometric society, 765-799.↩︎"
  },
  {
    "objectID": "tareas/tarea-1.html",
    "href": "tareas/tarea-1.html",
    "title": "Tarea 1",
    "section": "",
    "text": "Fecha de entrega: viernes 13 de septiembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los lenguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-1.html#instrucciones",
    "href": "tareas/tarea-1.html#instrucciones",
    "title": "Tarea 1",
    "section": "",
    "text": "Fecha de entrega: 20 de septiembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los lenguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-1.html#datos",
    "href": "tareas/tarea-1.html#datos",
    "title": "Tarea 1",
    "section": "Datos",
    "text": "Datos\nmotral2012.csv"
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-1",
    "href": "tareas/tarea-1.html#pregunta-1",
    "title": "Tarea 1",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nConsidere el problema de regresión no lineal en el que la variable dependiente escalar \\(y\\) tiene una media condicional \\(E(y_i)=g(x_i,\\beta)\\), siendo \\(g(\\cdot)\\) una función no lineal. Suponga que:\n\nEl proceso generador de datos es \\(y_i=g(x_i,\\beta_0)+u_i\\).\nEn el proceso generador de datos \\(E(u_i|x_i)=0\\) y \\(E(uu'|X)=\\Omega\\), donde \\(\\Omega_{0,ij}=\\sigma_{ij}\\).\nLa función \\(g(\\cdot)\\) satisface \\(g(x, \\beta^{(1)})=g(x, \\beta^{(2)})\\) si y solo si \\(\\beta^{(1)}=\\beta^{(2)}\\).\nLa matriz \\(A_0\\) existe y es finita y no singular y donde \\(A_0=p\\lim\\frac{1}{N}\\sum_{i=1}^{N}\\left.\\frac{\\partial g_i}{\\partial \\beta}\\right|_{\\beta_0}\\left.\\frac{\\partial g_i}{\\partial \\beta'}\\right|_{\\beta_0}=p\\lim\\frac{1}{N}\\left.\\frac{\\partial g'}{\\partial \\beta}\\frac{\\partial g'}{\\partial \\beta'}\\right|_{\\beta_0}\\)\n\\(N^{-1/2}\\sum_{i=1}^N \\left.\\frac{\\partial g_i}{\\partial \\beta}u_i \\right|_{\\beta_0}\\xrightarrow{d}\\mathcal{N}(0,B_0)\\), donde \\(B_0=p\\lim \\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\sigma_{ij}\\left.\\frac{\\partial g_i}{\\partial \\beta}\\frac{\\partial g_i}{\\partial \\beta'}\\right|_{\\beta_0}=p\\lim\\frac{1}{N}\\left.\\frac{\\partial g'}{\\partial \\beta}\\Omega_0 \\frac{\\partial g}{\\partial \\beta'}\\right|_{\\beta_0}\\).\n\n\n[5 puntos] Plantee el problema de optimización para la minimización de la suma de los errores cuadráticos y obtenga las condiciones de primer orden.\n[10 puntos] Pruebe que \\(\\hat{\\beta}_{MCNL}\\), el estimador de mínimos cuadrados no lineales (MCNL) y definido como una raíz de las condiciones de primer orden, es consistente para \\(\\beta_0\\).\n[10 puntos] Derive una expresión para \\(\\sqrt{N}(\\hat{\\beta}_{MCNL}-\\beta_0)\\) y pruebe que \\(\\sqrt{N}(\\hat{\\beta}_{MCNL}-\\beta_0)\\xrightarrow{d}\\mathcal{N}(0,A_0^{-1}B_0A_0^{-1})\\). Tip: utilice una expansión de Taylor exacta de primer orden.\n[5 puntos] ¿Cómo estimaría \\(V(\\hat{\\beta}_{MCNL})\\)?"
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-2",
    "href": "tareas/tarea-1.html#pregunta-2",
    "title": "Tarea 1",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nSuponga que está interesado en una variable aleatoria que tiene una distribución Bernoulli con parámetro \\(p\\). La función de densidad está definida como:\n\\[f(x_;p)=\\left\\{\\begin{array} .1 & \\text{con probabilidad } p \\\\ 0 & \\text{con probabilidad } 1-p \\end{array} \\right.\\] Suponga que tiene una muestra de \\(N\\) observaciones independientes e idénticamente distribuidas.\n\n[4 puntos] Plantee la función de log verosimilitud del problema.\n[4 puntos] Obtenga las condiciones de primer orden y resuelva para \\(\\hat{p}\\).\n[2 puntos] ¿Cuál es la media y la varianza del estimador de máxima verosimilitud que ha encontrado?"
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-3",
    "href": "tareas/tarea-1.html#pregunta-3",
    "title": "Tarea 1",
    "section": "Pregunta 3",
    "text": "Pregunta 3\nConsidere el modelo logit:\n\\[f(y_i|x_i;\\theta_0)=\\left\\{ \\begin{array} .1 & \\frac{\\exp\\{x_i'\\theta_0\\}}{1+\\exp\\{x_i'\\theta_0\\}}  \\\\ 0 &  \\frac{1}{1+\\exp\\{x_i'\\theta_0\\}} \\end{array} \\right.\\] donde \\(x_i\\) es un vector de variables explicativas, \\(\\theta_0\\) y es el vector de parámetros poblacional. Asuma que dispone de observaciones \\((y_i,x_i)\\) que son iid.\n\n[5 puntos] Escriba la función de log verosimilitud condicional para la observación \\(i\\).\n[5 puntos] Encuentre el vector score para la observación \\(i\\).\n[5 puntos] Encuentre la hesiana de la función de log verosimilitud con respecto a \\(\\mathbf{\\theta}\\).\n[5 puntos] Obtenga la matriz de información para la observación \\(i\\)."
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-4",
    "href": "tareas/tarea-1.html#pregunta-4",
    "title": "Tarea 1",
    "section": "Pregunta 4",
    "text": "Pregunta 4\nSuponga una variable aleatoria \\(X_i\\) con distribución desconocida. Sin embargo, sí conocemos que \\(E(X)=\\mu=54\\) y que \\(\\sqrt{V(X)}=\\sigma=6\\). Suponga que se recolecta una muestra de 50 observaciones.\n\n[2 punto] ¿Cuál es la distribución asintótica de la media muestral \\(\\bar{X}\\)?\n[4 punto] ¿Cuál es la probabilidad de que \\(\\bar{X}&gt;58\\)?\n[2 punto] ¿Cuál es la probabilidad de que una observación elegida al azar sea tal que \\(X_i&gt;58\\)?\n[2 punto] Provea un intervalo de confianza de 99% para la media muestral."
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-5",
    "href": "tareas/tarea-1.html#pregunta-5",
    "title": "Tarea 1",
    "section": "Pregunta 5",
    "text": "Pregunta 5\nEn esta pregunta mostraremos los alcances de los teoremas del límite central. Para esto, generaremos muchas muestras de tamaño \\(N\\) con una distribución \\(Bernoulli\\) con probabilidad de éxito \\(p=0.7\\). Recuerde que cuando realice simulaciones, siempre debe fijar una semilla al inicio para poder replicar su trabajo.\n\n[2 puntos] ¿Cuál es la media y la varianza de una variable aleatoria \\(y_i \\sim Bernoulli(0.7)\\)?\n[2 puntos] Si \\(y_i\\) son iid y podemos aplicar un teorema de límite central, ¿cuál es la distribución teórica de \\(\\bar{y}\\) cuando \\(N\\to\\infty\\)?\n[5 puntos] Realice el siguiente procedimiento \\(J=1,000\\) veces. Obtenga una muestra de tamaño \\(N=3\\) a partir de la distribución \\(Bernoulli(0.7)\\) y calcule la media muestral \\(\\bar{y}\\). Coleccione las \\(J\\) medias muestrales y luego grafique un histograma de las medias muestrales obtenidas junto con una curva teórica normal con la media y varianza obtenida en la parte b. Comente sobre lo que observa.\n[3 puntos] Repita lo realizado en la parte b., ahora con \\(N=15\\). Comente sobre lo que observa.\n[3 puntos] Repita lo realizado en la parte b., ahora con \\(N=1,500\\). Comente sobre lo que observa.\n[5 puntos] ¿Cómo usaría este ejercicio con palabras simples para explicar a una persona que no sabe mucho de estadística sobre la importancia de los teoremas de límite central?"
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-6",
    "href": "tareas/tarea-1.html#pregunta-6",
    "title": "Tarea 1",
    "section": "Pregunta 6",
    "text": "Pregunta 6\nSea \\(x_1\\) un vector de variables continuas, \\(x_2\\) una variable continua y \\(d_1\\) una variable dicotómica. Considere el siguiente modelo probit: \\[P(y=1│x_1,x_2 )=\\Phi(x_1'\\alpha+\\beta x_2+\\gamma x_2^2 )\\]\n\n[5 punto] Provea una expresión para el efecto marginal de \\(x_2\\) en la probabilidad. ¿Cómo estimaría este efecto marginal?\n[3 punto] Considere ahora el modelo: \\[P(y=1│x_1  ,x_2 ,d_1)=\\Phi(x_1 '\\delta+\\pi x_2+\\rho d_1+\\nu x_2 d_1 )\\] Provea la nueva expresión para el efecto marginal de \\(x_2\\).\n[2 punto] En el modelo de la parte b., ¿cómo evaluaría el efecto de un cambio en \\(d_1\\) en la probabilidad? Provea una expresión para este efecto."
  },
  {
    "objectID": "tareas/index.html",
    "href": "tareas/index.html",
    "title": "Tareas",
    "section": "",
    "text": "Tarea 1\n\nFecha de entrega: viernes 13 de septiembre a las 20:00 en Teams\nPreguntas\n\n\n\n\nTarea 2\n\nFecha de entrega: viernes 4 de octubre a las 20:00 en Teams\n\n\n\n\nTarea 3\n\nFecha de entrega: viernes 8 de noviembre a las 20:00 en Teams\n\n\n\n\nTarea 4\n\nFecha de entrega: viernes 29 de noviembre a las 20:00 en Teams",
    "crumbs": [
      "Tareas"
    ]
  },
  {
    "objectID": "reglas.html",
    "href": "reglas.html",
    "title": "Reglas",
    "section": "",
    "text": "No se tolerarán actos de discriminación. Se procura un ambiente de respeto entre todos los miembros de la clase.\nToda la comunicación relativa al curso se dará por medio del correo institucional del CIDE.\nLas tareas y exámenes se entregarán a través de Teams.\nLos participantes en la sesión deberán procurar que haya un ambiente silencioso para el desarrollo de la clase.\nSe aplicarán estrictamente los lineamientos generales contenidos en el código de ética del CIDE en términos de plagio y fraude en tareas y exámenes.",
    "crumbs": [
      "Reglas"
    ]
  },
  {
    "objectID": "presentaciones.html",
    "href": "presentaciones.html",
    "title": "Presentaciones",
    "section": "",
    "text": "Por favor, seleccione una de las lecturas marcadas con una “+” de la lista de lecturas y envíe un correo al profesor para que se le asigne una fecha de presentación.\n\n\n\n\n\n\n\n\n\nAutores\nTema\nPresentador o presentadora\nFecha de exposición\n\n\n\n\nAvila-Foucat & Pérez-Campuzano (2015)\nBinaria\n\nMiércoles 2 de octubre\n\n\nKveder & Flahaux (2013)\nMultinomial\n\nMiércoles 2 de octubre\n\n\nZou & Luo (2019)\nTobit\n\nMiércoles 2 de octubre\n\n\nHackett & Marquez-Padilla (2019)\nVI\nMoisés Barranco\nJueves 17 de octubre\n\n\nLópez-Feldman & Chávez (2017)\nVI\nDante Rito\nJueves 17 de octubre\n\n\nAmare t al. (2021)\nPanel\nEmiliano Alejo\nJueves 31 de octubre\n\n\nKagin et al. (2016)\nPanel\nMarcial Castillo\nJueves 31 de octubre\n\n\nLi & Maddala (1999)\nBootstrap\nVictor Rosas\nJueves 21 de noviembre\n\n\nEngelhardt & Kumar (2011)\nCuantil\n\nJueves 21 de noviembre",
    "crumbs": [
      "Presentaciones"
    ]
  },
  {
    "objectID": "lecturas.html",
    "href": "lecturas.html",
    "title": "Lecturas",
    "section": "",
    "text": "Todas las lecturas de capítulos de libro son obligatorias pues permiten una discusión informada en la clase. Las lecturas marcadas con “*” no serán cubiertas en clase, pero son ampliamente recomendables. En las sesiones de exposiciones cada alumno presentará uno de los artículos enlistados con negritas, por lo que se espera que el resto de la clase tenga el conocimiento suficiente para participar en la discusión.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#prerrequisitos",
    "href": "lecturas.html#prerrequisitos",
    "title": "Lecturas",
    "section": "Prerrequisitos",
    "text": "Prerrequisitos\n\nModelos lineales\n\nW, Capítulos 1-4",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-1",
    "href": "lecturas.html#semana-1",
    "title": "Lecturas",
    "section": "Semana 1",
    "text": "Semana 1\n\nIntroducción\n\nAngrist, J. D., & Pischke, J. S. (2017). Undergraduate Econometrics Instruction: Through Our Classes, Darkly. Journal of Economic Perspectives,31(2), 125-44.\n* Nakamura, E., & Steinsson, J. (2018). Identification in macroeconomics. Journal of Economic Perspectives, 32(3), 59-86.\n\nMCO\n\nCT, Capítulo 4 (secciones 4.1 a 4.3)",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-2",
    "href": "lecturas.html#semana-2",
    "title": "Lecturas",
    "section": "Semana 2",
    "text": "Semana 2\n\nTeoría asintótica\n\nCT, Capítulo 4, (sección 4.4)\n\nEstimadores extremos\n\nCT, Capítulo 5",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-3",
    "href": "lecturas.html#semana-3",
    "title": "Lecturas",
    "section": "Semana 3",
    "text": "Semana 3\n\nPrueba de hipótesis\n\nCT, Capítulo 7",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-4",
    "href": "lecturas.html#semana-4",
    "title": "Lecturas",
    "section": "Semana 4",
    "text": "Semana 4\n\nVariable dependiente binaria\n\nCT, Capítulo 14 (secciones 14.1 - 14.4)\nBinaria: Avila-Foucat, V. S., & Pérez-Campuzano, E. (2015). Municipality socioeconomic characteristics and the probability of occurrence of Wildlife Management Units in Mexico. Environmental Science & Policy, 45, 146-153.\n* Ordenados: Conigliani, C., Manca, A., & Tancredi, A. (2015). Prediction of patient-reported outcome measures via multivariate ordered probit models. Journal of the Royal Statistical Society. Series A (Statistics in Society), 567-591.\n\nVariable dependiente categórica\n\nCT, Capítulo 15 (secciones 15.1 - 15.4)\nMultinomial: Kveder, C. L. M., & Flahaux, M. L. (2013). Returning to Dakar: A mixed methods analysis of the role of migration experience for occupational status. World Development, 45, 223-238.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-5",
    "href": "lecturas.html#semana-5",
    "title": "Lecturas",
    "section": "Semana 5",
    "text": "Semana 5\n\nModelos de conteo\n\nCT, Capítulo 20 (secciones 20.1 - 20.4).\n* Poisson: White, K., & Buckley, C. J. (2011). Exposure to international migration and its effect on childbearing in Turkey. International Migration Review, 45(1), 123-147.\n* Negativo binomial: Antón, J. I., & De Bustillo, R. M. (2010). Health care utilisation and immigration in Spain. The European Journal of Health Economics, 11(5), 487-498.\n* Inflado en cero: Young, J. D., Anderson, N. M., Naughton, H. T., & Mullan, K. (2018). Economic and policy factors driving adoption of institutional woody biomass heating systems in the US. Energy Economics, 69, 456-470.\n* Dos partes: Colchero, M. A., Molina, M., & Guerrero-López, C. M. (2017). After Mexico implemented a tax, purchases of sugar-sweetened beverages decreased and water increased: difference by place of residence, household composition, and income level. The Journal of nutrition, 147(8), 1552-1557.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-6",
    "href": "lecturas.html#semana-6",
    "title": "Lecturas",
    "section": "Semana 6",
    "text": "Semana 6\n\nModelos de selección\n\nCT, Capítulo 16 (secciones 16.1 – 16.6)\nTobit: Zou, B., & Luo, B. (2019). Rural Household Energy Consumption Characteristics and Determinants in China. Energy.\n* Heckman: Parey, M., Ruhose, J., Waldinger, F., & Netz, N. (2017). The selection of high-skilled emigrants. Review of Economics and Statistics, 99(5), 776-792.\n* Ordenado + selección: Alemi, F., Circella, G., Mokhtarian, P., & Handy, S. (2019). What drives the use of ridehailing in California? Ordered probit models of the usage frequency of Uber and Lyft. Transportation Research Part C: Emerging Technologies, 102, 233-248.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-7",
    "href": "lecturas.html#semana-7",
    "title": "Lecturas",
    "section": "Semana 7",
    "text": "Semana 7\n\nVariables instrumentales\n\nW, Capítulo 5.\nCT, Capítulo 4 (secciones 4.8 y 4.9)",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-8",
    "href": "lecturas.html#semana-8",
    "title": "Lecturas",
    "section": "Semana 8",
    "text": "Semana 8\n\nMétodo generalizado de momentos\n\nCT, Capítulo 6 (secciones 6.1 - 6.4)",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-9",
    "href": "lecturas.html#semana-9",
    "title": "Lecturas",
    "section": "Semana 9",
    "text": "Semana 9\n\nVariables instrumentales en la práctica\n\nVI: Hackett, L., & Marquez-Padilla, F. (2019). Working for Change: the Effect of Female Labor Force Participation on Fertility. SSRN Working Paper 3354753.\nVI: López-Feldman, A., & Chávez, E. (2017). Remittances and natural resource extraction: Evidence from Mexico. Ecological Economics, 132, 69-79.\n\nOtras aplicaciones de VI\n\n* VI: Campos-Vazquez, R. M., & Nuñez, R. (2019). Obesity and labor market outcomes in Mexico/Obesidad y el mercado de trabajo en México. Estudios Económicos, 34(2), 159-196.\n* MC2E2M: Mocetti, S. (2007). Intergenerational earnings mobility in Italy. The BE Journal of Economic Analysis & Policy, 7(2).\n\n* Poisson + VI: Hirvonen, K., & Hoddinott, J. (2017). Agricultural production and children’s diets: Evidence from rural Ethiopia. Agricultural Economics, 48(4), 469-480.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-10",
    "href": "lecturas.html#semana-10",
    "title": "Lecturas",
    "section": "Semana 10",
    "text": "Semana 10\n\nModelos y estimadores de panel\n\nCT, Capítulo 21\nPanel: Amare, M., Abay, K. A., Tiberti, L., & Chamberlin, J. (2021). COVID-19 and food security: Panel data evidence from Nigeria. Food policy, 101, 102099.\nPanel: Kagin, J., Taylor, J. E., & Yúnez-Naude, A. (2016). Inverse productivity or inverse efficiency? Evidence from Mexico. The Journal of Development Studies, 52(3), 396-411.\n* Panel: Bwalya, S. M. (2006). Foreign direct investment and technology spillovers: Evidence from panel data analysis of manufacturing firms in Zambia. Journal of development economics, 81(2), 514-526.\n* Panel + DID: Estrada, R. (2019). Rules versus discretion in public service: Teacher hiring in Mexico. Journal of Labor Economics, 37(2), 545-579.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-11",
    "href": "lecturas.html#semana-11",
    "title": "Lecturas",
    "section": "Semana 11",
    "text": "Semana 11\n\nTemas de errores estándar\n\nMHE, Capítulo 8",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-12",
    "href": "lecturas.html#semana-12",
    "title": "Lecturas",
    "section": "Semana 12",
    "text": "Semana 12\n\nBootstrap\n\nCT, Capítulo 11\nBootstrap: Li, H., & Maddala, G. S. (1999). Bootstrap variance estimation of nonlinear functions of parameters: an application to long-run elasticities of energy demand. Review of Economics and Statistics, 81(4), 728-733.\n\nRegresión cuantil\n\nCT, Capítulo 4 (sección 4.6)\nCuantil: Engelhardt, G. V., & Kumar, A. (2011). Pensions and household wealth accumulation. Journal of Human Resources, 46(1), 203-236.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-13",
    "href": "lecturas.html#semana-13",
    "title": "Lecturas",
    "section": "Semana 13",
    "text": "Semana 13\n\nMétodos semiparamétricos\n\nCT, Capítulo 9\nSemiparamétrico: Hussinger, K. (2008). R&D and subsidies at the firm level: An application of parametric and semiparametric two‐step selection models. Journal of applied econometrics, 23(6), 729-747.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-14",
    "href": "lecturas.html#semana-14",
    "title": "Lecturas",
    "section": "Semana 14",
    "text": "Semana 14\n\nMétodos semiparamétricos\n\nCT, Capítulo 9\nSemiparamétrico: Hussinger, K. (2008). R&D and subsidies at the firm level: An application of parametric and semiparametric two‐step selection models. Journal of applied econometrics, 23(6), 729-747."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Econometría II 2024",
    "section": "",
    "text": "Profesor: Irvin Rojas (irvin.rojas@cide.edu).\nLaboratorista: por definir.\nHorario de clases: miércoles y jueves (8:00 a 9:30).\nHorario de laboratorio: por definir.\nPlataforma del curso: Microsoft Teams.\nHorario de oficina: martes y jueves (17:00)\n\n¡Bienvenidas, bienvenidos!\nEste es un sitio para las y los estudiantes del curso de Econometría II de la Maestría en Economía del CIDE. Sin embargo, otras personas pueden encontrar útiles los recursos de este sitio, como el programa del curso, las tareas y la lista de lecturas.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "materials.html",
    "href": "materials.html",
    "title": "Course Materials",
    "section": "",
    "text": "Datasets\nSlides"
  },
  {
    "objectID": "programa.html",
    "href": "programa.html",
    "title": "Programa",
    "section": "",
    "text": "Conocer la teoría sobre la que se fundamentan los métodos para la estimación de relaciones empíricas y la inferencia usando datos de sección cruzada y de panel.\nDiseñar estrategias econométricas usando los modelos adecuados de acuerdo con la pregunta de investigación.\nEmplear software para estimar los modelos econométricos apropiados de acuerdo con la naturaleza de los datos disponibles.\nConocer e implementar buenas prácticas en el uso de software, orientadas a la transparencia y la replicabilidad en la investigación.\nConocer los métodos que se emplean en la investigación económica actual.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#objetivos",
    "href": "programa.html#objetivos",
    "title": "Programa",
    "section": "",
    "text": "Conocer la teoría sobre la que se fundamentan los métodos para la estimación de relaciones empíricas y la inferencia usando datos de sección cruzada y de panel.\nDiseñar estrategias econométricas usando los modelos adecuados de acuerdo con la pregunta de investigación.\nEmplear software para estimar los modelos econométricos apropiados de acuerdo con la naturaleza de los datos disponibles.\nConocer e implementar buenas prácticas en el uso de software, orientadas a la transparencia y la replicabilidad en la investigación.\nConocer los métodos que se emplean en la investigación económica actual.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#referencias",
    "href": "programa.html#referencias",
    "title": "Programa",
    "section": "Referencias",
    "text": "Referencias\nEl curso se basa en los siguientes textos:\n\n(MHE) Angrist, J.D. y Pischke, J.S. (2013). Mostly Harmless Econometrics: An Empiricists Companion. Princeton University Press.\n* (CT) Cameron, A.C. y Trivedi, P.K. (2005). Microeconometrics: Methods and applications. Oxford University Press.\nHansen, B. (2022). Econometrics. Princeton University Press.\nHayashi, F. (2000). Econometrics. Princeton University Press.\n* (W) Wooldridge, J.M. (2010). Econometric analysis of cross section and panel data. Segunda edición, MIT Press.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#contenido-temático",
    "href": "programa.html#contenido-temático",
    "title": "Programa",
    "section": "Contenido temático",
    "text": "Contenido temático\nUnidad 1. Introducción\n\nRevisión de fundamentos de estadística y regresión lineal\nTeoría asintótica\nEstimadores extremos\nMáxima verosimilitud\nMínimos cuadrados no lineales\nInferencia estadística\n\nUnidad 2. Modelos de variable dependiente no continua\n\nModelos de variable dependiente binaria\n\nModelos de conteo\n\nUnidad 3. Modelos de selección\n\nModelo de Tobit\nModelo de Heckman\n\nUnidad 4. Endogeneidad\n\nVariables instrumentales\nMétodo generalizado de momentos\nEstimación con instrumentos débiles\n\nUnidad 5. Datos de panel\n\nModelos de efectos fijos y de efectos aleatorios\nEstimadores between y within\nEstimadores de primeras diferencias y de efectos aleatorios\nErrores estándar agrupados\n\nUnidad 6. Extensiones\n\nBootstrap\nRegresión por cuantiles\nMétodos semi paramétricos y no paramétricos\nModelos de panel no lineales\nModelos de panel con endogeneidad\nModelos de riesgo y de sobrevivencia",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#evaluación-del-curso",
    "href": "programa.html#evaluación-del-curso",
    "title": "Programa",
    "section": "Evaluación del curso",
    "text": "Evaluación del curso\n\nExamen parcial: 30%.\nExamen final acumulativo: 45%\nTareas (4): 20% (5% cada una)\nExposición: 5%",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#tareas",
    "href": "programa.html#tareas",
    "title": "Programa",
    "section": "Tareas",
    "text": "Tareas\nCuatro tareas teórico-prácticas. Las tareas deben entregarse de manera individual, pero se recomienda ampliamente colaborar en grupos de estudio. Las tareas deberán entregarse en Teams antes de la fecha y hora señalada. No se aceptarán tareas fuera de tiempo. Por favor, no comprima los archivos en carpetas comprimidas. Las tareas deberán contener dos archivos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad de manera aleatoria.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#software",
    "href": "programa.html#software",
    "title": "Programa",
    "section": "Software",
    "text": "Software\nR será el paquete standard usado en las sesiones prácticas. Más aún, el uso de cualquier software es aceptado siempre que se cumplan con los requisitos de replicabilidad y reportes de las tareas y exámenes. Habrá una sesión especial para introducir el uso de Quarto para la generación de reportes científicos.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#exámenes",
    "href": "programa.html#exámenes",
    "title": "Programa",
    "section": "Exámenes",
    "text": "Exámenes\n\nExamen parcial: miércoles 9 de octubre en el horario de clase.\nExamen final: por definir.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#exposición",
    "href": "programa.html#exposición",
    "title": "Programa",
    "section": "Exposición",
    "text": "Exposición\nCada alumno realizará una presentación de uno de los artículos aplicados marcados con negritas en la lista de lecturas. Cada presentación deberá ser de máximo 15 minutos y deberá incluir el contenido que el presentador considere más relevante. La presentación deberá abordar, mínimamente: 1) el problema a investigar, 2) la metodología empleada, 3) la relación entre la metodología y la teoría vista en el curso, 4) los datos empleados, 5) los principales resultados, y 6) una crítica sobre la validez y las conclusiones del estudio.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#lista-de-lecturas",
    "href": "programa.html#lista-de-lecturas",
    "title": "Programa",
    "section": "Lista de lecturas",
    "text": "Lista de lecturas\nTodas las lecturas de capítulos de libro son obligatorias pues permiten una discusión informada en la clase. Las lecturas marcadas con “*” no serán cubiertas en clase, pero son ampliamente recomendables. En las sesiones de exposiciones cada alumno presentará uno de los artículos enlistados con negritas, por lo que se espera que el resto de la clase tenga el conocimiento suficiente para participar en la discusión.\nLa lista de lecturas está disponible aquí.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Example schedule:\n\n\n\n\n\n\n\n\n\nMorning\nAfternoon\n\n\n\n\nL\nIntro + Data manipulation\ngit / GitHub\n\n\nM\nGeneralised Linear Models\nData visualisation\n\n\nX\nMixed models / GAM / Bayes\nFunctional programming + Students work\n\n\nJ\nMultivariate analyses\nReproducible workflows\n\n\nV\nUsing R as GIS + Students work\nProject presentations"
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html",
    "href": "tareas/tarea-1-respuestas.html",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Suponga que está interesado en una variable aleatoria que tiene una distribución Bernoulli con parámetro \\(p\\). La función de densidad está definida como:\n\\[f(x_;p)=\\left\\{\\begin{array} .1 & \\text{con probabilidad } p \\\\ 0 & \\text{con probabilidad } 1-p \\end{array} \\right.\\] Suponga que tiene una muestra de \\(N\\) observaciones independientes e idénticamente distribuidas.\n\n[4 puntos] Plantee la función de log verosimilitud del problema.\nPodemos escribir la función de densidad para la \\(i\\)-ésima observación como\n\\[f(x_i;p)=p^{x_i}(1-p)^{(1-x_i)}\\]\nPor tanto, la función de verosimilitud es\n\\[L_N(p)=\\prod_{i=1}^N f(x;p)=\\prod_{i=1}^N p^{x_i}(1-p)^{(1-x_i)} = p^{\\sum_{i=1}^N x_i}(1-p)^{N-\\sum_{i=1}^N x_i}\\]\nY la función de log verosimilitud será\n\\[\\mathcal{L_N(p)}=\\ln{L_N(p)}=\\sum x_i \\ln(p)-(N-\\sum x_i)\\ln(1-p)\\]\n[4 puntos] Obtenga las condiciones de primer orden y resuelva para \\(\\hat{p}\\).\nDerivando \\(\\mathcal{L}_N\\) con respecto a \\(p\\) obtenemos la condición de primer orden:\n\\[\\frac{d\\mathcal{L}_N(p)}{d p}=\\frac{\\sum x_i}{p}-\\frac{N-\\sum x_i}{1-p}=0\\]\nY resolviendo, obtenemos el estimador de máxima verosimilitud \\[\\hat{p}_{MV}=\\bar{x}\\] es decir, la media muestral.\n[2 puntos] ¿Cuál es la media y la varianza del estimador de máxima verosimilitud que ha encontrado?\nObtenemos directamente la media \\[E(\\hat{p}_{MV})=E(\\bar{x})=\\frac{1}{N}E\\left(\\sum x_i\\right)=\\frac{1}{N}N p=p\\]\nMientras que la varianza es \\[V(\\hat{p}_{MV})=\\frac{1}{N^2}V\\left(\\sum x_i\\right)=\\frac{p(1-p)}{N}\\]\n\n\n\n\nSuponga que \\(y_i|\\mathbf{x}_i\\sim\\mathcal{N}(m(\\mathbf{x}_i,\\mathbf{\\beta}_0),\\sigma_0^2)\\), donde \\(m(\\mathbf{x},\\mathbf{\\beta})\\) es una función del vector de variables explicativas \\(\\mathbf{x}\\) y del vector de parámetros \\(\\mathbf{\\beta}\\) de dimensión \\((k\\times 1)\\). Entonces, \\(E(y_i|\\mathbf{x}_i)=m(\\mathbf{x}_i,\\mathbf{\\beta}_0)\\) y \\(V(y_i|\\mathbf{x}_i)=\\sigma^2_0\\).\n\n[2 puntos] Escriba la función de log verosimilitud condicional para la observación \\(i\\). Muestre que el estimador de máxima verosimilitud \\(\\hat{\\mathbf{\\beta}}\\) resuelve el problema de minimización \\(\\min_\\mathbf{\\beta}\\sum_i(y_i-m(\\mathbf{x}_i,\\mathbf{\\beta}))^2\\).\nLa densidad de la \\(i\\)ésima observación es:\n\\[f(y|x_i)=\\frac{1}{\\sqrt{2\\pi\\sigma^2_0}}exp\\left(-\\frac{1}{2\\sigma^2_0}(y-m(x_i,\\beta))^2\\right)\\]\nPor tanto, la log verosimilitud para \\(i\\) es:\n\\[\n\\mathcal{l}_i(\\beta,\\sigma^2)=-\\frac{1}{2}\\ln(2\\pi)-\\frac{1}{2}\\ln(\\sigma^2)-\\frac{1}{2\\sigma^2}(y_i-m(x_i,\\beta))^2\n\\]\nDado que solo la última parte de este problema depende de \\(\\beta\\), y siendo \\(\\sigma^2&gt;0\\), el problema de maximizar \\(\\sum_i\\mathcal{l}_i(\\beta,\\sigma^2)\\) es igual a maximizar \\(\\sum_i(y_i-m(x_i,\\beta))^2\\).\n[4 puntos] Sea \\(\\mathbf{\\theta}\\equiv(\\mathbf{\\beta}'\\;\\sigma^2)'\\) un vector de parámetros de dimensión \\((k+1)\\times 1\\). Encuentre el vector score para la observación \\(i\\). Muestre que \\(E(\\mathbf{s}_i(\\mathbf{\\theta}_0)|\\mathbf{x}_i)=\\mathbf{0}\\).\nEl vector score es el vector de primeras derivadas parciales de la log verosimilitud. Las derivadas parciales son:\n\\[\n\\begin{aligned} \\frac{\\partial \\mathcal{l}_i}{\\partial\\beta}&=\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'\\frac{(y_i-m(x_i,\\beta))}{\\sigma^2} \\\\ \\frac{\\partial \\mathcal{l}_i}{\\partial\\sigma^2}&= -\\frac{1}{2\\sigma^2}+\\frac{1}{2\\sigma^4}(y_i-m(x_i,\\beta))^2\\end{aligned}\n\\]\nNoten que \\(\\left(\\frac{\\partial \\mathcal{l}_i}{\\partial\\beta}\\right)'\\) es un vector de \\(1\\times k\\). Podemos escribir el score como:\n\\[s_i(\\beta,\\sigma^2)=\n\\begin{pmatrix}\n\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\frac{(y_i-m(x_i,\\beta))}{\\sigma^2} \\\\\n-\\frac{1}{2\\sigma^2}+\\frac{1}{2\\sigma^4}(y_i-m(x_i,\\beta))^2 \\\\\n\\end{pmatrix}\\]\nDado que \\(E(y_i|x_i)=m(x_i,\\beta)\\),los primeros \\(k\\) términos del score tienen esperanza 0. Entonces, nos resta comprobar la última entrada. Calculando el valor esperado del segundo sumando de la última entrada:\n\\[E((y_i-m(x_i,\\beta))^2)=E((y_i-E(y_i|x_i))^2)=V(y_i|x_i)=\\sigma^2\\]\nlo que hace que la última entrada del vector score también tenga esperanza 0.\n[2 puntos] Usando las condiciones de primer orden, encuentre \\(\\hat{\\sigma}^2\\) en términos de \\(\\hat{\\mathbf{\\beta}}\\).\nLa condición de primer orden con respecto a \\(\\sigma^2\\) es\n\\[\\sum_i \\left(-\\frac{1}{2\\sigma^2}+\\frac{1}{2\\sigma^4}(y_i-m(x_i,\\beta))^2\\right)\\]\nResolviendo para \\(\\sigma^2\\) obtenemos:\n\\[\\hat{\\sigma}^2=\\frac{1}{N}\\sum_i (y_i-m(x_i,\\hat{\\beta}))^2\\]\n[5 puntos] Encuentre la matriz hesiana de la función de log verosimilitud con respecto a \\(\\mathbf{\\theta}\\).\nProcedemos a derivar el score, primero con respecto a \\(\\beta\\) y luego con respecto a \\(\\sigma^2\\).\n\n\\(\\frac{\\partial}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\frac{(y_i-m(x_i,\\beta))}{\\sigma^2}\\right)=-\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'+\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta\\partial\\beta}(y_i-m(x_i,\\beta))\\)\n\\(\\frac{\\partial}{\\partial\\sigma^2}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\frac{(y_i-m(x_i,\\beta))}{\\sigma^2}\\right)=-\\frac{1}{\\sigma^4}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}(y_i-m(x_i,\\beta))\\)\n\\(\\frac{\\partial}{\\partial\\beta}\\left( -\\frac{1}{2\\sigma^2}+\\frac{1}{2\\sigma^4}(y_i-m(x_i,\\beta))^2\\right)=-\\frac{1}{\\sigma^4}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'(y_i-m(x_i,\\beta))\\)\n\\(\\frac{\\partial}{\\partial\\sigma^2}\\left( -\\frac{1}{2\\sigma^2}+\\frac{1}{2\\sigma^4}(y_i-m(x_i,\\beta))^2\\right)=\\frac{1}{2\\sigma^4}-\\frac{1}{\\sigma^6}(y-m(x_i,\\beta))^2\\)\n\nPor lo que la matriz Hessiana es:\n\\[\n  H_i(\\beta,\\sigma^2)=\n  \\begin{pmatrix}\n  -\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'+\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta\\partial\\beta}(y_i-m(x_i,\\beta)) & -\\frac{1}{\\sigma^4}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}(y_i-m(x_i,\\beta)) \\\\ -\\frac{1}{\\sigma^4}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'(y_i-m(x_i,\\beta)) & \\frac{1}{2\\sigma^4}-\\frac{1}{\\sigma^6}(y-m(x_i,\\beta))^2 \\\\\n  \\end{pmatrix}\n\\]\n[5 puntos] Muestre que \\(-E(\\mathbf{H}_i(\\mathbf{\\theta}_0)|\\mathbf{x}_i)=E(\\mathbf{s}_i(\\mathbf{\\theta}_0)\\mathbf{s}_i(\\mathbf{\\theta}_0)'|\\mathbf{x}_i)\\).\nPrimero mostramos el valor esperado de cada entrada de la matriz hessiana. En la parte b. mostramos que \\(E(y-m(x_i,\\beta))=0\\), por lo que los elementos fuera de la diagonal principal tiene expectativa cero.\nPor la misma razón:\n\\[\n\\begin{aligned}\n& E\\left(-\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'+\\frac{1}{\\sigma^2}\\frac{\\partial  m(x,\\beta)}{\\partial\\beta\\partial\\beta}(y_i-m(x_i,\\beta))\\right) = \\\\\n& -\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'\n\\end{aligned}\n\\]\nEl último término usa lo que hemos mostrado antes, \\(E((y_i-m(x_i,\\beta))^2)=\\sigma^2\\). Por tanto:\n\\[\nE\\left(\\frac{1}{2\\sigma^4}-\\frac{1}{\\sigma^6}(y-m(x_i,\\beta))^2\\right)=-\\frac{1}{2\\sigma^4}\n\\]\nEntonces obtenemos un primer resultado:\n\\[\n-E(H_i(\\beta,\\sigma^2)|x_i)=\n\\begin{pmatrix}\n\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)' & 0 \\\\\n0 & \\frac{1}{2\\sigma^4}\\\\\n\\end{pmatrix}\n\\]\nTenemos que mostrar que el valor esperado del producto exterior del score es igual a lo que acabamos de encontrar. Calculamos el valor esperado del producto exterior del score:\n\\[E(s(\\beta,\\sigma^2)s(\\beta,\\sigma^2)'|x_i)=E\\left(\\begin{pmatrix} A & B \\\\ B & C \\end{pmatrix}\\Bigg|x_i\\right)\\].\nEl bloque superior de la matriz resultante es \\(E(A)\\):\n\\[\n\\begin{aligned}\nE(A)&=\n\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'\\frac{(y_i-m(x_i,\\beta))^2}{\\sigma^4} \\\\\n&=\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'\n\\end{aligned}\n\\]\nEl término \\(B\\) es:\n\\[E(B)=-\\frac{1}{2\\sigma^4}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'(y-m(x_i,\\beta))+\\frac{1}{2\\sigma^6}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'(y-m(x_i,\\beta))^3\\]\nEste término tiene valor esperado cero porque para una variable aleatoria normal \\(X\\) con media cero, sucede que \\(E(X^n)=0\\) cuando \\(n\\) es impar.\nY finalmente, el término \\(E(C)\\) será:\n\\[\n\\begin{aligned}\nC&=\nE\\left(-\\frac{1}{2\\sigma^2}+\\frac{1}{2\\sigma^4}(y_i-m(x_i,\\beta))^2\\right)\\\\\n&=E\\left(\\frac{1}{4\\sigma^8}(y-m(x_i,\\beta))^4-\\frac{1}{2\\sigma^6}(y-m(x_i,\\beta))^2+\\frac{1}{4\\sigma^4}\\right) \\\\\n&=E\\left(\\frac{1}{4\\sigma^8}(y-m(x_i,\\beta))^4\\right)-\\frac{1}{2\\sigma^4}+\\frac{1}{4\\sigma^4}\n\\end{aligned}\n\\]\nPara una variable aleatoria \\(X\\sim \\mathcal{N}(0, \\sigma^2)\\), sucede que \\(E(X^4)=3\\sigma^4\\). Entonces:\n\\[\n\\begin{aligned}\nC&=\\frac{3\\sigma^4}{4\\sigma^8}-\\frac{1}{2\\sigma^4}+\\frac{1}{4\\sigma^4} \\\\\n& =\\frac{1}{2\\sigma^4}\n\\end{aligned}\n\\]\n[2 puntos] Encuentre la varianza asintótica estimada de \\(\\hat{\\mathbf{\\beta}}\\) y explique cómo obtendría los errores estándar.\nPor los resultados generales de MV vistos en clase, sabemos que la varianza asintótica está dada por \\(E(A_i(\\theta))^{-1}\\), donde \\(A_i(\\theta)=-E(H_i(\\theta))\\), obtenida en la parte e (no confundir con \\(A\\) del punto anterior, usada para simplificar la presentación de los cálculos sobre el producto exterior del score). Un extimador para la matriz de varianzas es entonces:\n\\[\n\\hat{V}(\\hat{\\beta})=\\hat{\\sigma}^2\\left(\\sum_i\\frac{\\partial m(x_i,\\hat{\\beta})}{\\partial\\beta}\\left(\\frac{\\partial m(x_i,\\hat{\\beta})}{\\partial\\beta}\\right)'\\right)^{-1}\n\\]\nEl error estándar del \\(j\\)ésimo regresor estimado es simplemente la raíz cuadrada de la \\(j\\)ésima entrada en la diagonal principal de \\(\\hat{V}(\\hat{\\beta})\\).\n\n\n\n\nSuponga una variable aleatoria \\(X_i\\) con distribución desconocida. Sin embargo, sí conocemos que \\(E(X)=\\mu=54\\) y que \\(\\sqrt{V(X)}=\\sigma=6\\). Suponga que se recolecta una muestra de 50 observaciones.\n\n[2 punto] ¿Cuál es la distribución asintótica de la media muestral \\(\\bar{X}\\)?\nSi se puede aplicar un teorema de límite central a la media muestral, sabemos que la nueva variable hereda la media de \\(X_i\\) y la desviación estándar es la desviación estándar de \\(X_i\\) dividida por la raíz del tamaño de la muestra. Es decir:\n\\[\\bar{X}\\sim \\mathcal{N}(54, 6^2/50)\\]\n[4 punto] ¿Cuál es la probabilidad de que \\(\\bar{X}&gt;58\\)?\nSabemos que \\(\\frac{\\bar{X}-54}{6/\\sqrt{50}}\\sim\\mathcal{N}(0,1)\\), por tanto:\n\\[P(\\bar{X}&gt;58)=P\\left(z&gt;\\frac{58-54}{6/\\sqrt{50}}\\right)=P(z&gt;4.714045)=1-\\Phi(4.714045)\\]\nCalculamos la probabilidad usando pnorm, que nos da la función de distribución. La probabilidad es un número muy pequeño:\n\n1-pnorm((58-54)/(6/sqrt(50)), mean = 0, sd = 1)\n\n[1] 1.214234e-06\n\n\n[2 punto] ¿Cuál es la probabilidad de que una observación elegida al azar sea tal que \\(X_i&gt;58\\)?\nEs imposible de determinar porque no sabemos la distribución de \\(X_i\\). Esto es algo muy conveniente de los TLC, pues nos permiten hacer afirmaciones sobre la media muestral sin saber la distribución de la que provienen las observaciones. Solo necesitamos que se cumplan las condiciones sobre las \\(X_i\\) para aplicar los TLC.\n[2 punto] Provea un intervalo de confianza de 99% para la media muestral.\nPor un lado, sabemos que la variable aleatoria \\(Z=\\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{N}}\\) tendrá una distribución \\(\\mathcal{N}(0,1)\\). Por otro lado, queremos obtener \\(P(-z_{\\alpha/2}&lt;Z&lt;z_{\\alpha/2})=0.99\\). Manipulando, obtenemos una expresión para el intervalo de confianza:\n\\[\\left(\\bar{X}-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{N}},\\bar{X}+z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{N}}\\right)\\]\nEn nuestro caso, el intervalo es:\n\\[P\\left(\\bar{X}\\pm 2.5758\\times(6/\\sqrt{50})\\right)=0.99\\]\ndonde obtenemos el 2.5758 como:\n\nqnorm(0.995)\n\n[1] 2.575829\n\n\nqnorm es la función cuantil y está definida como la función inversa de la función de distribución. La función cuantil da el valor de \\(x\\) tal que \\(F(x)=P(X \\leq x)=p\\).\nEntonces, el intervalo de confianza es: \\[P(\\bar{X}\\pm 2.185664)=0.99\\]\n\n\n\n\nEn esta pregunta mostraremos los alcances de los teoremas del límite central. Para esto, generaremos muchas muestras de tamaño \\(N\\) con una distribución \\(Bernoulli\\) con probabilidad de éxito \\(p=0.3\\). Recuerde que cuando realice simulaciones, siempre debe fijar una semilla al inicio para poder replicar su trabajo.\n\n[2 puntos] ¿Cuál es la media y la varianza de una variable aleatoria \\(y_i \\sim Bernoulli(0.3)\\)?\nPara una variable que se distribuye \\(Bernoulli(p)\\), la media es \\(p\\) y la varianza es \\(p(1-p)\\). Para este caso, \\(E(y_i)=0.3\\) y \\(V(y_i)=0.3*0.7=0.21\\).\n[2 puntos] Si \\(y_i\\) son iid y podemos aplicar un teorema de límite central, ¿cuál es la distribución teórica de \\(\\bar{y}\\) cuando \\(N\\to\\infty\\)?\nObtenemos el valor esperado y la varianza de \\(\\bar{y}\\):\n\\[E(\\bar{y})=\\frac{1}{N}E(\\sum_i y_i)  = E(y_i)=p\\]\n\\[V(\\bar{y})=\\frac{1}{N^2}V(\\sum_i y_i) = \\frac{1}{N}V(y_i)=\\frac{p(1-p)}{N}\\]\nEntonces, un TLC nos daría las condiciones para que:\n\\[\\frac{\\bar{y}-0.3}{0.21/N}\\sim\\mathcal{N}(0, 1)\\]\n[5 puntos] Realice el siguiente procedimiento \\(J=1,000\\) veces. Obtenga una muestra de tamaño \\(N=2\\) a partir de la distribución \\(Bernoulli(0.3)\\) y calcule la media muestral \\(\\bar{y}\\). Coleccione las \\(J\\) medias muestrales y luego grafique un histograma de las medias muestrales obtenidas junto con una curva teórica normal con la media y varianza obtenida en la parte b. Comente sobre lo que observa.\n\nset.seed(820)\nreps &lt;- 1000\nn &lt;- 2\np &lt;- 0.3\nv &lt;- p*(1-p)/n\n\nymedias2 &lt;- numeric(reps)\nfor (i in 1:reps){\n sample &lt;- rbernoulli(n, p)\n ymedias2[i]&lt;-mean(sample)\n}\n\nGraficamos junto con una densidad \\(N(0.3, 0.21/2)\\):\n\nhist(ymedias2, breaks=20, prob=TRUE, \n     xlab=\"Medias\")\ncurve(dnorm(x, mean=p, sd=sqrt(v)), \n      col=\"darkblue\", lwd=2, add=TRUE, yaxt=\"n\")\n\n\n\n\nEl histograma no se parece nada a la curva normal.\n[3 puntos] Repita lo realizado en la parte b., ahora con \\(N=10\\). Comente sobre lo que observa.\n\nreps &lt;- 1000\nn &lt;- 10\np &lt;- 0.3\nv &lt;- p*(1-p)/n\n\nymedias10 &lt;- numeric(reps)\nfor (i in 1:reps){\n sample &lt;- rbernoulli(n, p)\n ymedias10[i]&lt;-mean(sample)\n}\n\nGraficamos junto con una densidad \\(N(0.3, 0.21/10)\\):\n\nhist(ymedias10, breaks=20, prob=TRUE)\ncurve(dnorm(x, mean=p, sd=sqrt(v)), \n      col=\"darkblue\", lwd=2, add=TRUE, yaxt=\"n\")\n\n\n\n\nEl histograma comienza a tener una forma normal. De hecho, se parece ya bastante.\n[3 puntos] Repita lo realizado en la parte b., ahora con \\(N=10,000\\). Comente sobre lo que observa.\n\n#|echo: true\n\nreps &lt;- 1000\nn &lt;- 10000\np &lt;- 0.3\nv &lt;- p*(1-p)/n\n\nymedias10000 &lt;- numeric(reps)\nfor (i in 1:reps){\n sample &lt;- rbernoulli(n, p)\n ymedias10000[i]&lt;-mean(sample)\n}\n\nGraficamos junto con una densidad \\(N(0.3, 0.21/10000)\\):\n\nhist(ymedias10000, breaks=20, prob=TRUE, \n     xlab=\"Medias\")\ncurve(dnorm(x, mean=p, sd=sqrt(v)), \n      col=\"darkblue\", lwd=2, add=TRUE, yaxt=\"n\")\n\n\n\n\nEl histograma se parece ya a la curva normal teórica, con una varianza muy pequeña, con la gran mayoría de las medias concentradas muy cerca del valor esperado.\n[5 puntos] ¿Cómo usaría este ejercicio con palabras simples para explicar a una persona que no sabe mucho de estadística sobre la importancia de los teoremas de límite central?\nUn TLC nos permite hacer afirmaciones sobre la distribución de un estadístico. Un estadístico es un resumen de los datos, por lo que nos interesa usar dichos estadísticos para describir características de los fenómenos que estudiamos usando datos. Queremos saber cosas como lo que esperamos en promedio que suceda con una variable, o qué tanta variabilidad dicha variable tendrá en la población. Con un TLC podemos hacer afirmaciones sobre cómo lucen promedios muestrales de la variable que estudiamos cuando tenemos suficientes observaciones. Nos dice en particular que va a tener una distribución normal.\n\n\n\n\nUse los datos en el archivo motral2012.csv, que incluye una muestra de individuos con sus características socioeconómicas. Nos interesa conocer los factores que afectan la probabilidad de que los individuos tengan ahorros. Considere lo siguiente sobre las opciones de ahorro de los entrevistados, contenida en la variable p14:\n\np14 igual a 1 significa cuentas de ahorro bancarias\np14 igual a 2 significa cuenta de inversión bancaria\np14 igual a 3 significa inversiones en bienes raíces\np14 igual a 4 significa caja de ahorro en su trabajo\np14 igual a 5 significa caja de ahorro con sus amigos\np14 igual a 6 significa tandas\np14 igual a 7 significa que ahorra en su casa o alcancías\np14 igual a 8 significa otro lugar\np14 NA significa que no ahorra\n\n\n[2 puntos] Comience generando una variable binaria ahorra que tome el valor de 1 para las personas que ahorran y 0 en otro caso. Construya también la variable mujer que tome el valor de 1 cuando sex toma el valor de 2 y 0 en otro caso.\nGeneramos variables:\n\ndata.financiero &lt;- read_csv(\"../files/motral2012.csv\",\n                          locale = locale(encoding = \"latin1\")) %&gt;%\n  clean_names() %&gt;% \n  mutate(ahorra = ifelse(is.na(p14), 0, 1),\n         mujer=ifelse(sex==2,1,0))\n\n[3 puntos] Estime un modelo de probabilidad lineal que relacione ahorra como variable dependiente con eda (edad), anios_esc (años de escolaridad) y mujer. Reporte los errores que asumen homocedasticidad y los errores robustos a heteroscedasticidad.\nEstimamos el modelo lineal y obtenemos la matriz de varianzas robusta usando vcovHC:\n\nsummary(reg.lineal &lt;- lm(ahorra ~ eda + anios_esc + mujer,\n                         data = data.financiero))\n\n\nCall:\nlm(formula = ahorra ~ eda + anios_esc + mujer, data = data.financiero)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9816 -0.4626 -0.2984  0.4947  0.8254 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.4559531  0.0303390  15.029  &lt; 2e-16 ***\neda         -0.0049494  0.0006541  -7.567  4.5e-14 ***\nanios_esc    0.0174601  0.0014516  12.028  &lt; 2e-16 ***\nmujer       -0.0140326  0.0134973  -1.040    0.299    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4892 on 5260 degrees of freedom\nMultiple R-squared:  0.04033,    Adjusted R-squared:  0.03978 \nF-statistic: 73.69 on 3 and 5260 DF,  p-value: &lt; 2.2e-16\n\n#Matriz robusta\nv_rob &lt;- vcovHC(reg.lineal, type = \"HC0\")\nse_rob    &lt;- sqrt(diag(v_rob))\n\nPresentamos usando stargazer, aunque pueden usar el paquete de su preferencia. Por ejemplo, quizás quieran darle una revisada a modelsummary.\nstargazer(reg.lineal, reg.lineal,\n          se = list(NULL, se_rob),\n          digits = 4,\n          type = 'html')\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nahorra\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\neda\n\n\n-0.0049***\n\n\n-0.0049***\n\n\n\n\n\n\n(0.0007)\n\n\n(0.0007)\n\n\n\n\n\n\n\n\n\n\n\n\nanios_esc\n\n\n0.0175***\n\n\n0.0175***\n\n\n\n\n\n\n(0.0015)\n\n\n(0.0024)\n\n\n\n\n\n\n\n\n\n\n\n\nmujer\n\n\n-0.0140\n\n\n-0.0140\n\n\n\n\n\n\n(0.0135)\n\n\n(0.0135)\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n0.4560***\n\n\n0.4560***\n\n\n\n\n\n\n(0.0303)\n\n\n(0.0385)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n5,264\n\n\n5,264\n\n\n\n\nR2\n\n\n0.0403\n\n\n0.0403\n\n\n\n\nAdjusted R2\n\n\n0.0398\n\n\n0.0398\n\n\n\n\nResidual Std. Error (df = 5260)\n\n\n0.4892\n\n\n0.4892\n\n\n\n\nF Statistic (df = 3; 5260)\n\n\n73.6878***\n\n\n73.6878***\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n[3 puntos] ¿Cuál es el efecto en la probabilidad de ahorrar si los años de educación se incrementan en una unidad, pasando de 3 a 4 años de educación?\nEn un modelo lineal esto es simplemente un incremento en 1.75 puntos porcentuales.\n[4 puntos] Realice una prueba de significancia conjunta de eda y anios_esc. ¿Qué concluye?\nPodemos usar la función linearHypothesis:\n\ncar::linearHypothesis(reg.lineal, c(\"eda=0\", \"anios_esc=0\"))\n\nLinear hypothesis test\n\nHypothesis:\neda = 0\nanios_esc = 0\n\nModel 1: restricted model\nModel 2: ahorra ~ eda + anios_esc + mujer\n\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1   5262 1311.5                                  \n2   5260 1258.9  2    52.597 109.88 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nConcluimos que no hay evidencia para afirmar que \\(\\beta_{eda}=\\beta_{anios\\_esc}=0\\).\n[4 puntos] Estime un modelo probit relacionando las mismas variables. Use la función avg_slopes del paquete marginaleffects para obtener los efectos marginales promedio de un cambio en cada uno de los regresores. ¿Por qué difiere la magnitud de este efecto marginal con respecto a la parte c.?\nEstimamos el modelo probit:\n\nreg.probit &lt;- glm(ahorra ~ eda + anios_esc + mujer,\n                  family = binomial(link = \"probit\"),\n                  data = data.financiero)\n\nsummary(reg.probit)$coef\n\n               Estimate  Std. Error   z value     Pr(&gt;|z|)\n(Intercept) -0.18770947 0.083351859 -2.252013 2.432145e-02\neda         -0.01258123 0.001703646 -7.384884 1.525863e-13\nanios_esc    0.05130108 0.004480285 11.450404 2.340518e-30\nmujer       -0.04077164 0.035053348 -1.163131 2.447763e-01\n\n\nNoten que el signo de los coeficientes coinciden con el promedio de los efectos marginales:\n\navg_slopes(reg.probit)\n\n\n      Term Contrast Estimate Std. Error     z Pr(&gt;|z|)     S    2.5 %   97.5 %\n anios_esc    dY/dX  0.01977   0.001659 11.91   &lt;0.001 106.3  0.01651  0.02302\n eda          dY/dX -0.00485   0.000646 -7.50   &lt;0.001  43.9 -0.00611 -0.00358\n mujer        1 - 0 -0.01571   0.013504 -1.16    0.245   2.0 -0.04218  0.01076\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nEl promedio del efecto marginal de un cambio en los años de educación es de 2 puntos porcentuales. Ligeramente superior al efecto obtenido en el modelo lineal.\n[4 puntos] Ahora estime el efecto marginal en la media para eda y anios_esc y para las mujeres, usando la función slopes. ¿Por qué difiere la magnitud de este efecto marginal respecto a la parte c. y la d.?\nPara obtener los efectos marginales evaluados en algun valor \\(X_i\\) de los covariables, debemos especificar estos valores usando datagrid:\n\navg_slopes(reg.probit,\n           newdata = datagrid(eda = mean(data.financiero$eda),\n                              anios_esc = mean(data.financiero$anios_esc),\n                              mujer = 1))\n\n\n      Term Contrast Estimate Std. Error     z Pr(&gt;|z|)    S    2.5 %   97.5 %\n anios_esc    dY/dX   0.0204   0.001779 11.46   &lt;0.001 98.5  0.01689  0.02386\n eda          dY/dX  -0.0050   0.000677 -7.38   &lt;0.001 42.5 -0.00632 -0.00367\n mujer        1 - 0  -0.0162   0.013944 -1.16    0.245  2.0 -0.04355  0.01111\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nEl efecto marginal de un cambio en los años de escolaridad evaluados en la media de los años de educación y edad, para las mujeres, es de 2.04 puntos. Esto difiere del modelo lineal porque en el modelo lineal los efectos marginales son constantes, mientras que los efectos marginal del modelo no lineal dependen del punto de evaluación. También difiere de los efectos marginales promedio pues aquí solo hemos calculado el efecto marginal una sola vez, para un valor \\(X_i\\), mientras que el promedio de efectos marginales implica calcular el efecto marginal para cada individuo y luego obtener el promedio.\nEn clase les pregunté cómo estimarían el error estándar de los cambios marginales y brevemente mencioné que una forma muy usada es el Método Delta, el cual se basa en que los efectos marginales son funciones no lineales de los parámetros. Esto es lo que efectivamente se usa en la función avg_slopes para obtener los errores estándar y los intervalos de confianza. Aquí pueden leer al respecto.\n\n\n\n\nAhora estimará un modelo multinomial empleando los mismos datos en motral2012.csv. El propósito será ahora estudiar los factores relevantes para predecir la forma de ahorro que tienen las personas que ahorran.\n\n[2 punto] Genere una variable categórica llamada ahorro que sea igual a 1 cuando p14 sea igual a 1 o 2, igual a 2 cuando p14 sea igual a 7, e igual a 3 cuando p14 sea igual a 3, 4, 5, 6 u 8. Haga que esa variable sea missing cuando p14 sea missing. Posteriormente, convierta esta nueva variable en una de factores de forma que el valor 1 tenga la etiqueta “Banco”, el valor 2 tenga la etiqueta “Casa” y el valor 3 tenga la etiqueta “Otro”.\nConstruimos la variable dependiente:\n\ndata.financiero &lt;- read_csv(\"../files/motral2012.csv\",\n                            locale = locale(encoding = \"latin1\")) %&gt;%\n  clean_names() %&gt;% \n  mutate(ahorro=NA) %&gt;% \n  mutate(ahorro=ifelse(p14%in%c(1,2),1,ahorro)) %&gt;%\n  mutate(ahorro=ifelse(p14==7,2,ahorro)) %&gt;% \n  mutate(ahorro=ifelse(p14%in%c(3,4,5,6,8),3,ahorro)) %&gt;% \n  mutate(ahorro=factor(ahorro,\n                   levels=c(1,2,3), labels=c(\"Banco\",\"Casa\",\"Otro\"))) %&gt;%\n  mutate(mujer=ifelse(sex==2,1,0))\n\n[4 puntos] Estime un modelo logit multinomial (regresores invariantes a la alternativa) con la opción de ahorro como variable dependiente y los mismos regresores de la pregunta 5. Hay varios paquetes para hacer esto, pero recomiendo usar la función multinom del paquete nnet. ¿Qué puede decir sobre el coeficiente de años de educación en la alternativa “Casa”?\nUsamos multinom para estimar el modelo logit multinomial:\n\nmultilogit &lt;- nnet::multinom(ahorro~ eda + anios_esc + mujer,\n                              data=data.financiero)\n\n# weights:  15 (8 variable)\ninitial  value 2727.854313 \niter  10 value 2546.085070\nfinal  value 2545.712541 \nconverged\n\nsummary(multilogit)\n\nCall:\nnnet::multinom(formula = ahorro ~ eda + anios_esc + mujer, data = data.financiero)\n\nCoefficients:\n     (Intercept)          eda   anios_esc       mujer\nCasa    3.026880 -0.052310196 -0.14829719  0.09265405\nOtro    0.206704 -0.003501367 -0.04628175 -0.06459305\n\nStd. Errors:\n     (Intercept)         eda  anios_esc      mujer\nCasa   0.2487107 0.005207439 0.01355319 0.09956544\nOtro   0.2476498 0.004964123 0.01285100 0.09995715\n\nResidual Deviance: 5091.425 \nAIC: 5107.425 \n\n\nEn el logit multinominal (regresores invariantes) el coeficiente se interpreta con respecto a una categoría base. En este caso, la categoría base es Banco. El modelo implica que la probabilidad de ahorrar en casa disminuye con un año más de educación, en comparación con la probabilidad de ahorrar en el banco. En particular, sabemos que podemos escribir el log del cociente de la probabilidad de las categorías \\(j\\) y \\(k\\) sean escogidas, normalizando \\(k\\) a ser la base, como:\n\\[\\ln\\left(\\frac{P(y=Casa)}{P(y=Banco)}\\right)=x'\\beta=\\beta_0+\\beta_1 edad + \\beta_2 educación + \\beta_3 mujer \\]\nEs decir, un año más de educación se asocia con una reducción en el log de la razón de momios de 0.15.\n[6 puntos] Calcule los efectos marginales promedio sobre la probabilidad de ahorrar en el banco. Al considerar el cambio en la probabilidad para el caso de las mujeres (cuando la variable mujer pasa de 0 a 1), ¿de qué tamaño es el efecto predicho en la probabilidad de ahorrar en el banco?\nUsamos avg_slopes:\n\navg_slopes(multilogit)\n\n\n Group      Term Contrast Estimate Std. Error       z Pr(&gt;|z|)    S    2.5 %\n Banco anios_esc    dY/dX  0.02285   0.002381   9.595   &lt;0.001 70.0  0.01818\n Banco eda          dY/dX  0.00657   0.000935   7.027   &lt;0.001 38.8  0.00474\n Banco mujer        1 - 0 -0.00343   0.019432  -0.177    0.860  0.2 -0.04152\n Casa  anios_esc    dY/dX -0.02512   0.002231 -11.262   &lt;0.001 95.3 -0.02949\n Casa  eda          dY/dX -0.00982   0.000860 -11.422   &lt;0.001 98.0 -0.01151\n Casa  mujer        1 - 0  0.02271   0.017662   1.286    0.199  2.3 -0.01191\n Otro  anios_esc    dY/dX  0.00228   0.002174   1.046    0.295  1.8 -0.00199\n Otro  eda          dY/dX  0.00325   0.000842   3.863   &lt;0.001 13.1  0.00160\n Otro  mujer        1 - 0 -0.01927   0.017549  -1.098    0.272  1.9 -0.05367\n   97.5 %\n  0.02751\n  0.00840\n  0.03465\n -0.02075\n -0.00814\n  0.05732\n  0.00654\n  0.00490\n  0.01512\n\nColumns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  probs \n\n\nEl efecto de ser mujer es de una reducción de 0.3 puntos en la probabilidad de ahorrar en el banco al estimar el promedio de los efectos marginales.\n[4 puntos] Calcule los cocientes de riesgo relativo (relative risk ratios o RRR). ¿Qué significa el hecho de que el RRR asociado a ser mujer sea mayor que 1 en la alternativa “Casa”?\n\n(multilogit_rrr = exp(coef(multilogit)))\n\n     (Intercept)       eda anios_esc     mujer\nCasa   20.632752 0.9490344 0.8621748 1.0970821\nOtro    1.229619 0.9965048 0.9547729 0.9374489\n\n\nLos coeficientes en forma de RRR tienen la interpretación del cambio en el riesgo relativo que una categoría sea elegida con relación al riesgo de escoger la categoría base. En este caso, el ser mujer está asociado con una probabilidad de ahorrar en “Casa” 1.097 veces mayor de que la de ahorrar en “Banco”.\n[4 puntos] Estime nuevamente el modelo, pero ahora, especifique que la alternativa “Casa” sea la alternativa base. ¿Cómo es el RRR de la edad en la alternativa “Banco”? ¿Es esto congruente con lo que obtuvo en la parte d. de esta pregunta?\nPrimero tenemos que cambiar la base. Para esto hacemos uso de que ahorro es una variable de factores. Luego estimamos:\n\ndata.financiero &lt;- data.financiero %&gt;% \n  mutate(ahorro = relevel(ahorro, ref = \"Casa\"))\n\nmultilogit2 &lt;- nnet::multinom(ahorro ~ eda + anios_esc + mujer,\n                              data=data.financiero)\n\n# weights:  15 (8 variable)\ninitial  value 2727.854313 \niter  10 value 2552.696634\nfinal  value 2545.712541 \nconverged\n\n\nObtenemos el RRR:\n\n(multilogit2_rrr = exp(coef(multilogit2)))\n\n      (Intercept)      eda anios_esc     mujer\nBanco  0.04846638 1.053703  1.159857 0.9115111\nOtro   0.05959489 1.050020  1.107401 0.8544952\n\n\nAl cambiar la categoría base a Casa solo se modifica la interpretación relativa. En la parte d. el RRR de la edad para la opción de Casa era 0.949, es decir, si la edad se incrementa en una unidad, la probabilidad de ahorrar en Casa es 0.949 veces la de ahorrar en Banco. Con la nueva categoría base, el RRR de la edad para ahorrar en Banco es 1.054, es decir, si la edad se incrementa en un año, la probabilidad de ahorrar en Banco es 1.054 veces más probable que la probabilidad de ahorrar en Casa. La parte d. implica que \\(P(Casa)=0.949(Banco)\\). Mientras que estimando el modelo con la nueva categoría, \\(P(Banco)=1.054(Casa)\\), o \\(P(Casa)=1/1.054(Banco)\\). Empleando todos los decimales en R se puede notar que 1/1.054≅0.949 Ambos resultados son consistentes."
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-1",
    "href": "tareas/tarea-1-respuestas.html#pregunta-1",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Suponga que está interesado en una variable aleatoria que tiene una distribución Bernoulli con parámetro \\(p\\). La función de densidad está definida como:\n\\[f(x_;p)=\\left\\{\\begin{array} .1 & \\text{con probabilidad } p \\\\ 0 & \\text{con probabilidad } 1-p \\end{array} \\right.\\] Suponga que tiene una muestra de \\(N\\) observaciones independientes e idénticamente distribuidas.\n\n[4 puntos] Plantee la función de log verosimilitud del problema.\nPodemos escribir la función de densidad para la \\(i\\)-ésima observación como\n\\[f(x_i;p)=p^{x_i}(1-p)^{(1-x_i)}\\]\nPor tanto, la función de verosimilitud es\n\\[L_N(p)=\\prod_{i=1}^N f(x;p)=\\prod_{i=1}^N p^{x_i}(1-p)^{(1-x_i)} = p^{\\sum_{i=1}^N x_i}(1-p)^{N-\\sum_{i=1}^N x_i}\\]\nY la función de log verosimilitud será\n\\[\\mathcal{L_N(p)}=\\ln{L_N(p)}=\\sum x_i \\ln(p)-(N-\\sum x_i)\\ln(1-p)\\]\n[4 puntos] Obtenga las condiciones de primer orden y resuelva para \\(\\hat{p}\\).\nDerivando \\(\\mathcal{L}_N\\) con respecto a \\(p\\) obtenemos la condición de primer orden:\n\\[\\frac{d\\mathcal{L}_N(p)}{d p}=\\frac{\\sum x_i}{p}-\\frac{N-\\sum x_i}{1-p}=0\\]\nY resolviendo, obtenemos el estimador de máxima verosimilitud \\[\\hat{p}_{MV}=\\bar{x}\\] es decir, la media muestral.\n[2 puntos] ¿Cuál es la media y la varianza del estimador de máxima verosimilitud que ha encontrado?\nObtenemos directamente la media \\[E(\\hat{p}_{MV})=E(\\bar{x})=\\frac{1}{N}E\\left(\\sum x_i\\right)=\\frac{1}{N}N p=p\\]\nMientras que la varianza es \\[V(\\hat{p}_{MV})=\\frac{1}{N^2}V\\left(\\sum x_i\\right)=\\frac{p(1-p)}{N}\\]"
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-2",
    "href": "tareas/tarea-1-respuestas.html#pregunta-2",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Suponga que \\(y_i|\\mathbf{x}_i\\sim\\mathcal{N}(m(\\mathbf{x}_i,\\mathbf{\\beta}_0),\\sigma_0^2)\\), donde \\(m(\\mathbf{x},\\mathbf{\\beta})\\) es una función del vector de variables explicativas \\(\\mathbf{x}\\) y del vector de parámetros \\(\\mathbf{\\beta}\\) de dimensión \\((k\\times 1)\\). Entonces, \\(E(y_i|\\mathbf{x}_i)=m(\\mathbf{x}_i,\\mathbf{\\beta}_0)\\) y \\(V(y_i|\\mathbf{x}_i)=\\sigma^2_0\\).\n\n[2 puntos] Escriba la función de log verosimilitud condicional para la observación \\(i\\). Muestre que el estimador de máxima verosimilitud \\(\\hat{\\mathbf{\\beta}}\\) resuelve el problema de minimización \\(\\min_\\mathbf{\\beta}\\sum_i(y_i-m(\\mathbf{x}_i,\\mathbf{\\beta}))^2\\).\nLa densidad de la \\(i\\)ésima observación es:\n\\[f(y|x_i)=\\frac{1}{\\sqrt{2\\pi\\sigma^2_0}}exp\\left(-\\frac{1}{2\\sigma^2_0}(y-m(x_i,\\beta))^2\\right)\\]\nPor tanto, la log verosimilitud para \\(i\\) es:\n\\[\n\\mathcal{l}_i(\\beta,\\sigma^2)=-\\frac{1}{2}\\ln(2\\pi)-\\frac{1}{2}\\ln(\\sigma^2)-\\frac{1}{2\\sigma^2}(y_i-m(x_i,\\beta))^2\n\\]\nDado que solo la última parte de este problema depende de \\(\\beta\\), y siendo \\(\\sigma^2&gt;0\\), el problema de maximizar \\(\\sum_i\\mathcal{l}_i(\\beta,\\sigma^2)\\) es igual a maximizar \\(\\sum_i(y_i-m(x_i,\\beta))^2\\).\n[4 puntos] Sea \\(\\mathbf{\\theta}\\equiv(\\mathbf{\\beta}'\\;\\sigma^2)'\\) un vector de parámetros de dimensión \\((k+1)\\times 1\\). Encuentre el vector score para la observación \\(i\\). Muestre que \\(E(\\mathbf{s}_i(\\mathbf{\\theta}_0)|\\mathbf{x}_i)=\\mathbf{0}\\).\nEl vector score es el vector de primeras derivadas parciales de la log verosimilitud. Las derivadas parciales son:\n\\[\n\\begin{aligned} \\frac{\\partial \\mathcal{l}_i}{\\partial\\beta}&=\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'\\frac{(y_i-m(x_i,\\beta))}{\\sigma^2} \\\\ \\frac{\\partial \\mathcal{l}_i}{\\partial\\sigma^2}&= -\\frac{1}{2\\sigma^2}+\\frac{1}{2\\sigma^4}(y_i-m(x_i,\\beta))^2\\end{aligned}\n\\]\nNoten que \\(\\left(\\frac{\\partial \\mathcal{l}_i}{\\partial\\beta}\\right)'\\) es un vector de \\(1\\times k\\). Podemos escribir el score como:\n\\[s_i(\\beta,\\sigma^2)=\n\\begin{pmatrix}\n\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\frac{(y_i-m(x_i,\\beta))}{\\sigma^2} \\\\\n-\\frac{1}{2\\sigma^2}+\\frac{1}{2\\sigma^4}(y_i-m(x_i,\\beta))^2 \\\\\n\\end{pmatrix}\\]\nDado que \\(E(y_i|x_i)=m(x_i,\\beta)\\),los primeros \\(k\\) términos del score tienen esperanza 0. Entonces, nos resta comprobar la última entrada. Calculando el valor esperado del segundo sumando de la última entrada:\n\\[E((y_i-m(x_i,\\beta))^2)=E((y_i-E(y_i|x_i))^2)=V(y_i|x_i)=\\sigma^2\\]\nlo que hace que la última entrada del vector score también tenga esperanza 0.\n[2 puntos] Usando las condiciones de primer orden, encuentre \\(\\hat{\\sigma}^2\\) en términos de \\(\\hat{\\mathbf{\\beta}}\\).\nLa condición de primer orden con respecto a \\(\\sigma^2\\) es\n\\[\\sum_i \\left(-\\frac{1}{2\\sigma^2}+\\frac{1}{2\\sigma^4}(y_i-m(x_i,\\beta))^2\\right)\\]\nResolviendo para \\(\\sigma^2\\) obtenemos:\n\\[\\hat{\\sigma}^2=\\frac{1}{N}\\sum_i (y_i-m(x_i,\\hat{\\beta}))^2\\]\n[5 puntos] Encuentre la matriz hesiana de la función de log verosimilitud con respecto a \\(\\mathbf{\\theta}\\).\nProcedemos a derivar el score, primero con respecto a \\(\\beta\\) y luego con respecto a \\(\\sigma^2\\).\n\n\\(\\frac{\\partial}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\frac{(y_i-m(x_i,\\beta))}{\\sigma^2}\\right)=-\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'+\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta\\partial\\beta}(y_i-m(x_i,\\beta))\\)\n\\(\\frac{\\partial}{\\partial\\sigma^2}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\frac{(y_i-m(x_i,\\beta))}{\\sigma^2}\\right)=-\\frac{1}{\\sigma^4}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}(y_i-m(x_i,\\beta))\\)\n\\(\\frac{\\partial}{\\partial\\beta}\\left( -\\frac{1}{2\\sigma^2}+\\frac{1}{2\\sigma^4}(y_i-m(x_i,\\beta))^2\\right)=-\\frac{1}{\\sigma^4}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'(y_i-m(x_i,\\beta))\\)\n\\(\\frac{\\partial}{\\partial\\sigma^2}\\left( -\\frac{1}{2\\sigma^2}+\\frac{1}{2\\sigma^4}(y_i-m(x_i,\\beta))^2\\right)=\\frac{1}{2\\sigma^4}-\\frac{1}{\\sigma^6}(y-m(x_i,\\beta))^2\\)\n\nPor lo que la matriz Hessiana es:\n\\[\n  H_i(\\beta,\\sigma^2)=\n  \\begin{pmatrix}\n  -\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'+\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta\\partial\\beta}(y_i-m(x_i,\\beta)) & -\\frac{1}{\\sigma^4}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}(y_i-m(x_i,\\beta)) \\\\ -\\frac{1}{\\sigma^4}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'(y_i-m(x_i,\\beta)) & \\frac{1}{2\\sigma^4}-\\frac{1}{\\sigma^6}(y-m(x_i,\\beta))^2 \\\\\n  \\end{pmatrix}\n\\]\n[5 puntos] Muestre que \\(-E(\\mathbf{H}_i(\\mathbf{\\theta}_0)|\\mathbf{x}_i)=E(\\mathbf{s}_i(\\mathbf{\\theta}_0)\\mathbf{s}_i(\\mathbf{\\theta}_0)'|\\mathbf{x}_i)\\).\nPrimero mostramos el valor esperado de cada entrada de la matriz hessiana. En la parte b. mostramos que \\(E(y-m(x_i,\\beta))=0\\), por lo que los elementos fuera de la diagonal principal tiene expectativa cero.\nPor la misma razón:\n\\[\n\\begin{aligned}\n& E\\left(-\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'+\\frac{1}{\\sigma^2}\\frac{\\partial  m(x,\\beta)}{\\partial\\beta\\partial\\beta}(y_i-m(x_i,\\beta))\\right) = \\\\\n& -\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'\n\\end{aligned}\n\\]\nEl último término usa lo que hemos mostrado antes, \\(E((y_i-m(x_i,\\beta))^2)=\\sigma^2\\). Por tanto:\n\\[\nE\\left(\\frac{1}{2\\sigma^4}-\\frac{1}{\\sigma^6}(y-m(x_i,\\beta))^2\\right)=-\\frac{1}{2\\sigma^4}\n\\]\nEntonces obtenemos un primer resultado:\n\\[\n-E(H_i(\\beta,\\sigma^2)|x_i)=\n\\begin{pmatrix}\n\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)' & 0 \\\\\n0 & \\frac{1}{2\\sigma^4}\\\\\n\\end{pmatrix}\n\\]\nTenemos que mostrar que el valor esperado del producto exterior del score es igual a lo que acabamos de encontrar. Calculamos el valor esperado del producto exterior del score:\n\\[E(s(\\beta,\\sigma^2)s(\\beta,\\sigma^2)'|x_i)=E\\left(\\begin{pmatrix} A & B \\\\ B & C \\end{pmatrix}\\Bigg|x_i\\right)\\].\nEl bloque superior de la matriz resultante es \\(E(A)\\):\n\\[\n\\begin{aligned}\nE(A)&=\n\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'\\frac{(y_i-m(x_i,\\beta))^2}{\\sigma^4} \\\\\n&=\\frac{1}{\\sigma^2}\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'\n\\end{aligned}\n\\]\nEl término \\(B\\) es:\n\\[E(B)=-\\frac{1}{2\\sigma^4}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'(y-m(x_i,\\beta))+\\frac{1}{2\\sigma^6}\\left(\\frac{\\partial m(x,\\beta)}{\\partial\\beta}\\right)'(y-m(x_i,\\beta))^3\\]\nEste término tiene valor esperado cero porque para una variable aleatoria normal \\(X\\) con media cero, sucede que \\(E(X^n)=0\\) cuando \\(n\\) es impar.\nY finalmente, el término \\(E(C)\\) será:\n\\[\n\\begin{aligned}\nC&=\nE\\left(-\\frac{1}{2\\sigma^2}+\\frac{1}{2\\sigma^4}(y_i-m(x_i,\\beta))^2\\right)\\\\\n&=E\\left(\\frac{1}{4\\sigma^8}(y-m(x_i,\\beta))^4-\\frac{1}{2\\sigma^6}(y-m(x_i,\\beta))^2+\\frac{1}{4\\sigma^4}\\right) \\\\\n&=E\\left(\\frac{1}{4\\sigma^8}(y-m(x_i,\\beta))^4\\right)-\\frac{1}{2\\sigma^4}+\\frac{1}{4\\sigma^4}\n\\end{aligned}\n\\]\nPara una variable aleatoria \\(X\\sim \\mathcal{N}(0, \\sigma^2)\\), sucede que \\(E(X^4)=3\\sigma^4\\). Entonces:\n\\[\n\\begin{aligned}\nC&=\\frac{3\\sigma^4}{4\\sigma^8}-\\frac{1}{2\\sigma^4}+\\frac{1}{4\\sigma^4} \\\\\n& =\\frac{1}{2\\sigma^4}\n\\end{aligned}\n\\]\n[2 puntos] Encuentre la varianza asintótica estimada de \\(\\hat{\\mathbf{\\beta}}\\) y explique cómo obtendría los errores estándar.\nPor los resultados generales de MV vistos en clase, sabemos que la varianza asintótica está dada por \\(E(A_i(\\theta))^{-1}\\), donde \\(A_i(\\theta)=-E(H_i(\\theta))\\), obtenida en la parte e (no confundir con \\(A\\) del punto anterior, usada para simplificar la presentación de los cálculos sobre el producto exterior del score). Un extimador para la matriz de varianzas es entonces:\n\\[\n\\hat{V}(\\hat{\\beta})=\\hat{\\sigma}^2\\left(\\sum_i\\frac{\\partial m(x_i,\\hat{\\beta})}{\\partial\\beta}\\left(\\frac{\\partial m(x_i,\\hat{\\beta})}{\\partial\\beta}\\right)'\\right)^{-1}\n\\]\nEl error estándar del \\(j\\)ésimo regresor estimado es simplemente la raíz cuadrada de la \\(j\\)ésima entrada en la diagonal principal de \\(\\hat{V}(\\hat{\\beta})\\)."
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-3",
    "href": "tareas/tarea-1-respuestas.html#pregunta-3",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Suponga una variable aleatoria \\(X_i\\) con distribución desconocida. Sin embargo, sí conocemos que \\(E(X)=\\mu=54\\) y que \\(\\sqrt{V(X)}=\\sigma=6\\). Suponga que se recolecta una muestra de 50 observaciones.\n\n[2 punto] ¿Cuál es la distribución asintótica de la media muestral \\(\\bar{X}\\)?\nSi se puede aplicar un teorema de límite central a la media muestral, sabemos que la nueva variable hereda la media de \\(X_i\\) y la desviación estándar es la desviación estándar de \\(X_i\\) dividida por la raíz del tamaño de la muestra. Es decir:\n\\[\\bar{X}\\sim \\mathcal{N}(54, 6^2/50)\\]\n[4 punto] ¿Cuál es la probabilidad de que \\(\\bar{X}&gt;58\\)?\nSabemos que \\(\\frac{\\bar{X}-54}{6/\\sqrt{50}}\\sim\\mathcal{N}(0,1)\\), por tanto:\n\\[P(\\bar{X}&gt;58)=P\\left(z&gt;\\frac{58-54}{6/\\sqrt{50}}\\right)=P(z&gt;4.714045)=1-\\Phi(4.714045)\\]\nCalculamos la probabilidad usando pnorm, que nos da la función de distribución. La probabilidad es un número muy pequeño:\n\n1-pnorm((58-54)/(6/sqrt(50)), mean = 0, sd = 1)\n\n[1] 1.214234e-06\n\n\n[2 punto] ¿Cuál es la probabilidad de que una observación elegida al azar sea tal que \\(X_i&gt;58\\)?\nEs imposible de determinar porque no sabemos la distribución de \\(X_i\\). Esto es algo muy conveniente de los TLC, pues nos permiten hacer afirmaciones sobre la media muestral sin saber la distribución de la que provienen las observaciones. Solo necesitamos que se cumplan las condiciones sobre las \\(X_i\\) para aplicar los TLC.\n[2 punto] Provea un intervalo de confianza de 99% para la media muestral.\nPor un lado, sabemos que la variable aleatoria \\(Z=\\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{N}}\\) tendrá una distribución \\(\\mathcal{N}(0,1)\\). Por otro lado, queremos obtener \\(P(-z_{\\alpha/2}&lt;Z&lt;z_{\\alpha/2})=0.99\\). Manipulando, obtenemos una expresión para el intervalo de confianza:\n\\[\\left(\\bar{X}-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{N}},\\bar{X}+z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{N}}\\right)\\]\nEn nuestro caso, el intervalo es:\n\\[P\\left(\\bar{X}\\pm 2.5758\\times(6/\\sqrt{50})\\right)=0.99\\]\ndonde obtenemos el 2.5758 como:\n\nqnorm(0.995)\n\n[1] 2.575829\n\n\nqnorm es la función cuantil y está definida como la función inversa de la función de distribución. La función cuantil da el valor de \\(x\\) tal que \\(F(x)=P(X \\leq x)=p\\).\nEntonces, el intervalo de confianza es: \\[P(\\bar{X}\\pm 2.185664)=0.99\\]"
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-4",
    "href": "tareas/tarea-1-respuestas.html#pregunta-4",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "En esta pregunta mostraremos los alcances de los teoremas del límite central. Para esto, generaremos muchas muestras de tamaño \\(N\\) con una distribución \\(Bernoulli\\) con probabilidad de éxito \\(p=0.3\\). Recuerde que cuando realice simulaciones, siempre debe fijar una semilla al inicio para poder replicar su trabajo.\n\n[2 puntos] ¿Cuál es la media y la varianza de una variable aleatoria \\(y_i \\sim Bernoulli(0.3)\\)?\nPara una variable que se distribuye \\(Bernoulli(p)\\), la media es \\(p\\) y la varianza es \\(p(1-p)\\). Para este caso, \\(E(y_i)=0.3\\) y \\(V(y_i)=0.3*0.7=0.21\\).\n[2 puntos] Si \\(y_i\\) son iid y podemos aplicar un teorema de límite central, ¿cuál es la distribución teórica de \\(\\bar{y}\\) cuando \\(N\\to\\infty\\)?\nObtenemos el valor esperado y la varianza de \\(\\bar{y}\\):\n\\[E(\\bar{y})=\\frac{1}{N}E(\\sum_i y_i)  = E(y_i)=p\\]\n\\[V(\\bar{y})=\\frac{1}{N^2}V(\\sum_i y_i) = \\frac{1}{N}V(y_i)=\\frac{p(1-p)}{N}\\]\nEntonces, un TLC nos daría las condiciones para que:\n\\[\\frac{\\bar{y}-0.3}{0.21/N}\\sim\\mathcal{N}(0, 1)\\]\n[5 puntos] Realice el siguiente procedimiento \\(J=1,000\\) veces. Obtenga una muestra de tamaño \\(N=2\\) a partir de la distribución \\(Bernoulli(0.3)\\) y calcule la media muestral \\(\\bar{y}\\). Coleccione las \\(J\\) medias muestrales y luego grafique un histograma de las medias muestrales obtenidas junto con una curva teórica normal con la media y varianza obtenida en la parte b. Comente sobre lo que observa.\n\nset.seed(820)\nreps &lt;- 1000\nn &lt;- 2\np &lt;- 0.3\nv &lt;- p*(1-p)/n\n\nymedias2 &lt;- numeric(reps)\nfor (i in 1:reps){\n sample &lt;- rbernoulli(n, p)\n ymedias2[i]&lt;-mean(sample)\n}\n\nGraficamos junto con una densidad \\(N(0.3, 0.21/2)\\):\n\nhist(ymedias2, breaks=20, prob=TRUE, \n     xlab=\"Medias\")\ncurve(dnorm(x, mean=p, sd=sqrt(v)), \n      col=\"darkblue\", lwd=2, add=TRUE, yaxt=\"n\")\n\n\n\n\nEl histograma no se parece nada a la curva normal.\n[3 puntos] Repita lo realizado en la parte b., ahora con \\(N=10\\). Comente sobre lo que observa.\n\nreps &lt;- 1000\nn &lt;- 10\np &lt;- 0.3\nv &lt;- p*(1-p)/n\n\nymedias10 &lt;- numeric(reps)\nfor (i in 1:reps){\n sample &lt;- rbernoulli(n, p)\n ymedias10[i]&lt;-mean(sample)\n}\n\nGraficamos junto con una densidad \\(N(0.3, 0.21/10)\\):\n\nhist(ymedias10, breaks=20, prob=TRUE)\ncurve(dnorm(x, mean=p, sd=sqrt(v)), \n      col=\"darkblue\", lwd=2, add=TRUE, yaxt=\"n\")\n\n\n\n\nEl histograma comienza a tener una forma normal. De hecho, se parece ya bastante.\n[3 puntos] Repita lo realizado en la parte b., ahora con \\(N=10,000\\). Comente sobre lo que observa.\n\n#|echo: true\n\nreps &lt;- 1000\nn &lt;- 10000\np &lt;- 0.3\nv &lt;- p*(1-p)/n\n\nymedias10000 &lt;- numeric(reps)\nfor (i in 1:reps){\n sample &lt;- rbernoulli(n, p)\n ymedias10000[i]&lt;-mean(sample)\n}\n\nGraficamos junto con una densidad \\(N(0.3, 0.21/10000)\\):\n\nhist(ymedias10000, breaks=20, prob=TRUE, \n     xlab=\"Medias\")\ncurve(dnorm(x, mean=p, sd=sqrt(v)), \n      col=\"darkblue\", lwd=2, add=TRUE, yaxt=\"n\")\n\n\n\n\nEl histograma se parece ya a la curva normal teórica, con una varianza muy pequeña, con la gran mayoría de las medias concentradas muy cerca del valor esperado.\n[5 puntos] ¿Cómo usaría este ejercicio con palabras simples para explicar a una persona que no sabe mucho de estadística sobre la importancia de los teoremas de límite central?\nUn TLC nos permite hacer afirmaciones sobre la distribución de un estadístico. Un estadístico es un resumen de los datos, por lo que nos interesa usar dichos estadísticos para describir características de los fenómenos que estudiamos usando datos. Queremos saber cosas como lo que esperamos en promedio que suceda con una variable, o qué tanta variabilidad dicha variable tendrá en la población. Con un TLC podemos hacer afirmaciones sobre cómo lucen promedios muestrales de la variable que estudiamos cuando tenemos suficientes observaciones. Nos dice en particular que va a tener una distribución normal."
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-5",
    "href": "tareas/tarea-1-respuestas.html#pregunta-5",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Use los datos en el archivo motral2012.csv, que incluye una muestra de individuos con sus características socioeconómicas. Nos interesa conocer los factores que afectan la probabilidad de que los individuos tengan ahorros. Considere lo siguiente sobre las opciones de ahorro de los entrevistados, contenida en la variable p14:\n\np14 igual a 1 significa cuentas de ahorro bancarias\np14 igual a 2 significa cuenta de inversión bancaria\np14 igual a 3 significa inversiones en bienes raíces\np14 igual a 4 significa caja de ahorro en su trabajo\np14 igual a 5 significa caja de ahorro con sus amigos\np14 igual a 6 significa tandas\np14 igual a 7 significa que ahorra en su casa o alcancías\np14 igual a 8 significa otro lugar\np14 NA significa que no ahorra\n\n\n[2 puntos] Comience generando una variable binaria ahorra que tome el valor de 1 para las personas que ahorran y 0 en otro caso. Construya también la variable mujer que tome el valor de 1 cuando sex toma el valor de 2 y 0 en otro caso.\nGeneramos variables:\n\ndata.financiero &lt;- read_csv(\"../files/motral2012.csv\",\n                          locale = locale(encoding = \"latin1\")) %&gt;%\n  clean_names() %&gt;% \n  mutate(ahorra = ifelse(is.na(p14), 0, 1),\n         mujer=ifelse(sex==2,1,0))\n\n[3 puntos] Estime un modelo de probabilidad lineal que relacione ahorra como variable dependiente con eda (edad), anios_esc (años de escolaridad) y mujer. Reporte los errores que asumen homocedasticidad y los errores robustos a heteroscedasticidad.\nEstimamos el modelo lineal y obtenemos la matriz de varianzas robusta usando vcovHC:\n\nsummary(reg.lineal &lt;- lm(ahorra ~ eda + anios_esc + mujer,\n                         data = data.financiero))\n\n\nCall:\nlm(formula = ahorra ~ eda + anios_esc + mujer, data = data.financiero)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-1.9816 -0.4626 -0.2984  0.4947  0.8254 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.4559531  0.0303390  15.029  &lt; 2e-16 ***\neda         -0.0049494  0.0006541  -7.567  4.5e-14 ***\nanios_esc    0.0174601  0.0014516  12.028  &lt; 2e-16 ***\nmujer       -0.0140326  0.0134973  -1.040    0.299    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4892 on 5260 degrees of freedom\nMultiple R-squared:  0.04033,    Adjusted R-squared:  0.03978 \nF-statistic: 73.69 on 3 and 5260 DF,  p-value: &lt; 2.2e-16\n\n#Matriz robusta\nv_rob &lt;- vcovHC(reg.lineal, type = \"HC0\")\nse_rob    &lt;- sqrt(diag(v_rob))\n\nPresentamos usando stargazer, aunque pueden usar el paquete de su preferencia. Por ejemplo, quizás quieran darle una revisada a modelsummary.\nstargazer(reg.lineal, reg.lineal,\n          se = list(NULL, se_rob),\n          digits = 4,\n          type = 'html')\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nahorra\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\neda\n\n\n-0.0049***\n\n\n-0.0049***\n\n\n\n\n\n\n(0.0007)\n\n\n(0.0007)\n\n\n\n\n\n\n\n\n\n\n\n\nanios_esc\n\n\n0.0175***\n\n\n0.0175***\n\n\n\n\n\n\n(0.0015)\n\n\n(0.0024)\n\n\n\n\n\n\n\n\n\n\n\n\nmujer\n\n\n-0.0140\n\n\n-0.0140\n\n\n\n\n\n\n(0.0135)\n\n\n(0.0135)\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n0.4560***\n\n\n0.4560***\n\n\n\n\n\n\n(0.0303)\n\n\n(0.0385)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n5,264\n\n\n5,264\n\n\n\n\nR2\n\n\n0.0403\n\n\n0.0403\n\n\n\n\nAdjusted R2\n\n\n0.0398\n\n\n0.0398\n\n\n\n\nResidual Std. Error (df = 5260)\n\n\n0.4892\n\n\n0.4892\n\n\n\n\nF Statistic (df = 3; 5260)\n\n\n73.6878***\n\n\n73.6878***\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\n[3 puntos] ¿Cuál es el efecto en la probabilidad de ahorrar si los años de educación se incrementan en una unidad, pasando de 3 a 4 años de educación?\nEn un modelo lineal esto es simplemente un incremento en 1.75 puntos porcentuales.\n[4 puntos] Realice una prueba de significancia conjunta de eda y anios_esc. ¿Qué concluye?\nPodemos usar la función linearHypothesis:\n\ncar::linearHypothesis(reg.lineal, c(\"eda=0\", \"anios_esc=0\"))\n\nLinear hypothesis test\n\nHypothesis:\neda = 0\nanios_esc = 0\n\nModel 1: restricted model\nModel 2: ahorra ~ eda + anios_esc + mujer\n\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1   5262 1311.5                                  \n2   5260 1258.9  2    52.597 109.88 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nConcluimos que no hay evidencia para afirmar que \\(\\beta_{eda}=\\beta_{anios\\_esc}=0\\).\n[4 puntos] Estime un modelo probit relacionando las mismas variables. Use la función avg_slopes del paquete marginaleffects para obtener los efectos marginales promedio de un cambio en cada uno de los regresores. ¿Por qué difiere la magnitud de este efecto marginal con respecto a la parte c.?\nEstimamos el modelo probit:\n\nreg.probit &lt;- glm(ahorra ~ eda + anios_esc + mujer,\n                  family = binomial(link = \"probit\"),\n                  data = data.financiero)\n\nsummary(reg.probit)$coef\n\n               Estimate  Std. Error   z value     Pr(&gt;|z|)\n(Intercept) -0.18770947 0.083351859 -2.252013 2.432145e-02\neda         -0.01258123 0.001703646 -7.384884 1.525863e-13\nanios_esc    0.05130108 0.004480285 11.450404 2.340518e-30\nmujer       -0.04077164 0.035053348 -1.163131 2.447763e-01\n\n\nNoten que el signo de los coeficientes coinciden con el promedio de los efectos marginales:\n\navg_slopes(reg.probit)\n\n\n      Term Contrast Estimate Std. Error     z Pr(&gt;|z|)     S    2.5 %   97.5 %\n anios_esc    dY/dX  0.01977   0.001659 11.91   &lt;0.001 106.3  0.01651  0.02302\n eda          dY/dX -0.00485   0.000646 -7.50   &lt;0.001  43.9 -0.00611 -0.00358\n mujer        1 - 0 -0.01571   0.013504 -1.16    0.245   2.0 -0.04218  0.01076\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nEl promedio del efecto marginal de un cambio en los años de educación es de 2 puntos porcentuales. Ligeramente superior al efecto obtenido en el modelo lineal.\n[4 puntos] Ahora estime el efecto marginal en la media para eda y anios_esc y para las mujeres, usando la función slopes. ¿Por qué difiere la magnitud de este efecto marginal respecto a la parte c. y la d.?\nPara obtener los efectos marginales evaluados en algun valor \\(X_i\\) de los covariables, debemos especificar estos valores usando datagrid:\n\navg_slopes(reg.probit,\n           newdata = datagrid(eda = mean(data.financiero$eda),\n                              anios_esc = mean(data.financiero$anios_esc),\n                              mujer = 1))\n\n\n      Term Contrast Estimate Std. Error     z Pr(&gt;|z|)    S    2.5 %   97.5 %\n anios_esc    dY/dX   0.0204   0.001779 11.46   &lt;0.001 98.5  0.01689  0.02386\n eda          dY/dX  -0.0050   0.000677 -7.38   &lt;0.001 42.5 -0.00632 -0.00367\n mujer        1 - 0  -0.0162   0.013944 -1.16    0.245  2.0 -0.04355  0.01111\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nEl efecto marginal de un cambio en los años de escolaridad evaluados en la media de los años de educación y edad, para las mujeres, es de 2.04 puntos. Esto difiere del modelo lineal porque en el modelo lineal los efectos marginales son constantes, mientras que los efectos marginal del modelo no lineal dependen del punto de evaluación. También difiere de los efectos marginales promedio pues aquí solo hemos calculado el efecto marginal una sola vez, para un valor \\(X_i\\), mientras que el promedio de efectos marginales implica calcular el efecto marginal para cada individuo y luego obtener el promedio.\nEn clase les pregunté cómo estimarían el error estándar de los cambios marginales y brevemente mencioné que una forma muy usada es el Método Delta, el cual se basa en que los efectos marginales son funciones no lineales de los parámetros. Esto es lo que efectivamente se usa en la función avg_slopes para obtener los errores estándar y los intervalos de confianza. Aquí pueden leer al respecto."
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-6",
    "href": "tareas/tarea-1-respuestas.html#pregunta-6",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Ahora estimará un modelo multinomial empleando los mismos datos en motral2012.csv. El propósito será ahora estudiar los factores relevantes para predecir la forma de ahorro que tienen las personas que ahorran.\n\n[2 punto] Genere una variable categórica llamada ahorro que sea igual a 1 cuando p14 sea igual a 1 o 2, igual a 2 cuando p14 sea igual a 7, e igual a 3 cuando p14 sea igual a 3, 4, 5, 6 u 8. Haga que esa variable sea missing cuando p14 sea missing. Posteriormente, convierta esta nueva variable en una de factores de forma que el valor 1 tenga la etiqueta “Banco”, el valor 2 tenga la etiqueta “Casa” y el valor 3 tenga la etiqueta “Otro”.\nConstruimos la variable dependiente:\n\ndata.financiero &lt;- read_csv(\"../files/motral2012.csv\",\n                            locale = locale(encoding = \"latin1\")) %&gt;%\n  clean_names() %&gt;% \n  mutate(ahorro=NA) %&gt;% \n  mutate(ahorro=ifelse(p14%in%c(1,2),1,ahorro)) %&gt;%\n  mutate(ahorro=ifelse(p14==7,2,ahorro)) %&gt;% \n  mutate(ahorro=ifelse(p14%in%c(3,4,5,6,8),3,ahorro)) %&gt;% \n  mutate(ahorro=factor(ahorro,\n                   levels=c(1,2,3), labels=c(\"Banco\",\"Casa\",\"Otro\"))) %&gt;%\n  mutate(mujer=ifelse(sex==2,1,0))\n\n[4 puntos] Estime un modelo logit multinomial (regresores invariantes a la alternativa) con la opción de ahorro como variable dependiente y los mismos regresores de la pregunta 5. Hay varios paquetes para hacer esto, pero recomiendo usar la función multinom del paquete nnet. ¿Qué puede decir sobre el coeficiente de años de educación en la alternativa “Casa”?\nUsamos multinom para estimar el modelo logit multinomial:\n\nmultilogit &lt;- nnet::multinom(ahorro~ eda + anios_esc + mujer,\n                              data=data.financiero)\n\n# weights:  15 (8 variable)\ninitial  value 2727.854313 \niter  10 value 2546.085070\nfinal  value 2545.712541 \nconverged\n\nsummary(multilogit)\n\nCall:\nnnet::multinom(formula = ahorro ~ eda + anios_esc + mujer, data = data.financiero)\n\nCoefficients:\n     (Intercept)          eda   anios_esc       mujer\nCasa    3.026880 -0.052310196 -0.14829719  0.09265405\nOtro    0.206704 -0.003501367 -0.04628175 -0.06459305\n\nStd. Errors:\n     (Intercept)         eda  anios_esc      mujer\nCasa   0.2487107 0.005207439 0.01355319 0.09956544\nOtro   0.2476498 0.004964123 0.01285100 0.09995715\n\nResidual Deviance: 5091.425 \nAIC: 5107.425 \n\n\nEn el logit multinominal (regresores invariantes) el coeficiente se interpreta con respecto a una categoría base. En este caso, la categoría base es Banco. El modelo implica que la probabilidad de ahorrar en casa disminuye con un año más de educación, en comparación con la probabilidad de ahorrar en el banco. En particular, sabemos que podemos escribir el log del cociente de la probabilidad de las categorías \\(j\\) y \\(k\\) sean escogidas, normalizando \\(k\\) a ser la base, como:\n\\[\\ln\\left(\\frac{P(y=Casa)}{P(y=Banco)}\\right)=x'\\beta=\\beta_0+\\beta_1 edad + \\beta_2 educación + \\beta_3 mujer \\]\nEs decir, un año más de educación se asocia con una reducción en el log de la razón de momios de 0.15.\n[6 puntos] Calcule los efectos marginales promedio sobre la probabilidad de ahorrar en el banco. Al considerar el cambio en la probabilidad para el caso de las mujeres (cuando la variable mujer pasa de 0 a 1), ¿de qué tamaño es el efecto predicho en la probabilidad de ahorrar en el banco?\nUsamos avg_slopes:\n\navg_slopes(multilogit)\n\n\n Group      Term Contrast Estimate Std. Error       z Pr(&gt;|z|)    S    2.5 %\n Banco anios_esc    dY/dX  0.02285   0.002381   9.595   &lt;0.001 70.0  0.01818\n Banco eda          dY/dX  0.00657   0.000935   7.027   &lt;0.001 38.8  0.00474\n Banco mujer        1 - 0 -0.00343   0.019432  -0.177    0.860  0.2 -0.04152\n Casa  anios_esc    dY/dX -0.02512   0.002231 -11.262   &lt;0.001 95.3 -0.02949\n Casa  eda          dY/dX -0.00982   0.000860 -11.422   &lt;0.001 98.0 -0.01151\n Casa  mujer        1 - 0  0.02271   0.017662   1.286    0.199  2.3 -0.01191\n Otro  anios_esc    dY/dX  0.00228   0.002174   1.046    0.295  1.8 -0.00199\n Otro  eda          dY/dX  0.00325   0.000842   3.863   &lt;0.001 13.1  0.00160\n Otro  mujer        1 - 0 -0.01927   0.017549  -1.098    0.272  1.9 -0.05367\n   97.5 %\n  0.02751\n  0.00840\n  0.03465\n -0.02075\n -0.00814\n  0.05732\n  0.00654\n  0.00490\n  0.01512\n\nColumns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  probs \n\n\nEl efecto de ser mujer es de una reducción de 0.3 puntos en la probabilidad de ahorrar en el banco al estimar el promedio de los efectos marginales.\n[4 puntos] Calcule los cocientes de riesgo relativo (relative risk ratios o RRR). ¿Qué significa el hecho de que el RRR asociado a ser mujer sea mayor que 1 en la alternativa “Casa”?\n\n(multilogit_rrr = exp(coef(multilogit)))\n\n     (Intercept)       eda anios_esc     mujer\nCasa   20.632752 0.9490344 0.8621748 1.0970821\nOtro    1.229619 0.9965048 0.9547729 0.9374489\n\n\nLos coeficientes en forma de RRR tienen la interpretación del cambio en el riesgo relativo que una categoría sea elegida con relación al riesgo de escoger la categoría base. En este caso, el ser mujer está asociado con una probabilidad de ahorrar en “Casa” 1.097 veces mayor de que la de ahorrar en “Banco”.\n[4 puntos] Estime nuevamente el modelo, pero ahora, especifique que la alternativa “Casa” sea la alternativa base. ¿Cómo es el RRR de la edad en la alternativa “Banco”? ¿Es esto congruente con lo que obtuvo en la parte d. de esta pregunta?\nPrimero tenemos que cambiar la base. Para esto hacemos uso de que ahorro es una variable de factores. Luego estimamos:\n\ndata.financiero &lt;- data.financiero %&gt;% \n  mutate(ahorro = relevel(ahorro, ref = \"Casa\"))\n\nmultilogit2 &lt;- nnet::multinom(ahorro ~ eda + anios_esc + mujer,\n                              data=data.financiero)\n\n# weights:  15 (8 variable)\ninitial  value 2727.854313 \niter  10 value 2552.696634\nfinal  value 2545.712541 \nconverged\n\n\nObtenemos el RRR:\n\n(multilogit2_rrr = exp(coef(multilogit2)))\n\n      (Intercept)      eda anios_esc     mujer\nBanco  0.04846638 1.053703  1.159857 0.9115111\nOtro   0.05959489 1.050020  1.107401 0.8544952\n\n\nAl cambiar la categoría base a Casa solo se modifica la interpretación relativa. En la parte d. el RRR de la edad para la opción de Casa era 0.949, es decir, si la edad se incrementa en una unidad, la probabilidad de ahorrar en Casa es 0.949 veces la de ahorrar en Banco. Con la nueva categoría base, el RRR de la edad para ahorrar en Banco es 1.054, es decir, si la edad se incrementa en un año, la probabilidad de ahorrar en Banco es 1.054 veces más probable que la probabilidad de ahorrar en Casa. La parte d. implica que \\(P(Casa)=0.949(Banco)\\). Mientras que estimando el modelo con la nueva categoría, \\(P(Banco)=1.054(Casa)\\), o \\(P(Casa)=1/1.054(Banco)\\). Empleando todos los decimales en R se puede notar que 1/1.054≅0.949 Ambos resultados son consistentes."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html",
    "href": "tareas/tarea-2-respuestas.html",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = TRUE,\n                      warning = FALSE,\n                      message = FALSE,\n                      indent = \"   \")\nlibrary(tidyverse)\nlibrary(knitr)\nlibrary(stargazer)\nlibrary(sandwich)\nlibrary(clubSandwich)\nlibrary(lmtest)\nlibrary(sampleSelection)\nlibrary(AER)\nlibrary(modelsummary)\n\n\n\nConsidere el modelo Poisson visto en clase y un vector de variables explicativas \\(x\\), todas continuas, usadas para parametrizar la media.\n\n[1 puntos] ¿Cuál es el efecto de un cambio en el \\(j\\)ésimo regresor sobre \\(E(y│x)\\)?\nCon un modelo Poisson parametrizamos la media como \\(\\mu=exp(x'\\beta)\\). En este caso, un cambio en un regresor \\(j\\) tiene el efecto:\n\\[\\frac{\\partial E(y|x)}{\\partial x_j}=\\beta_j exp(x'\\beta)\\]\nEs decir, un cambio en una unidad de \\(x_j\\) produce un cambio en el conteo esperado de \\(y\\) igual a \\(\\beta_j exp(x'\\beta)\\) unidades.\n[2 puntos] Usando esta expresión, muestre que si el \\(j\\)ésimo regresor es \\(x_j\\), entonces \\(100 \\beta_j\\) es la semielasticidad de \\(E(y│x)\\) con respecto a \\(x_j\\). Nota: Este punto es muy útil para la interpretación de los coeficientes de un modelo Poisson.\nResolviendo para \\(\\beta_j\\) en la expresión que acabamos de encontrar:\n\\[\\beta_j=\\frac{\\partial E(y|x)}{\\partial x_j}\\frac{1}{\\exp(x'\\beta)}\\]\nReconociendo que\n\\[\\beta_j=\\frac{\\partial E(y|x)}{\\partial x_j}\\frac{1}{\\exp(x'\\beta)}=\\frac{\\partial E(y|x)}{\\partial x_j}\\frac{1}{E(y|x)}=\\frac{\\partial\\ln E(y|x)}{\\partial x_j}\\]\n\\(\\frac{\\partial\\ln E(y|x)}{\\partial x_j}\\) es una semileasticidad, es decir un cambio marginal de \\(x_j\\) se asocia con un cambio porcentual en la media condicional igual a \\(100\\beta_j\\Delta x_j\\).\n[2 puntos] ¿Cómo se interpreta \\(\\beta_j\\) si reemplazamos \\(x_j\\) por \\(\\log(x_j)\\))?\nSi ahora el regresor de interés entra en el índice como un logaritmo: \\[\\beta_j=\\frac{\\partial E(y|x)}{\\partial x_j}\\frac{x_j}{E(y|x)}\\]\nla defnición de una elasticidad.\n\n\n\n\nEn esta pregunta mostrará cómo para un modelo en dos partes Poisson la log verosimilitud del problema es la suma de log verosimilitud para un proceso binario y la log verosimilitud de un proceso Poisson truncado en cero. Considere una variable aleatoria \\(Y\\) con observaciones iid que sigue una distribución Poisson con parámetro \\(\\lambda\\) tal que\n\\[f(y,\\lambda)=P(Y=y)=\\frac{\\lambda^y exp(-\\lambda)}{y!}\\]\n\n[4 puntos] Obtenga la distribución Poisson truncada en cero, definida como \\(P(Y=y|Y&gt;0)\\).\nSabemos que la distribución truncada en cero es:\n\\[P(Y=y|Y&gt;0)=\\frac{f(y,\\lambda)}{1-f(0,\\lambda)}\\]\nSustituyendo la forma de la densidad Poisson:\n\\[P(Y=y|Y&gt;0)=\\frac{\\frac{\\lambda^y exp(-\\lambda)}{y!}}{1-exp(-\\lambda)}=\\frac{\\lambda^y}{y!(exp(\\lambda)-1)}\\]\n[4 puntos] Considere además un proceso binomial que modela la probabilidad de que la variable \\(Y\\) tome un valor cero o un valor positivo, como sigue:\n\\[P(Y=y)=\\begin{cases} \\pi \\quad\\quad y=0 \\\\ 1-\\pi\\quad\\quad y=1,2,3,\\ldots \\end{cases} \\]\nEn clase vimos la forma general del modelo en dos partes:\n\\[\ng(y)=\n\\begin{cases}\nf_1(0) \\quad\\text{si }y=0 \\\\\n\\frac{(1-f_1(0))f_2(y)}{1-f_2(0)}\\quad\\text{si }y\\geq 1\n\\end{cases}\n\\]\nEspecialice forma general del modelo de dos partes usando la distribución truncada derivada en a. y el proceso binomial definido arriba para obtener una función de masa de probabilidad no condicional para \\(Y\\), \\(g(y)\\).\nSea \\(\\pi\\) la probabilidad de observar un conteo igual a cero, especializamos la función vista en clase, incorporando la distribución truncada encontrada en la parte a.:\n\\[\ng(y)=\n\\begin{cases}\n\\pi \\quad\\text{si }y=0 \\\\\n(1-\\pi)\\frac{\\lambda^y}{y!(exp(\\lambda)-1)} \\quad\\text{si }y\\geq 1\n\\end{cases}\n\\]\n[4 puntos] Obtenga la log verosimilitud para la \\(i\\)ésima observación. Se sugiere que continúe sus cálculos con una ecuación en dos partes.\nLa log verosimilitud de la \\(i\\)ésima observación es:\n\\[\n\\mathcal{l}_i(\\pi,\\lambda,y_i)=\n\\begin{cases}\n\\ln(\\pi) \\quad\\text{si }y=0 \\\\\n\\ln\\left((1-\\pi)\\frac{\\lambda^{y_i}}{y!(exp(\\lambda)-1)}\\right) \\quad\\text{si }y\\geq 1\n\\end{cases}\n\\]\n[4 puntos] En este problema, parametrizaremos \\(\\lambda_i\\) como \\(\\lambda_i=exp(x_i'\\beta_2)\\), como regularmente lo hemos hecho en una regresión Poisson. Por otro lado, podemos trabajar con una parametrización general de la probabilidad \\(\\pi\\), \\(\\pi=F(x_i'\\beta_1)\\). Escriba la función de log verosimilitud del problema usando la parametrización para \\(\\pi_i\\) y para \\(\\lambda_i\\) que acabamos de describir. Presente esta función en una sola parte.\nCon la parametrización dada, podemos reescribir la log verosimilitud de una observación como:\n\\[\n\\mathcal{l}_i(\\pi,\\lambda,y_i)=\n\\begin{cases}\n\\ln(F(x_i'\\beta_1)) \\quad\\text{si }y=0 \\\\\n\\ln\\left((1-F(x_i'\\beta_1))\\frac{exp(x_i'\\beta_2)^{y_i}}{y!(exp(exp(x_i'\\beta_2))-1)} \\right) \\quad\\text{si }y\\geq 1\n\\end{cases}\n\\]\nLa log verosimilitud del problema es la probabilidad de observar los datos. Con la parametrización anterior:\n\\[\n\\mathcal{L}(\\beta_1,\\beta_2,y_i)=\\ln\\left(\\prod_{i\\in y_i=0}F(x_i'\\beta_1)\\prod_{i\\in y_i&gt;0}(1-F(x_i'\\beta_1))\\prod_{i\\in y_i&gt;0}\\frac{exp(x_i'\\beta_2)^{y_i}}{y!(exp(exp(x_i'\\beta_2))-1)} \\right)\n\\]\nDistribuyendo el logarítmo:\n\\[\n\\begin{align}\n\\mathcal{L}(\\beta_1,\\beta_2,y_i)&=\\sum_{i\\in y_i=0}\\ln(F(x_i'\\beta_1))+\\sum_{i\\in y_i&gt;0}\\ln\\left(1-F(x_i'\\beta_1)\\right)+ \\\\\n&+\\sum_{i\\in y_i&gt;0}x_i'\\beta_2y_i-\\sum_{i\\in y_i&gt;0}\\ln\\left(exp(exp(x_i'\\beta_2))-1\\right)-\\sum_{i\\in y_i&gt;0}y!\n\\end{align}\n\\]\n[4 puntos] Agrupe los términos para mostrar que \\(\\mathcal{L}=\\mathcal{L}_1(\\beta_1)+\\mathcal{L}_2(\\beta_2)\\). Así, mostrará que la log verosimilitud del problema se puede descomponer en una log verosimilitud para el modelo binario y otra para el conteo truncado en cero. Por tanto, no perdemos información si estimamos los parámetros de la probabilidad binomial por un lado, y los de la distribución Poisson truncada en cero, por el otro.\nClaramente:\n\\[\n\\mathcal{L}(\\beta_1,\\beta_2,y_i)=\\mathcal{L_1}(\\beta_1,y_i)+\\mathcal{L_2}(\\beta_2,y_i)\n\\]\nes decir, la suma de dos log verosimilitudes, una de un proceso binario y otra para el modelo Poisson truncado en cero.\n\n\n\n\nUse los datos phd_articulos.csv, los cuales contienen información sobre el número de artículos publicados para una muestra de entonces estudiantes de doctorado. Nuestra variable de interés será el número de artículos art.\n\n[4 puntos] Estime un modelo Poisson que incluya variables dicotómicas para estudiantes mujeres (female) y para estudiantes casadas o casados (married), el número de hijos mejores de cinco años (kid5), el ranking de prestigio del doctorado (phd) y el número de artículos publicados por su mentor (mentor). Realice la estimación de la matriz de varianzas primero a partir de la varianza teórica que resulta de la igualdad de la matriz de información y luego usando una matriz de sándwich. Interprete los coeficientes estimados.\n\ndata.phd&lt;-read_csv(\"../files/phd_articulos.csv\",\n                          locale = locale(encoding =                \"latin1\"))\n\ndata.phd &lt;- data.phd %&gt;% \n  mutate(female=factor(female,\n                       levels=c('Male','Female')))\n\nmpoisson &lt;- glm(art ~ factor(female) + factor(married) + kid5 + phd + mentor,\n                family=\"poisson\",\n                data=data.phd)\n\nsummary(mpoisson)\n\n\nCall:\nglm(formula = art ~ factor(female) + factor(married) + kid5 + \n    phd + mentor, family = \"poisson\", data = data.phd)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            0.459860   0.093335   4.927 8.35e-07 ***\nfactor(female)Female  -0.224594   0.054613  -4.112 3.92e-05 ***\nfactor(married)Single -0.155243   0.061374  -2.529   0.0114 *  \nkid5                  -0.184883   0.040127  -4.607 4.08e-06 ***\nphd                    0.012823   0.026397   0.486   0.6271    \nmentor                 0.025543   0.002006  12.733  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 1817.4  on 914  degrees of freedom\nResidual deviance: 1634.4  on 909  degrees of freedom\nAIC: 3314.1\n\nNumber of Fisher Scoring iterations: 5\n\n\nPresentamos errores heterocedásticos y robustos a la heterocedasticidad. Aquí les muestro otro paquete que puede servirles para presentar resultados en trabajos y tesinas, alterntivo a stargazer, modelsummary:\n\nmodelsummary(list(mpoisson, mpoisson),\n             vcov = list('classical', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n\n\n\n\n (1)\n  (2)\n\n\n\n\n(Intercept)\n0.460***\n0.460***\n\n\n\n(0.093)\n(0.151)\n\n\nfactor(female)Female\n-0.225***\n-0.225***\n\n\n\n(0.055)\n(0.072)\n\n\nfactor(married)Single\n-0.155**\n-0.155*\n\n\n\n(0.061)\n(0.083)\n\n\nkid5\n-0.185***\n-0.185***\n\n\n\n(0.040)\n(0.057)\n\n\nphd\n0.013\n0.013\n\n\n\n(0.026)\n(0.044)\n\n\nmentor\n0.026***\n0.026***\n\n\n\n(0.002)\n(0.004)\n\n\nNum.Obs.\n915\n915\n\n\nAIC\n3314.1\n3314.1\n\n\nBIC\n3343.0\n3343.0\n\n\nLog.Lik.\n-1651.056\n-1651.056\n\n\nF\n43.333\n14.855\n\n\nRMSE\n1.84\n1.84\n\n\nStd.Errors\nIID\nHC3\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n\nPara las variables continuas, como el número de artículos publicados por el mentor, la interpretación es el cambio en el log conteo esperado. En este caso, un artículo más publicado por el mentor incrementa el log conteo esperado en 0.026. También sabemos que los coeficientes tienen una interpretación de semielasticidad; en este caso, la semielasticidad del conteo con respecto al número de artículos publicados es 0.026. Para las variables dicotómicas, por ejemplo female, la interpretación es la diferencia entre el log conteo esperado entre mujeres y la categoría base (hombres).\n[5 puntos] Obtenga la razón de tasas de incidencia (IRR) para los coeficientes e interprete los resultados.\n\nexp(summary(mpoisson)$coef)\n\n                       Estimate Std. Error      z value Pr(&gt;|z|)\n(Intercept)           1.5838526   1.097829 1.379638e+02 1.000001\nfactor(female)Female  0.7988403   1.056132 1.636793e-02 1.000039\nfactor(married)Single 0.8562068   1.063297 7.970295e-02 1.011490\nkid5                  0.8312018   1.040943 9.977222e-03 1.000004\nphd                   1.0129051   1.026749 1.625407e+00 1.872246\nmentor                1.0258718   1.002008 3.386456e+05 1.000000\n\n\nAunque esto también puede hacerse directamente en modelsummary:\n\nmodelsummary(list(mpoisson, mpoisson),\n             exponentiate = TRUE,\n             vcov = list('classical', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n\n\n\n\n (1)\n  (2)\n\n\n\n\n(Intercept)\n1.584***\n1.584***\n\n\n\n(0.148)\n(0.240)\n\n\nfactor(female)Female\n0.799***\n0.799***\n\n\n\n(0.044)\n(0.058)\n\n\nfactor(married)Single\n0.856**\n0.856*\n\n\n\n(0.053)\n(0.071)\n\n\nkid5\n0.831***\n0.831***\n\n\n\n(0.033)\n(0.047)\n\n\nphd\n1.013\n1.013\n\n\n\n(0.027)\n(0.045)\n\n\nmentor\n1.026***\n1.026***\n\n\n\n(0.002)\n(0.004)\n\n\nNum.Obs.\n915\n915\n\n\nAIC\n3314.1\n3314.1\n\n\nBIC\n3343.0\n3343.0\n\n\nLog.Lik.\n-1651.056\n-1651.056\n\n\nF\n43.333\n14.855\n\n\nRMSE\n1.84\n1.84\n\n\nStd.Errors\nIID\nHC3\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n\nLa interpretación de los coeficientes se vuelve más sencilla usando irr. Para la variable continua mentor, un artículo más publicado por el mentor está asociado con 1.026 veces más artículos publicados por el estudiante, es decir, un 2.6% más artículos. En cambio, la variable dicotómica para mujeres indica que las mujeres publican 0.8 veces el número de artículos que los hombres.\n[3 puntos] Considere ahora que las mujeres han tenido carreras profesionales más cortas que los hombres, es decir, han estado menos expuestas a la ocurrencia de los eventos publicar. Incorpore esto al análisis y reinterprete los resultados. Pista: explore la opción offeset en glm de R. La columna profage mide la duración efectiva de las carreras profesionales de cada individuo.\nEl razonamiento es que ahora queremos conocer cuál es la tasa de publicación, es decir, \\(art/profage\\). Pero como nuestro podemos Poisson solo puede manejar conteos, podemos modificar el modelo para pasar la edad de la carrera del lado derecho:\n\\[\\begin{aligned}ln(art/profage)&=x'\\beta \\\\ ln(art)&=x'\\beta+\\ln(profage) \\end{aligned}\\]\n\nmpoisson_duracion &lt;- glm(art ~\n                  factor(female) + factor(married) + kid5 + phd + mentor,\n                  offset = log(profage),\n                  family=\"poisson\",\n                  data=data.phd)\n\nsummary(mpoisson_duracion)$coef\n\n                         Estimate  Std. Error     z value      Pr(&gt;|z|)\n(Intercept)           -2.95404558 0.093812104 -31.4889600 1.230266e-217\nfactor(female)Female   0.45874678 0.054721432   8.3833109  5.145931e-17\nfactor(married)Single -0.15598278 0.061347334  -2.5426171  1.100257e-02\nkid5                  -0.18643454 0.040135522  -4.6451256  3.398696e-06\nphd                    0.01801602 0.026428953   0.6816773  4.954430e-01\nmentor                 0.02573493 0.002001731  12.8563329  7.924799e-38\n\n\nHasta ahora hemos asumido que cada individuo ha estado “en riesgo” de publicar por el mismo periodo de tiempo, lo cual puede ser no cierto si, por ejemplo, algunos estudiantes se graduaron antes, o si otros han tenido pausas en sus carreras. Al controlar por el hecho de que las mujeres han tenido carreras más cortas, la variable female deja de ser negativa y se convierte en positiva. Las mujeres publican más que los hombres al tomar en cuenta la duración de las carreras.\nComparando los tres modelos:\n\nmodelsummary(list(mpoisson, mpoisson, mpoisson_duracion),\n             vcov = list('classical', 'robust', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n\n\n\n\n (1)\n  (2)\n  (3)\n\n\n\n\n(Intercept)\n0.460***\n0.460***\n-2.954***\n\n\n\n(0.093)\n(0.151)\n(0.155)\n\n\nfactor(female)Female\n-0.225***\n-0.225***\n0.459***\n\n\n\n(0.055)\n(0.072)\n(0.073)\n\n\nfactor(married)Single\n-0.155**\n-0.155*\n-0.156*\n\n\n\n(0.061)\n(0.083)\n(0.083)\n\n\nkid5\n-0.185***\n-0.185***\n-0.186***\n\n\n\n(0.040)\n(0.057)\n(0.057)\n\n\nphd\n0.013\n0.013\n0.018\n\n\n\n(0.026)\n(0.044)\n(0.045)\n\n\nmentor\n0.026***\n0.026***\n0.026***\n\n\n\n(0.002)\n(0.004)\n(0.005)\n\n\nNum.Obs.\n915\n915\n915\n\n\nAIC\n3314.1\n3314.1\n3322.8\n\n\nBIC\n3343.0\n3343.0\n3351.7\n\n\nLog.Lik.\n-1651.056\n-1651.056\n-1655.393\n\n\nF\n43.333\n14.855\n20.311\n\n\nRMSE\n1.84\n1.84\n1.85\n\n\nStd.Errors\nIID\nHC3\nHC3\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n\n\n[3 puntos] Emplee ahora un modelo negativo binomial con sobredispersión cuadrática en la media para estimar la relación entre el número de artículos publicados y las variables explicativas antes enumeradas. Interprete el coeficiente asociado al número de hijos y a la variable dicotómica para estudiantes mujeres. ¿Qué puede decir sobre la significancia del \\(\\alpha\\) estimado?\n\nmnb2 &lt;- MASS::glm.nb(art ~\n                 factor(female) + factor(married) + kid5 + phd + mentor,\n                 data = data.phd)\nsummary(mnb2)\n\n\nCall:\nMASS::glm.nb(formula = art ~ factor(female) + factor(married) + \n    kid5 + phd + mentor, data = data.phd, init.theta = 2.264387695, \n    link = log)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            0.406633   0.125778   3.233 0.001225 ** \nfactor(female)Female  -0.216418   0.072636  -2.979 0.002887 ** \nfactor(married)Single -0.150489   0.082097  -1.833 0.066791 .  \nkid5                  -0.176415   0.052813  -3.340 0.000837 ***\nphd                    0.015271   0.035873   0.426 0.670326    \nmentor                 0.029082   0.003214   9.048  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(2.2644) family taken to be 1)\n\n    Null deviance: 1109.0  on 914  degrees of freedom\nResidual deviance: 1004.3  on 909  degrees of freedom\nAIC: 3135.9\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  2.264 \n          Std. Err.:  0.271 \n\n 2 x log-likelihood:  -3121.917 \n\n\nPonemos todo junto:\n\nmodelsummary(list(mpoisson, mpoisson, mpoisson_duracion, mnb2),\n             vcov = list('classical', 'robust', 'robust', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n\n\n\n\n (1)\n  (2)\n  (3)\n  (4)\n\n\n\n\n(Intercept)\n0.460***\n0.460***\n-2.954***\n0.407***\n\n\n\n(0.093)\n(0.151)\n(0.155)\n(0.135)\n\n\nfactor(female)Female\n-0.225***\n-0.225***\n0.459***\n-0.216***\n\n\n\n(0.055)\n(0.072)\n(0.073)\n(0.071)\n\n\nfactor(married)Single\n-0.155**\n-0.155*\n-0.156*\n-0.150*\n\n\n\n(0.061)\n(0.083)\n(0.083)\n(0.081)\n\n\nkid5\n-0.185***\n-0.185***\n-0.186***\n-0.176***\n\n\n\n(0.040)\n(0.057)\n(0.057)\n(0.053)\n\n\nphd\n0.013\n0.013\n0.018\n0.015\n\n\n\n(0.026)\n(0.044)\n(0.045)\n(0.038)\n\n\nmentor\n0.026***\n0.026***\n0.026***\n0.029***\n\n\n\n(0.002)\n(0.004)\n(0.005)\n(0.003)\n\n\nNum.Obs.\n915\n915\n915\n915\n\n\nAIC\n3314.1\n3314.1\n3322.8\n3135.9\n\n\nBIC\n3343.0\n3343.0\n3351.7\n3169.6\n\n\nLog.Lik.\n-1651.056\n-1651.056\n-1655.393\n-1560.958\n\n\nF\n43.333\n14.855\n20.311\n20.935\n\n\nRMSE\n1.84\n1.84\n1.85\n1.86\n\n\nStd.Errors\nIID\nHC3\nHC3\nHC3\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n\n\n\nA diferencia de otros paquetes, glm.nb reporta \\(\\theta=1/\\alpha\\):\n\n(alpha &lt;- 1/summary(mnb2)$theta)        \n\n[1] 0.4416205\n\n\nEste es el modelo NB2 visto en clase y la forma más usada para implementar un modelo negativo binomial. Se asume una sobredispersión cuadrática en la media, con la varianza parametrizada usando \\(\\alpha\\). La interpretación de los coeficientes se mantiene con respecto al modelo Poisson. Los coeficientes tienen magnitudes similares, pero se prefiere el modelo NB2 si el propósito es pronóstico pues toma en cuenta la sobredispersión y le da suficiente flexibilidad a la varianza para depender de manera cuadrática de la media.\nUn poco más cuidado hay que poner en \\(\\alpha\\). En este caso, \\(\\hat{\\alpha}=0.44\\). Pero noten que lo que se reporta es el error estándar de \\(\\theta\\). Como platicamos en clase, con un estadístico podemos hacer un test y obtener un valor \\(p\\), pero una función no lineal del mismo puede que no tenga el mismo valor \\(p\\). Esto ocurre aquí, deberíamos recurrir al método delta para calcular el error estándar de \\(\\alpha\\).\n\n\n\n\nRetome los datos del archivo motral2012.csv usado en la Tarea 1. Estimará un modelo Tobit para explicar los factores que afectan la oferta laboral femenina. En este archivo de datos la variable hrsocup registra las horas trabajadas a la semana.\n\n[2 punto] ¿Qué proporción de la muestra femenina reporta horas trabajadas iguales a cero?\nSi hacemos una dummy de horas positivas, al sacarle la media obtenemos la proporción.\n\ndata.salarios&lt;-read_csv(\"../files/motral2012.csv\",\n                          locale = locale(encoding = \"latin1\")) \n\ndata.salarios &lt;- data.salarios %&gt;% \n  filter(sex==2) %&gt;% \n  mutate(zerohrs=ifelse(hrsocup==0,1,0))\n\nsummary(data.salarios$zerohrs)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.3528  1.0000  1.0000 \n\n\nEl 35% de las observaciones tienen cero horas trabajadas.\n[3 puntos] Se desea estimar el efecto de los años de educación (anios_esc) sobre la oferta laboral femenina controlando por el estado marital (casada), la edad (eda) y el número de hijos (n_hij) como una variable continua. En la base, e_con toma el valor de 5 para las personas casadas. Genere la variable dummy casada que tome el valor de 1 para las mujeres casadas y cero en otro caso. Estime un modelo de MCO para hrsocup mayor que cero, usando solo la población femenina. Reporte errores robustos. ¿Cuál es la interpretación sobre el coeficiente de los años de escolaridad?\nEl estimar por MCO, un año más de escolaridad se asocia con 0.17 horas trabajadas más a la semana. Sin embargo, este efecto no es estadísticamente significativo.\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(casada=ifelse(e_con==5,1,0))\n\nreg_mco &lt;- lm(hrsocup ~ anios_esc+casada+eda+n_hij,\n          data=filter(data.salarios,hrsocup&gt;0))\n\ncoeftest(reg_mco,\n         vcov = vcovHC(reg_mco, \"HC1\"))[1:4,]\n\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 36.70129720 1.99116828 18.432042 2.742336e-69\nanios_esc    0.17465627 0.10353350  1.686954 9.179628e-02\ncasada      -3.52571327 0.89724706 -3.929479 8.855253e-05\neda          0.06949593 0.04914655  1.414055 1.575295e-01\n\n\nCon modelsummary podemos hacer pedir la tabla de coeficientes. Podemos especificar qué tipo de errores robustos queremos en la opción vcov:\n\nmodelsummary(list(reg_mco, reg_mco),\n             vcov = list('classical', 'HC1'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n\n\n\n\n (1)\n  (2)\n\n\n\n\n(Intercept)\n36.701***\n36.701***\n\n\n\n(1.959)\n(1.991)\n\n\nanios_esc\n0.175*\n0.175*\n\n\n\n(0.104)\n(0.104)\n\n\ncasada\n-3.526***\n-3.526***\n\n\n\n(0.862)\n(0.897)\n\n\neda\n0.069\n0.069\n\n\n\n(0.047)\n(0.049)\n\n\nn_hij\n-1.149***\n-1.149***\n\n\n\n(0.336)\n(0.372)\n\n\nNum.Obs.\n1699\n1699\n\n\nR2\n0.030\n0.030\n\n\nR2 Adj.\n0.028\n0.028\n\n\nAIC\n14234.8\n14234.8\n\n\nBIC\n14267.4\n14267.4\n\n\nLog.Lik.\n-7111.383\n-7111.383\n\n\nF\n13.171\n12.526\n\n\nRMSE\n15.91\n15.91\n\n\nStd.Errors\nIID\nHC1\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n\n[3 puntos] ¿Qué problema existe con el modelo planteado en el punto anterior en términos de la selección? ¿Considera que se trata de un caso de censura o de truncamiento?\nPodemos racionalizar las horas trabajadas en un modelo microeconómico de oferta laboral. Las horas trabajadas observadas son positivas cuando la solución óptima es una cantidad positiva de horas. Sin embargo, si la solución óptima implicara horas negativas, las horas observadas serían cero. En este caso tenemos datos censurados en cero. Si existe una relación positiva entre educación y horas trabajadas, al estimar un modelo por MCO usando solo los datos con horas positivas estamos sobreestimando la media condicional pues se habrán omitido del análisis aquellas mujeres cuya solución a su problema de optimización eran horas iguales a cero o negativas.\n[8 puntos] Estime un modelo Tobit de datos censurados. ¿Qué resuelve el modelo Tobit en este caso? Interprete nuevamente el coeficiente sobre los años de escolaridad.\nLa función tobit permite hacer esto muy fácilmente. Noten que left especifica dónde está la censura. La opción gaussian pone explícito uno de los supuestos críticos del modelo tobit visto en clase: errores normales. Además, se asume homocedasticidad.\n\nreg_tobit &lt;- tobit(hrsocup ~ anios_esc+casada+eda+n_hij,\n               left = 0,\n               right = Inf,\n               dist = \"gaussian\",\n               data = data.salarios)\n\nsummary(reg_tobit)\n\n\nCall:\ntobit(formula = hrsocup ~ anios_esc + casada + eda + n_hij, left = 0, \n    right = Inf, dist = \"gaussian\", data = data.salarios)\n\nObservations:\n         Total  Left-censored     Uncensored Right-censored \n          2625            926           1699              0 \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.88236    3.19905   0.276  0.78269    \nanios_esc     0.85530    0.17509   4.885 1.04e-06 ***\ncasada      -10.99515    1.43025  -7.688 1.50e-14 ***\neda           0.41621    0.07665   5.430 5.64e-08 ***\nn_hij        -1.73840    0.55887  -3.111  0.00187 ** \nLog(scale)    3.44512    0.01887 182.608  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nScale: 31.35 \n\nGaussian distribution\nNumber of Newton-Raphson Iterations: 3 \nLog-likelihood: -9086 on 6 Df\nWald-statistic: 127.9 on 4 Df, p-value: &lt; 2.22e-16 \n\n\nEl modelo tobit para datos censurados toma en cuenta que hay una masa de ceros en las horas trabajadas para individuos para los que disponemos de sus características en la base de datos. El modelo tobit ajusta la probabilidad de observar esta masa de ceros. El coeficiente estimado será ahora consistente si el modelo está bien especificado, es decir, si el proceso subyacente es lineal en los parámetros y con un error normal homoscedástico (los supuestos de tobit básico). En este caso, un año más de educación se asocia con 0.85 más horas semanales trabajadas, un efecto estadísticamente significativo. Usar MCO subestimaba el efecto de la escolaridad.\nmodelsummary acepta la salida de la función tobit:\n\nmodelsummary(list(reg_mco, reg_mco, reg_tobit),\n             vcov = list('classical', 'HC1', 'classical'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n\n\n\n\n (1)\n  (2)\n  (3)\n\n\n\n\n(Intercept)\n36.701***\n36.701***\n0.882\n\n\n\n(1.959)\n(1.991)\n(3.199)\n\n\nanios_esc\n0.175*\n0.175*\n0.855***\n\n\n\n(0.104)\n(0.104)\n(0.175)\n\n\ncasada\n-3.526***\n-3.526***\n-10.995***\n\n\n\n(0.862)\n(0.897)\n(1.430)\n\n\neda\n0.069\n0.069\n0.416***\n\n\n\n(0.047)\n(0.049)\n(0.077)\n\n\nn_hij\n-1.149***\n-1.149***\n-1.738***\n\n\n\n(0.336)\n(0.372)\n(0.559)\n\n\nNum.Obs.\n1699\n1699\n2625\n\n\nR2\n0.030\n0.030\n\n\n\nR2 Adj.\n0.028\n0.028\n\n\n\nAIC\n14234.8\n14234.8\n18184.9\n\n\nBIC\n14267.4\n14267.4\n18220.1\n\n\nLog.Lik.\n-7111.383\n-7111.383\n\n\n\nF\n13.171\n12.526\n\n\n\nRMSE\n15.91\n15.91\n23.02\n\n\nStd.Errors\nIID\nHC1\nIID\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n\n\n[4 puntos] ¿Cuál es el efecto marginal de un incremento de un año de educación en la oferta laboral? ¿Cómo cambia su respuesta si, en lugar de considerar la variable latente, considera la variable censurada?\nEl efecto marginal en la variable latente es directamente el coficiente estimado en la parte d., es decir 0.855.\nEl efecto marginal en la media censurada está dado por:\n\\[\\frac{\\partial E(y|x)}{\\partial x_j}=\\beta_j\\Phi(x_i'\\beta)\\]\nLo que hice aquí fue calcular este efecto marginal para cada individuo y luego obtener el promedio de los efectos marginales en aquellos individuos con horas positivas.\n\ndata.salarios &lt;- data.salarios %&gt;%\n  mutate(index1=predict(reg_tobit,.)) %&gt;% \n  mutate(phi=pnorm(index1/reg_tobit$scale)) %&gt;% \n  mutate(mfx_anis_esc=reg_tobit$coefficients[2]*phi,\n         mfx_eda=reg_tobit$coefficients[4]*phi,\n         mfx_n_hij=reg_tobit$coefficients[5]*phi)\n\ndata.salarios %&gt;%\n  filter(hrsocup&gt;0) %&gt;% \n  summarise(mfx_anis_esc=mean(mfx_anis_esc)) \n\n# A tibble: 1 × 1\n  mfx_anis_esc\n         &lt;dbl&gt;\n1        0.612\n\n\n\n\n\n\nUsando los mismos datos del archivo motral2012.csv implementará un ejercicio en el mismo espíritu del famoso estudio de Mroz (1987)1 sobre la oferta laboral femenina. El propósito es estimar la relación entre el salario y el número de horas trabajadas, concentrándonos en la muestra de mujeres.\n\n[5 puntos] El primer problema al que nos enfrentamos es que el salario no se observa para las mujeres que no trabajan. Estime un modelo lineal para el log del salario por hora, ing_x_hrs, usando las variables anios_esc, eda, n_hij, el cuadrado de n_hij, busqueda y casada, usando la submuestra de mujeres con salario por hora positivo. Dichas variables representan los años de escolaridad, la edad, el número de hijos, el cuadrado del número de hijos, si la persona buscó trabajo recientemente y si la persona es casada, respectivamente. Use los coeficientes estimados para imputar el ingreso por hora, faltante para las mujeres que reportan 0 en las horas trabajadas.\nImputamos el salario faltante:\n\ndata.salarios&lt;-read_csv(\"../files/motral2012.csv\",\n                        locale = locale(encoding = \"latin1\")) %&gt;%\n  filter(sex==2) %&gt;% \n  mutate(casada=ifelse(e_con==5,1,0))\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(ly=ifelse(ing_x_hrs&gt;0,log(ing_x_hrs),NA)) \n\nreg_imput &lt;- lm(ly ~ anios_esc+casada+eda+n_hij+n_hij^2+busqueda,\n              data = data.salarios)\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(lyhat = predict(reg_imput, .)) %&gt;% \n  mutate(ly = ifelse(is.na(ly), lyhat, ly))\n\nAquí tomé en cuenta que hay personas con horas trabajadas positivas e ingreso cero. En ese caso puse un NA al log del salario. Luego, en la imputación, le asigné el valor ajustado a estas observaciones junto con todas las que tienen el log del salario faltante.\n[5 puntos] Use heckit de la librería sampleSelection para estimar por máxima verosimilitud un heckit para las horas trabajadas hrsocup. En la ecuación de selección (si la persona trabaja o no) incluya como variable explicativa el salario por hora (imputado para las mujeres que no trabajan), además de anios_esc, eda, n_hij, el cuadrado de n_hij, casada y busqueda (esta última es un indicador de si se buscó trabajo en la última semana). En la ecuación de horas, incluya los mismos regresores, excepto n_hij, su cuadrado y busqueda.\nLa función heckit permite estimar el modelo de Heckman por máxima verosimilitud de manera muy simple. Hay que especificar method=“ml” para que la estimación sea por máxima verosimilitud:\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(trabaja = ifelse(hrsocup&gt;0,1,0)) %&gt;% \n  mutate(trabaja = factor(trabaja,levels=c(0,1)))\n\nreg_heckit_mv &lt;- heckit(trabaja ~ anios_esc+casada+eda+ly+n_hij+n_hij^2+busqueda,\n                hrsocup ~ anios_esc+casada+eda+ly,\n                method=\"ml\",\n                data = data.salarios)\n\nsummary(reg_heckit_mv)\n\n--------------------------------------------\nTobit 2 model (sample selection model)\nMaximum Likelihood estimation\nNewton-Raphson maximisation, 3 iterations\nReturn code 8: successive function values within relative tolerance limit (reltol)\nLog-Likelihood: -7181.675 \n2625 observations (926 censored and 1699 observed)\n14 free parameters (df = 2611)\nProbit selection equation:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.583614   0.448320  -5.763 9.24e-09 ***\nanios_esc    0.005346   0.020341   0.263    0.793    \ncasada      -0.213125   0.145135  -1.468    0.142    \neda         -0.003391   0.008137  -0.417    0.677    \nly          -0.004236   0.133344  -0.032    0.975    \nn_hij        0.023985   0.058900   0.407    0.684    \nbusqueda     2.406669   0.104595  23.009  &lt; 2e-16 ***\nOutcome equation:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 55.62469    2.17656  25.556  &lt; 2e-16 ***\nanios_esc    1.04819    0.09995  10.487  &lt; 2e-16 ***\ncasada      -3.58856    0.77967  -4.603 4.37e-06 ***\neda          0.11614    0.03902   2.977  0.00294 ** \nly          -9.83418    0.60389 -16.285  &lt; 2e-16 ***\n   Error terms:\n      Estimate Std. Error t value Pr(&gt;|t|)    \nsigma  14.8579     0.2591  57.350   &lt;2e-16 ***\nrho    -0.1606     0.1964  -0.818    0.414    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n--------------------------------------------\n\n\nPodemos reportar con modelsummary, aunque realmente lo hace muy mal:\n\nmodelsummary(list(reg_heckit_mv),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n-2.584***\n\n\n\n55.625***\n\n\n\n(0.448)\n\n\n\n(2.177)\n\n\nanios_esc\n0.005\n\n\n\n1.048***\n\n\n\n(0.020)\n\n\n\n(0.100)\n\n\ncasada\n-0.213\n\n\n\n-3.589***\n\n\n\n(0.145)\n\n\n\n(0.780)\n\n\neda\n-0.003\n\n\n\n0.116***\n\n\n\n(0.008)\n\n\n\n(0.039)\n\n\nly\n-0.004\n\n\n\n-9.834***\n\n\n\n(0.133)\n\n\n\n(0.604)\n\n\nn_hij\n0.024\n\n\n\n(0.059)\n\n\nbusqueda\n2.407***\n\n\n\n(0.105)\n\n\nsigma\n14.858***\n\n\n\n(0.259)\n\n\nrho\n-0.161\n\n\n\n(0.196)\n\n\nNum.Obs.\n2625\n\n\nAIC\n14391.4\n\n\nBIC\n14473.6\n\n\nRMSE\n14.84\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n[10 puntos] Estime ahora el heckit en dos pasos, a mano. Es decir, siga los siguientes pasos: i) estime un probit para la ecuación de selección y obtenga el índice \\(x_i'\\hat{\\beta}\\); ii) calcule el inverso de la razón de Mills \\(\\lambda_i(x_i'\\hat{\\beta})\\); y iii) estime por MCO la ecuación para las horas trabajadas con la submuestra que tiene horas trabajadas positivas, incluyendo como regresor el inverso de la razón de Mills estimado y el resto de los regresores. Compare los coeficientes y los errores estándar obtenidos en esta parte con los de la parte b. ¿Por qué son iguales o por qué difieren?\nEstimamos ahora el heckit a mano. Estimamos el probit y obtenemos el valor ajustado del IMR:\n\nreg_heckit_pe &lt;- glm(trabaja ~ anios_esc+casada+eda+ly+n_hij+n_hij^2+busqueda,\n                  family = binomial(link = \"probit\"),\n                  data = data.salarios)\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(index = predict(reg_heckit_pe, .)) %&gt;% \n  mutate(imr = dnorm(index)/pnorm(index))\n\n\nreg_heckit_se &lt;- lm(hrsocup ~ anios_esc+casada+eda+ly+imr,\n            data=filter(data.salarios,trabaja==1))\n\nsummary(reg_heckit_se)\n\n\nCall:\nlm(formula = hrsocup ~ anios_esc + casada + eda + ly + imr, data = filter(data.salarios, \n    trabaja == 1))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-46.172 -10.085   1.915   9.253  57.689 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 55.68676    2.17948  25.550  &lt; 2e-16 ***\nanios_esc    1.04814    0.10000  10.481  &lt; 2e-16 ***\ncasada      -3.56927    0.78057  -4.573 5.17e-06 ***\neda          0.11621    0.03904   2.977  0.00296 ** \nly          -9.82971    0.60406 -16.273  &lt; 2e-16 ***\nimr         -3.94669    3.62684  -1.088  0.27667    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.86 on 1693 degrees of freedom\nMultiple R-squared:  0.1563, Adjusted R-squared:  0.1539 \nF-statistic: 62.75 on 5 and 1693 DF,  p-value: &lt; 2.2e-16\n\n\nComparamos coeficientes (aquí stargazer lo hace mejor):\nstargazer(reg_heckit_mv, reg_heckit_se,\n          type=\"html\", \n          df=FALSE,\n          digits=4)\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nhrsocup\n\n\n\n\n\n\nHeckman\n\n\nOLS\n\n\n\n\n\n\nselection\n\n\n\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nanios_esc\n\n\n1.0482***\n\n\n1.0481***\n\n\n\n\n\n\n(0.0999)\n\n\n(0.1000)\n\n\n\n\n\n\n\n\n\n\n\n\ncasada\n\n\n-3.5886***\n\n\n-3.5693***\n\n\n\n\n\n\n(0.7797)\n\n\n(0.7806)\n\n\n\n\n\n\n\n\n\n\n\n\neda\n\n\n0.1161***\n\n\n0.1162***\n\n\n\n\n\n\n(0.0390)\n\n\n(0.0390)\n\n\n\n\n\n\n\n\n\n\n\n\nly\n\n\n-9.8342***\n\n\n-9.8297***\n\n\n\n\n\n\n(0.6039)\n\n\n(0.6041)\n\n\n\n\n\n\n\n\n\n\n\n\nimr\n\n\n\n\n-3.9467\n\n\n\n\n\n\n\n\n(3.6268)\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n55.6247***\n\n\n55.6868***\n\n\n\n\n\n\n(2.1766)\n\n\n(2.1795)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n2,625\n\n\n1,699\n\n\n\n\nR2\n\n\n0.1563\n\n\n\n\n\n\nAdjusted R2\n\n\n0.1539\n\n\n\n\n\n\nResidual Std. Error\n\n\n\n\n14.8614\n\n\n\n\nF Statistic\n\n\n\n\n62.7490***\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\nLa magnitud de los coeficientes es práctiamente la misma entre el modelo estimado por máxima verosimilitud y con un procedimiento en dos etapas a mano. En este ejemplo las diferencias son sutiles, aunque recordemos que en general la estimación por MV es más eficiente si la verosimilitud está bien planteada."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-1",
    "href": "tareas/tarea-2-respuestas.html#pregunta-1",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "Considere el modelo Poisson visto en clase y un vector de variables explicativas \\(x\\), todas continuas, usadas para parametrizar la media.\n\n[1 puntos] ¿Cuál es el efecto de un cambio en el \\(j\\)ésimo regresor sobre \\(E(y│x)\\)?\nCon un modelo Poisson parametrizamos la media como \\(\\mu=exp(x'\\beta)\\). En este caso, un cambio en un regresor \\(j\\) tiene el efecto:\n\\[\\frac{\\partial E(y|x)}{\\partial x_j}=\\beta_j exp(x'\\beta)\\]\nEs decir, un cambio en una unidad de \\(x_j\\) produce un cambio en el conteo esperado de \\(y\\) igual a \\(\\beta_j exp(x'\\beta)\\) unidades.\n[2 puntos] Usando esta expresión, muestre que si el \\(j\\)ésimo regresor es \\(x_j\\), entonces \\(100 \\beta_j\\) es la semielasticidad de \\(E(y│x)\\) con respecto a \\(x_j\\). Nota: Este punto es muy útil para la interpretación de los coeficientes de un modelo Poisson.\nResolviendo para \\(\\beta_j\\) en la expresión que acabamos de encontrar:\n\\[\\beta_j=\\frac{\\partial E(y|x)}{\\partial x_j}\\frac{1}{\\exp(x'\\beta)}\\]\nReconociendo que\n\\[\\beta_j=\\frac{\\partial E(y|x)}{\\partial x_j}\\frac{1}{\\exp(x'\\beta)}=\\frac{\\partial E(y|x)}{\\partial x_j}\\frac{1}{E(y|x)}=\\frac{\\partial\\ln E(y|x)}{\\partial x_j}\\]\n\\(\\frac{\\partial\\ln E(y|x)}{\\partial x_j}\\) es una semileasticidad, es decir un cambio marginal de \\(x_j\\) se asocia con un cambio porcentual en la media condicional igual a \\(100\\beta_j\\Delta x_j\\).\n[2 puntos] ¿Cómo se interpreta \\(\\beta_j\\) si reemplazamos \\(x_j\\) por \\(\\log(x_j)\\))?\nSi ahora el regresor de interés entra en el índice como un logaritmo: \\[\\beta_j=\\frac{\\partial E(y|x)}{\\partial x_j}\\frac{x_j}{E(y|x)}\\]\nla defnición de una elasticidad."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-2.-modelo-en-dos-partes-o-de-valla",
    "href": "tareas/tarea-2-respuestas.html#pregunta-2.-modelo-en-dos-partes-o-de-valla",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "En esta pregunta mostrará cómo para un modelo en dos partes Poisson la log verosimilitud del problema es la suma de log verosimilitud para un proceso binario y la log verosimilitud de un proceso Poisson truncado en cero. Considere una variable aleatoria \\(Y\\) con observaciones iid que sigue una distribución Poisson con parámetro \\(\\lambda\\) tal que\n\\[f(y,\\lambda)=P(Y=y)=\\frac{\\lambda^y exp(-\\lambda)}{y!}\\]\n\n[4 puntos] Obtenga la distribución Poisson truncada en cero, definida como \\(P(Y=y|Y&gt;0)\\).\nSabemos que la distribución truncada en cero es:\n\\[P(Y=y|Y&gt;0)=\\frac{f(y,\\lambda)}{1-f(0,\\lambda)}\\]\nSustituyendo la forma de la densidad Poisson:\n\\[P(Y=y|Y&gt;0)=\\frac{\\frac{\\lambda^y exp(-\\lambda)}{y!}}{1-exp(-\\lambda)}=\\frac{\\lambda^y}{y!(exp(\\lambda)-1)}\\]\n[4 puntos] Considere además un proceso binomial que modela la probabilidad de que la variable \\(Y\\) tome un valor cero o un valor positivo, como sigue:\n\\[P(Y=y)=\\begin{cases} \\pi \\quad\\quad y=0 \\\\ 1-\\pi\\quad\\quad y=1,2,3,\\ldots \\end{cases} \\]\nEn clase vimos la forma general del modelo en dos partes:\n\\[\ng(y)=\n\\begin{cases}\nf_1(0) \\quad\\text{si }y=0 \\\\\n\\frac{(1-f_1(0))f_2(y)}{1-f_2(0)}\\quad\\text{si }y\\geq 1\n\\end{cases}\n\\]\nEspecialice forma general del modelo de dos partes usando la distribución truncada derivada en a. y el proceso binomial definido arriba para obtener una función de masa de probabilidad no condicional para \\(Y\\), \\(g(y)\\).\nSea \\(\\pi\\) la probabilidad de observar un conteo igual a cero, especializamos la función vista en clase, incorporando la distribución truncada encontrada en la parte a.:\n\\[\ng(y)=\n\\begin{cases}\n\\pi \\quad\\text{si }y=0 \\\\\n(1-\\pi)\\frac{\\lambda^y}{y!(exp(\\lambda)-1)} \\quad\\text{si }y\\geq 1\n\\end{cases}\n\\]\n[4 puntos] Obtenga la log verosimilitud para la \\(i\\)ésima observación. Se sugiere que continúe sus cálculos con una ecuación en dos partes.\nLa log verosimilitud de la \\(i\\)ésima observación es:\n\\[\n\\mathcal{l}_i(\\pi,\\lambda,y_i)=\n\\begin{cases}\n\\ln(\\pi) \\quad\\text{si }y=0 \\\\\n\\ln\\left((1-\\pi)\\frac{\\lambda^{y_i}}{y!(exp(\\lambda)-1)}\\right) \\quad\\text{si }y\\geq 1\n\\end{cases}\n\\]\n[4 puntos] En este problema, parametrizaremos \\(\\lambda_i\\) como \\(\\lambda_i=exp(x_i'\\beta_2)\\), como regularmente lo hemos hecho en una regresión Poisson. Por otro lado, podemos trabajar con una parametrización general de la probabilidad \\(\\pi\\), \\(\\pi=F(x_i'\\beta_1)\\). Escriba la función de log verosimilitud del problema usando la parametrización para \\(\\pi_i\\) y para \\(\\lambda_i\\) que acabamos de describir. Presente esta función en una sola parte.\nCon la parametrización dada, podemos reescribir la log verosimilitud de una observación como:\n\\[\n\\mathcal{l}_i(\\pi,\\lambda,y_i)=\n\\begin{cases}\n\\ln(F(x_i'\\beta_1)) \\quad\\text{si }y=0 \\\\\n\\ln\\left((1-F(x_i'\\beta_1))\\frac{exp(x_i'\\beta_2)^{y_i}}{y!(exp(exp(x_i'\\beta_2))-1)} \\right) \\quad\\text{si }y\\geq 1\n\\end{cases}\n\\]\nLa log verosimilitud del problema es la probabilidad de observar los datos. Con la parametrización anterior:\n\\[\n\\mathcal{L}(\\beta_1,\\beta_2,y_i)=\\ln\\left(\\prod_{i\\in y_i=0}F(x_i'\\beta_1)\\prod_{i\\in y_i&gt;0}(1-F(x_i'\\beta_1))\\prod_{i\\in y_i&gt;0}\\frac{exp(x_i'\\beta_2)^{y_i}}{y!(exp(exp(x_i'\\beta_2))-1)} \\right)\n\\]\nDistribuyendo el logarítmo:\n\\[\n\\begin{align}\n\\mathcal{L}(\\beta_1,\\beta_2,y_i)&=\\sum_{i\\in y_i=0}\\ln(F(x_i'\\beta_1))+\\sum_{i\\in y_i&gt;0}\\ln\\left(1-F(x_i'\\beta_1)\\right)+ \\\\\n&+\\sum_{i\\in y_i&gt;0}x_i'\\beta_2y_i-\\sum_{i\\in y_i&gt;0}\\ln\\left(exp(exp(x_i'\\beta_2))-1\\right)-\\sum_{i\\in y_i&gt;0}y!\n\\end{align}\n\\]\n[4 puntos] Agrupe los términos para mostrar que \\(\\mathcal{L}=\\mathcal{L}_1(\\beta_1)+\\mathcal{L}_2(\\beta_2)\\). Así, mostrará que la log verosimilitud del problema se puede descomponer en una log verosimilitud para el modelo binario y otra para el conteo truncado en cero. Por tanto, no perdemos información si estimamos los parámetros de la probabilidad binomial por un lado, y los de la distribución Poisson truncada en cero, por el otro.\nClaramente:\n\\[\n\\mathcal{L}(\\beta_1,\\beta_2,y_i)=\\mathcal{L_1}(\\beta_1,y_i)+\\mathcal{L_2}(\\beta_2,y_i)\n\\]\nes decir, la suma de dos log verosimilitudes, una de un proceso binario y otra para el modelo Poisson truncado en cero."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-3",
    "href": "tareas/tarea-2-respuestas.html#pregunta-3",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "Use los datos phd_articulos.csv, los cuales contienen información sobre el número de artículos publicados para una muestra de entonces estudiantes de doctorado. Nuestra variable de interés será el número de artículos art.\n\n[4 puntos] Estime un modelo Poisson que incluya variables dicotómicas para estudiantes mujeres (female) y para estudiantes casadas o casados (married), el número de hijos mejores de cinco años (kid5), el ranking de prestigio del doctorado (phd) y el número de artículos publicados por su mentor (mentor). Realice la estimación de la matriz de varianzas primero a partir de la varianza teórica que resulta de la igualdad de la matriz de información y luego usando una matriz de sándwich. Interprete los coeficientes estimados.\n\ndata.phd&lt;-read_csv(\"../files/phd_articulos.csv\",\n                          locale = locale(encoding =                \"latin1\"))\n\ndata.phd &lt;- data.phd %&gt;% \n  mutate(female=factor(female,\n                       levels=c('Male','Female')))\n\nmpoisson &lt;- glm(art ~ factor(female) + factor(married) + kid5 + phd + mentor,\n                family=\"poisson\",\n                data=data.phd)\n\nsummary(mpoisson)\n\n\nCall:\nglm(formula = art ~ factor(female) + factor(married) + kid5 + \n    phd + mentor, family = \"poisson\", data = data.phd)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            0.459860   0.093335   4.927 8.35e-07 ***\nfactor(female)Female  -0.224594   0.054613  -4.112 3.92e-05 ***\nfactor(married)Single -0.155243   0.061374  -2.529   0.0114 *  \nkid5                  -0.184883   0.040127  -4.607 4.08e-06 ***\nphd                    0.012823   0.026397   0.486   0.6271    \nmentor                 0.025543   0.002006  12.733  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 1817.4  on 914  degrees of freedom\nResidual deviance: 1634.4  on 909  degrees of freedom\nAIC: 3314.1\n\nNumber of Fisher Scoring iterations: 5\n\n\nPresentamos errores heterocedásticos y robustos a la heterocedasticidad. Aquí les muestro otro paquete que puede servirles para presentar resultados en trabajos y tesinas, alterntivo a stargazer, modelsummary:\n\nmodelsummary(list(mpoisson, mpoisson),\n             vcov = list('classical', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n\n\n\n\n (1)\n  (2)\n\n\n\n\n(Intercept)\n0.460***\n0.460***\n\n\n\n(0.093)\n(0.151)\n\n\nfactor(female)Female\n-0.225***\n-0.225***\n\n\n\n(0.055)\n(0.072)\n\n\nfactor(married)Single\n-0.155**\n-0.155*\n\n\n\n(0.061)\n(0.083)\n\n\nkid5\n-0.185***\n-0.185***\n\n\n\n(0.040)\n(0.057)\n\n\nphd\n0.013\n0.013\n\n\n\n(0.026)\n(0.044)\n\n\nmentor\n0.026***\n0.026***\n\n\n\n(0.002)\n(0.004)\n\n\nNum.Obs.\n915\n915\n\n\nAIC\n3314.1\n3314.1\n\n\nBIC\n3343.0\n3343.0\n\n\nLog.Lik.\n-1651.056\n-1651.056\n\n\nF\n43.333\n14.855\n\n\nRMSE\n1.84\n1.84\n\n\nStd.Errors\nIID\nHC3\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n\nPara las variables continuas, como el número de artículos publicados por el mentor, la interpretación es el cambio en el log conteo esperado. En este caso, un artículo más publicado por el mentor incrementa el log conteo esperado en 0.026. También sabemos que los coeficientes tienen una interpretación de semielasticidad; en este caso, la semielasticidad del conteo con respecto al número de artículos publicados es 0.026. Para las variables dicotómicas, por ejemplo female, la interpretación es la diferencia entre el log conteo esperado entre mujeres y la categoría base (hombres).\n[5 puntos] Obtenga la razón de tasas de incidencia (IRR) para los coeficientes e interprete los resultados.\n\nexp(summary(mpoisson)$coef)\n\n                       Estimate Std. Error      z value Pr(&gt;|z|)\n(Intercept)           1.5838526   1.097829 1.379638e+02 1.000001\nfactor(female)Female  0.7988403   1.056132 1.636793e-02 1.000039\nfactor(married)Single 0.8562068   1.063297 7.970295e-02 1.011490\nkid5                  0.8312018   1.040943 9.977222e-03 1.000004\nphd                   1.0129051   1.026749 1.625407e+00 1.872246\nmentor                1.0258718   1.002008 3.386456e+05 1.000000\n\n\nAunque esto también puede hacerse directamente en modelsummary:\n\nmodelsummary(list(mpoisson, mpoisson),\n             exponentiate = TRUE,\n             vcov = list('classical', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n\n\n\n\n (1)\n  (2)\n\n\n\n\n(Intercept)\n1.584***\n1.584***\n\n\n\n(0.148)\n(0.240)\n\n\nfactor(female)Female\n0.799***\n0.799***\n\n\n\n(0.044)\n(0.058)\n\n\nfactor(married)Single\n0.856**\n0.856*\n\n\n\n(0.053)\n(0.071)\n\n\nkid5\n0.831***\n0.831***\n\n\n\n(0.033)\n(0.047)\n\n\nphd\n1.013\n1.013\n\n\n\n(0.027)\n(0.045)\n\n\nmentor\n1.026***\n1.026***\n\n\n\n(0.002)\n(0.004)\n\n\nNum.Obs.\n915\n915\n\n\nAIC\n3314.1\n3314.1\n\n\nBIC\n3343.0\n3343.0\n\n\nLog.Lik.\n-1651.056\n-1651.056\n\n\nF\n43.333\n14.855\n\n\nRMSE\n1.84\n1.84\n\n\nStd.Errors\nIID\nHC3\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n\nLa interpretación de los coeficientes se vuelve más sencilla usando irr. Para la variable continua mentor, un artículo más publicado por el mentor está asociado con 1.026 veces más artículos publicados por el estudiante, es decir, un 2.6% más artículos. En cambio, la variable dicotómica para mujeres indica que las mujeres publican 0.8 veces el número de artículos que los hombres.\n[3 puntos] Considere ahora que las mujeres han tenido carreras profesionales más cortas que los hombres, es decir, han estado menos expuestas a la ocurrencia de los eventos publicar. Incorpore esto al análisis y reinterprete los resultados. Pista: explore la opción offeset en glm de R. La columna profage mide la duración efectiva de las carreras profesionales de cada individuo.\nEl razonamiento es que ahora queremos conocer cuál es la tasa de publicación, es decir, \\(art/profage\\). Pero como nuestro podemos Poisson solo puede manejar conteos, podemos modificar el modelo para pasar la edad de la carrera del lado derecho:\n\\[\\begin{aligned}ln(art/profage)&=x'\\beta \\\\ ln(art)&=x'\\beta+\\ln(profage) \\end{aligned}\\]\n\nmpoisson_duracion &lt;- glm(art ~\n                  factor(female) + factor(married) + kid5 + phd + mentor,\n                  offset = log(profage),\n                  family=\"poisson\",\n                  data=data.phd)\n\nsummary(mpoisson_duracion)$coef\n\n                         Estimate  Std. Error     z value      Pr(&gt;|z|)\n(Intercept)           -2.95404558 0.093812104 -31.4889600 1.230266e-217\nfactor(female)Female   0.45874678 0.054721432   8.3833109  5.145931e-17\nfactor(married)Single -0.15598278 0.061347334  -2.5426171  1.100257e-02\nkid5                  -0.18643454 0.040135522  -4.6451256  3.398696e-06\nphd                    0.01801602 0.026428953   0.6816773  4.954430e-01\nmentor                 0.02573493 0.002001731  12.8563329  7.924799e-38\n\n\nHasta ahora hemos asumido que cada individuo ha estado “en riesgo” de publicar por el mismo periodo de tiempo, lo cual puede ser no cierto si, por ejemplo, algunos estudiantes se graduaron antes, o si otros han tenido pausas en sus carreras. Al controlar por el hecho de que las mujeres han tenido carreras más cortas, la variable female deja de ser negativa y se convierte en positiva. Las mujeres publican más que los hombres al tomar en cuenta la duración de las carreras.\nComparando los tres modelos:\n\nmodelsummary(list(mpoisson, mpoisson, mpoisson_duracion),\n             vcov = list('classical', 'robust', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n\n\n\n\n (1)\n  (2)\n  (3)\n\n\n\n\n(Intercept)\n0.460***\n0.460***\n-2.954***\n\n\n\n(0.093)\n(0.151)\n(0.155)\n\n\nfactor(female)Female\n-0.225***\n-0.225***\n0.459***\n\n\n\n(0.055)\n(0.072)\n(0.073)\n\n\nfactor(married)Single\n-0.155**\n-0.155*\n-0.156*\n\n\n\n(0.061)\n(0.083)\n(0.083)\n\n\nkid5\n-0.185***\n-0.185***\n-0.186***\n\n\n\n(0.040)\n(0.057)\n(0.057)\n\n\nphd\n0.013\n0.013\n0.018\n\n\n\n(0.026)\n(0.044)\n(0.045)\n\n\nmentor\n0.026***\n0.026***\n0.026***\n\n\n\n(0.002)\n(0.004)\n(0.005)\n\n\nNum.Obs.\n915\n915\n915\n\n\nAIC\n3314.1\n3314.1\n3322.8\n\n\nBIC\n3343.0\n3343.0\n3351.7\n\n\nLog.Lik.\n-1651.056\n-1651.056\n-1655.393\n\n\nF\n43.333\n14.855\n20.311\n\n\nRMSE\n1.84\n1.84\n1.85\n\n\nStd.Errors\nIID\nHC3\nHC3\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n\n\n[3 puntos] Emplee ahora un modelo negativo binomial con sobredispersión cuadrática en la media para estimar la relación entre el número de artículos publicados y las variables explicativas antes enumeradas. Interprete el coeficiente asociado al número de hijos y a la variable dicotómica para estudiantes mujeres. ¿Qué puede decir sobre la significancia del \\(\\alpha\\) estimado?\n\nmnb2 &lt;- MASS::glm.nb(art ~\n                 factor(female) + factor(married) + kid5 + phd + mentor,\n                 data = data.phd)\nsummary(mnb2)\n\n\nCall:\nMASS::glm.nb(formula = art ~ factor(female) + factor(married) + \n    kid5 + phd + mentor, data = data.phd, init.theta = 2.264387695, \n    link = log)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            0.406633   0.125778   3.233 0.001225 ** \nfactor(female)Female  -0.216418   0.072636  -2.979 0.002887 ** \nfactor(married)Single -0.150489   0.082097  -1.833 0.066791 .  \nkid5                  -0.176415   0.052813  -3.340 0.000837 ***\nphd                    0.015271   0.035873   0.426 0.670326    \nmentor                 0.029082   0.003214   9.048  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(2.2644) family taken to be 1)\n\n    Null deviance: 1109.0  on 914  degrees of freedom\nResidual deviance: 1004.3  on 909  degrees of freedom\nAIC: 3135.9\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  2.264 \n          Std. Err.:  0.271 \n\n 2 x log-likelihood:  -3121.917 \n\n\nPonemos todo junto:\n\nmodelsummary(list(mpoisson, mpoisson, mpoisson_duracion, mnb2),\n             vcov = list('classical', 'robust', 'robust', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n\n\n\n\n (1)\n  (2)\n  (3)\n  (4)\n\n\n\n\n(Intercept)\n0.460***\n0.460***\n-2.954***\n0.407***\n\n\n\n(0.093)\n(0.151)\n(0.155)\n(0.135)\n\n\nfactor(female)Female\n-0.225***\n-0.225***\n0.459***\n-0.216***\n\n\n\n(0.055)\n(0.072)\n(0.073)\n(0.071)\n\n\nfactor(married)Single\n-0.155**\n-0.155*\n-0.156*\n-0.150*\n\n\n\n(0.061)\n(0.083)\n(0.083)\n(0.081)\n\n\nkid5\n-0.185***\n-0.185***\n-0.186***\n-0.176***\n\n\n\n(0.040)\n(0.057)\n(0.057)\n(0.053)\n\n\nphd\n0.013\n0.013\n0.018\n0.015\n\n\n\n(0.026)\n(0.044)\n(0.045)\n(0.038)\n\n\nmentor\n0.026***\n0.026***\n0.026***\n0.029***\n\n\n\n(0.002)\n(0.004)\n(0.005)\n(0.003)\n\n\nNum.Obs.\n915\n915\n915\n915\n\n\nAIC\n3314.1\n3314.1\n3322.8\n3135.9\n\n\nBIC\n3343.0\n3343.0\n3351.7\n3169.6\n\n\nLog.Lik.\n-1651.056\n-1651.056\n-1655.393\n-1560.958\n\n\nF\n43.333\n14.855\n20.311\n20.935\n\n\nRMSE\n1.84\n1.84\n1.85\n1.86\n\n\nStd.Errors\nIID\nHC3\nHC3\nHC3\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n\n\n\nA diferencia de otros paquetes, glm.nb reporta \\(\\theta=1/\\alpha\\):\n\n(alpha &lt;- 1/summary(mnb2)$theta)        \n\n[1] 0.4416205\n\n\nEste es el modelo NB2 visto en clase y la forma más usada para implementar un modelo negativo binomial. Se asume una sobredispersión cuadrática en la media, con la varianza parametrizada usando \\(\\alpha\\). La interpretación de los coeficientes se mantiene con respecto al modelo Poisson. Los coeficientes tienen magnitudes similares, pero se prefiere el modelo NB2 si el propósito es pronóstico pues toma en cuenta la sobredispersión y le da suficiente flexibilidad a la varianza para depender de manera cuadrática de la media.\nUn poco más cuidado hay que poner en \\(\\alpha\\). En este caso, \\(\\hat{\\alpha}=0.44\\). Pero noten que lo que se reporta es el error estándar de \\(\\theta\\). Como platicamos en clase, con un estadístico podemos hacer un test y obtener un valor \\(p\\), pero una función no lineal del mismo puede que no tenga el mismo valor \\(p\\). Esto ocurre aquí, deberíamos recurrir al método delta para calcular el error estándar de \\(\\alpha\\)."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-4",
    "href": "tareas/tarea-2-respuestas.html#pregunta-4",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "Retome los datos del archivo motral2012.csv usado en la Tarea 1. Estimará un modelo Tobit para explicar los factores que afectan la oferta laboral femenina. En este archivo de datos la variable hrsocup registra las horas trabajadas a la semana.\n\n[2 punto] ¿Qué proporción de la muestra femenina reporta horas trabajadas iguales a cero?\nSi hacemos una dummy de horas positivas, al sacarle la media obtenemos la proporción.\n\ndata.salarios&lt;-read_csv(\"../files/motral2012.csv\",\n                          locale = locale(encoding = \"latin1\")) \n\ndata.salarios &lt;- data.salarios %&gt;% \n  filter(sex==2) %&gt;% \n  mutate(zerohrs=ifelse(hrsocup==0,1,0))\n\nsummary(data.salarios$zerohrs)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.3528  1.0000  1.0000 \n\n\nEl 35% de las observaciones tienen cero horas trabajadas.\n[3 puntos] Se desea estimar el efecto de los años de educación (anios_esc) sobre la oferta laboral femenina controlando por el estado marital (casada), la edad (eda) y el número de hijos (n_hij) como una variable continua. En la base, e_con toma el valor de 5 para las personas casadas. Genere la variable dummy casada que tome el valor de 1 para las mujeres casadas y cero en otro caso. Estime un modelo de MCO para hrsocup mayor que cero, usando solo la población femenina. Reporte errores robustos. ¿Cuál es la interpretación sobre el coeficiente de los años de escolaridad?\nEl estimar por MCO, un año más de escolaridad se asocia con 0.17 horas trabajadas más a la semana. Sin embargo, este efecto no es estadísticamente significativo.\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(casada=ifelse(e_con==5,1,0))\n\nreg_mco &lt;- lm(hrsocup ~ anios_esc+casada+eda+n_hij,\n          data=filter(data.salarios,hrsocup&gt;0))\n\ncoeftest(reg_mco,\n         vcov = vcovHC(reg_mco, \"HC1\"))[1:4,]\n\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 36.70129720 1.99116828 18.432042 2.742336e-69\nanios_esc    0.17465627 0.10353350  1.686954 9.179628e-02\ncasada      -3.52571327 0.89724706 -3.929479 8.855253e-05\neda          0.06949593 0.04914655  1.414055 1.575295e-01\n\n\nCon modelsummary podemos hacer pedir la tabla de coeficientes. Podemos especificar qué tipo de errores robustos queremos en la opción vcov:\n\nmodelsummary(list(reg_mco, reg_mco),\n             vcov = list('classical', 'HC1'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n\n\n\n\n (1)\n  (2)\n\n\n\n\n(Intercept)\n36.701***\n36.701***\n\n\n\n(1.959)\n(1.991)\n\n\nanios_esc\n0.175*\n0.175*\n\n\n\n(0.104)\n(0.104)\n\n\ncasada\n-3.526***\n-3.526***\n\n\n\n(0.862)\n(0.897)\n\n\neda\n0.069\n0.069\n\n\n\n(0.047)\n(0.049)\n\n\nn_hij\n-1.149***\n-1.149***\n\n\n\n(0.336)\n(0.372)\n\n\nNum.Obs.\n1699\n1699\n\n\nR2\n0.030\n0.030\n\n\nR2 Adj.\n0.028\n0.028\n\n\nAIC\n14234.8\n14234.8\n\n\nBIC\n14267.4\n14267.4\n\n\nLog.Lik.\n-7111.383\n-7111.383\n\n\nF\n13.171\n12.526\n\n\nRMSE\n15.91\n15.91\n\n\nStd.Errors\nIID\nHC1\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n\n[3 puntos] ¿Qué problema existe con el modelo planteado en el punto anterior en términos de la selección? ¿Considera que se trata de un caso de censura o de truncamiento?\nPodemos racionalizar las horas trabajadas en un modelo microeconómico de oferta laboral. Las horas trabajadas observadas son positivas cuando la solución óptima es una cantidad positiva de horas. Sin embargo, si la solución óptima implicara horas negativas, las horas observadas serían cero. En este caso tenemos datos censurados en cero. Si existe una relación positiva entre educación y horas trabajadas, al estimar un modelo por MCO usando solo los datos con horas positivas estamos sobreestimando la media condicional pues se habrán omitido del análisis aquellas mujeres cuya solución a su problema de optimización eran horas iguales a cero o negativas.\n[8 puntos] Estime un modelo Tobit de datos censurados. ¿Qué resuelve el modelo Tobit en este caso? Interprete nuevamente el coeficiente sobre los años de escolaridad.\nLa función tobit permite hacer esto muy fácilmente. Noten que left especifica dónde está la censura. La opción gaussian pone explícito uno de los supuestos críticos del modelo tobit visto en clase: errores normales. Además, se asume homocedasticidad.\n\nreg_tobit &lt;- tobit(hrsocup ~ anios_esc+casada+eda+n_hij,\n               left = 0,\n               right = Inf,\n               dist = \"gaussian\",\n               data = data.salarios)\n\nsummary(reg_tobit)\n\n\nCall:\ntobit(formula = hrsocup ~ anios_esc + casada + eda + n_hij, left = 0, \n    right = Inf, dist = \"gaussian\", data = data.salarios)\n\nObservations:\n         Total  Left-censored     Uncensored Right-censored \n          2625            926           1699              0 \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.88236    3.19905   0.276  0.78269    \nanios_esc     0.85530    0.17509   4.885 1.04e-06 ***\ncasada      -10.99515    1.43025  -7.688 1.50e-14 ***\neda           0.41621    0.07665   5.430 5.64e-08 ***\nn_hij        -1.73840    0.55887  -3.111  0.00187 ** \nLog(scale)    3.44512    0.01887 182.608  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nScale: 31.35 \n\nGaussian distribution\nNumber of Newton-Raphson Iterations: 3 \nLog-likelihood: -9086 on 6 Df\nWald-statistic: 127.9 on 4 Df, p-value: &lt; 2.22e-16 \n\n\nEl modelo tobit para datos censurados toma en cuenta que hay una masa de ceros en las horas trabajadas para individuos para los que disponemos de sus características en la base de datos. El modelo tobit ajusta la probabilidad de observar esta masa de ceros. El coeficiente estimado será ahora consistente si el modelo está bien especificado, es decir, si el proceso subyacente es lineal en los parámetros y con un error normal homoscedástico (los supuestos de tobit básico). En este caso, un año más de educación se asocia con 0.85 más horas semanales trabajadas, un efecto estadísticamente significativo. Usar MCO subestimaba el efecto de la escolaridad.\nmodelsummary acepta la salida de la función tobit:\n\nmodelsummary(list(reg_mco, reg_mco, reg_tobit),\n             vcov = list('classical', 'HC1', 'classical'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n\n\n\n\n (1)\n  (2)\n  (3)\n\n\n\n\n(Intercept)\n36.701***\n36.701***\n0.882\n\n\n\n(1.959)\n(1.991)\n(3.199)\n\n\nanios_esc\n0.175*\n0.175*\n0.855***\n\n\n\n(0.104)\n(0.104)\n(0.175)\n\n\ncasada\n-3.526***\n-3.526***\n-10.995***\n\n\n\n(0.862)\n(0.897)\n(1.430)\n\n\neda\n0.069\n0.069\n0.416***\n\n\n\n(0.047)\n(0.049)\n(0.077)\n\n\nn_hij\n-1.149***\n-1.149***\n-1.738***\n\n\n\n(0.336)\n(0.372)\n(0.559)\n\n\nNum.Obs.\n1699\n1699\n2625\n\n\nR2\n0.030\n0.030\n\n\n\nR2 Adj.\n0.028\n0.028\n\n\n\nAIC\n14234.8\n14234.8\n18184.9\n\n\nBIC\n14267.4\n14267.4\n18220.1\n\n\nLog.Lik.\n-7111.383\n-7111.383\n\n\n\nF\n13.171\n12.526\n\n\n\nRMSE\n15.91\n15.91\n23.02\n\n\nStd.Errors\nIID\nHC1\nIID\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n\n\n[4 puntos] ¿Cuál es el efecto marginal de un incremento de un año de educación en la oferta laboral? ¿Cómo cambia su respuesta si, en lugar de considerar la variable latente, considera la variable censurada?\nEl efecto marginal en la variable latente es directamente el coficiente estimado en la parte d., es decir 0.855.\nEl efecto marginal en la media censurada está dado por:\n\\[\\frac{\\partial E(y|x)}{\\partial x_j}=\\beta_j\\Phi(x_i'\\beta)\\]\nLo que hice aquí fue calcular este efecto marginal para cada individuo y luego obtener el promedio de los efectos marginales en aquellos individuos con horas positivas.\n\ndata.salarios &lt;- data.salarios %&gt;%\n  mutate(index1=predict(reg_tobit,.)) %&gt;% \n  mutate(phi=pnorm(index1/reg_tobit$scale)) %&gt;% \n  mutate(mfx_anis_esc=reg_tobit$coefficients[2]*phi,\n         mfx_eda=reg_tobit$coefficients[4]*phi,\n         mfx_n_hij=reg_tobit$coefficients[5]*phi)\n\ndata.salarios %&gt;%\n  filter(hrsocup&gt;0) %&gt;% \n  summarise(mfx_anis_esc=mean(mfx_anis_esc)) \n\n# A tibble: 1 × 1\n  mfx_anis_esc\n         &lt;dbl&gt;\n1        0.612"
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-5",
    "href": "tareas/tarea-2-respuestas.html#pregunta-5",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "Usando los mismos datos del archivo motral2012.csv implementará un ejercicio en el mismo espíritu del famoso estudio de Mroz (1987)1 sobre la oferta laboral femenina. El propósito es estimar la relación entre el salario y el número de horas trabajadas, concentrándonos en la muestra de mujeres.\n\n[5 puntos] El primer problema al que nos enfrentamos es que el salario no se observa para las mujeres que no trabajan. Estime un modelo lineal para el log del salario por hora, ing_x_hrs, usando las variables anios_esc, eda, n_hij, el cuadrado de n_hij, busqueda y casada, usando la submuestra de mujeres con salario por hora positivo. Dichas variables representan los años de escolaridad, la edad, el número de hijos, el cuadrado del número de hijos, si la persona buscó trabajo recientemente y si la persona es casada, respectivamente. Use los coeficientes estimados para imputar el ingreso por hora, faltante para las mujeres que reportan 0 en las horas trabajadas.\nImputamos el salario faltante:\n\ndata.salarios&lt;-read_csv(\"../files/motral2012.csv\",\n                        locale = locale(encoding = \"latin1\")) %&gt;%\n  filter(sex==2) %&gt;% \n  mutate(casada=ifelse(e_con==5,1,0))\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(ly=ifelse(ing_x_hrs&gt;0,log(ing_x_hrs),NA)) \n\nreg_imput &lt;- lm(ly ~ anios_esc+casada+eda+n_hij+n_hij^2+busqueda,\n              data = data.salarios)\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(lyhat = predict(reg_imput, .)) %&gt;% \n  mutate(ly = ifelse(is.na(ly), lyhat, ly))\n\nAquí tomé en cuenta que hay personas con horas trabajadas positivas e ingreso cero. En ese caso puse un NA al log del salario. Luego, en la imputación, le asigné el valor ajustado a estas observaciones junto con todas las que tienen el log del salario faltante.\n[5 puntos] Use heckit de la librería sampleSelection para estimar por máxima verosimilitud un heckit para las horas trabajadas hrsocup. En la ecuación de selección (si la persona trabaja o no) incluya como variable explicativa el salario por hora (imputado para las mujeres que no trabajan), además de anios_esc, eda, n_hij, el cuadrado de n_hij, casada y busqueda (esta última es un indicador de si se buscó trabajo en la última semana). En la ecuación de horas, incluya los mismos regresores, excepto n_hij, su cuadrado y busqueda.\nLa función heckit permite estimar el modelo de Heckman por máxima verosimilitud de manera muy simple. Hay que especificar method=“ml” para que la estimación sea por máxima verosimilitud:\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(trabaja = ifelse(hrsocup&gt;0,1,0)) %&gt;% \n  mutate(trabaja = factor(trabaja,levels=c(0,1)))\n\nreg_heckit_mv &lt;- heckit(trabaja ~ anios_esc+casada+eda+ly+n_hij+n_hij^2+busqueda,\n                hrsocup ~ anios_esc+casada+eda+ly,\n                method=\"ml\",\n                data = data.salarios)\n\nsummary(reg_heckit_mv)\n\n--------------------------------------------\nTobit 2 model (sample selection model)\nMaximum Likelihood estimation\nNewton-Raphson maximisation, 3 iterations\nReturn code 8: successive function values within relative tolerance limit (reltol)\nLog-Likelihood: -7181.675 \n2625 observations (926 censored and 1699 observed)\n14 free parameters (df = 2611)\nProbit selection equation:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.583614   0.448320  -5.763 9.24e-09 ***\nanios_esc    0.005346   0.020341   0.263    0.793    \ncasada      -0.213125   0.145135  -1.468    0.142    \neda         -0.003391   0.008137  -0.417    0.677    \nly          -0.004236   0.133344  -0.032    0.975    \nn_hij        0.023985   0.058900   0.407    0.684    \nbusqueda     2.406669   0.104595  23.009  &lt; 2e-16 ***\nOutcome equation:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 55.62469    2.17656  25.556  &lt; 2e-16 ***\nanios_esc    1.04819    0.09995  10.487  &lt; 2e-16 ***\ncasada      -3.58856    0.77967  -4.603 4.37e-06 ***\neda          0.11614    0.03902   2.977  0.00294 ** \nly          -9.83418    0.60389 -16.285  &lt; 2e-16 ***\n   Error terms:\n      Estimate Std. Error t value Pr(&gt;|t|)    \nsigma  14.8579     0.2591  57.350   &lt;2e-16 ***\nrho    -0.1606     0.1964  -0.818    0.414    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n--------------------------------------------\n\n\nPodemos reportar con modelsummary, aunque realmente lo hace muy mal:\n\nmodelsummary(list(reg_heckit_mv),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n\n\n\n\n (1)\n\n\n\n\n(Intercept)\n-2.584***\n\n\n\n55.625***\n\n\n\n(0.448)\n\n\n\n(2.177)\n\n\nanios_esc\n0.005\n\n\n\n1.048***\n\n\n\n(0.020)\n\n\n\n(0.100)\n\n\ncasada\n-0.213\n\n\n\n-3.589***\n\n\n\n(0.145)\n\n\n\n(0.780)\n\n\neda\n-0.003\n\n\n\n0.116***\n\n\n\n(0.008)\n\n\n\n(0.039)\n\n\nly\n-0.004\n\n\n\n-9.834***\n\n\n\n(0.133)\n\n\n\n(0.604)\n\n\nn_hij\n0.024\n\n\n\n(0.059)\n\n\nbusqueda\n2.407***\n\n\n\n(0.105)\n\n\nsigma\n14.858***\n\n\n\n(0.259)\n\n\nrho\n-0.161\n\n\n\n(0.196)\n\n\nNum.Obs.\n2625\n\n\nAIC\n14391.4\n\n\nBIC\n14473.6\n\n\nRMSE\n14.84\n\n\n\n * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n\n\n\n\n\n\n\n\n\n[10 puntos] Estime ahora el heckit en dos pasos, a mano. Es decir, siga los siguientes pasos: i) estime un probit para la ecuación de selección y obtenga el índice \\(x_i'\\hat{\\beta}\\); ii) calcule el inverso de la razón de Mills \\(\\lambda_i(x_i'\\hat{\\beta})\\); y iii) estime por MCO la ecuación para las horas trabajadas con la submuestra que tiene horas trabajadas positivas, incluyendo como regresor el inverso de la razón de Mills estimado y el resto de los regresores. Compare los coeficientes y los errores estándar obtenidos en esta parte con los de la parte b. ¿Por qué son iguales o por qué difieren?\nEstimamos ahora el heckit a mano. Estimamos el probit y obtenemos el valor ajustado del IMR:\n\nreg_heckit_pe &lt;- glm(trabaja ~ anios_esc+casada+eda+ly+n_hij+n_hij^2+busqueda,\n                  family = binomial(link = \"probit\"),\n                  data = data.salarios)\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(index = predict(reg_heckit_pe, .)) %&gt;% \n  mutate(imr = dnorm(index)/pnorm(index))\n\n\nreg_heckit_se &lt;- lm(hrsocup ~ anios_esc+casada+eda+ly+imr,\n            data=filter(data.salarios,trabaja==1))\n\nsummary(reg_heckit_se)\n\n\nCall:\nlm(formula = hrsocup ~ anios_esc + casada + eda + ly + imr, data = filter(data.salarios, \n    trabaja == 1))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-46.172 -10.085   1.915   9.253  57.689 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 55.68676    2.17948  25.550  &lt; 2e-16 ***\nanios_esc    1.04814    0.10000  10.481  &lt; 2e-16 ***\ncasada      -3.56927    0.78057  -4.573 5.17e-06 ***\neda          0.11621    0.03904   2.977  0.00296 ** \nly          -9.82971    0.60406 -16.273  &lt; 2e-16 ***\nimr         -3.94669    3.62684  -1.088  0.27667    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.86 on 1693 degrees of freedom\nMultiple R-squared:  0.1563, Adjusted R-squared:  0.1539 \nF-statistic: 62.75 on 5 and 1693 DF,  p-value: &lt; 2.2e-16\n\n\nComparamos coeficientes (aquí stargazer lo hace mejor):\nstargazer(reg_heckit_mv, reg_heckit_se,\n          type=\"html\", \n          df=FALSE,\n          digits=4)\n\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nhrsocup\n\n\n\n\n\n\nHeckman\n\n\nOLS\n\n\n\n\n\n\nselection\n\n\n\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nanios_esc\n\n\n1.0482***\n\n\n1.0481***\n\n\n\n\n\n\n(0.0999)\n\n\n(0.1000)\n\n\n\n\n\n\n\n\n\n\n\n\ncasada\n\n\n-3.5886***\n\n\n-3.5693***\n\n\n\n\n\n\n(0.7797)\n\n\n(0.7806)\n\n\n\n\n\n\n\n\n\n\n\n\neda\n\n\n0.1161***\n\n\n0.1162***\n\n\n\n\n\n\n(0.0390)\n\n\n(0.0390)\n\n\n\n\n\n\n\n\n\n\n\n\nly\n\n\n-9.8342***\n\n\n-9.8297***\n\n\n\n\n\n\n(0.6039)\n\n\n(0.6041)\n\n\n\n\n\n\n\n\n\n\n\n\nimr\n\n\n\n\n-3.9467\n\n\n\n\n\n\n\n\n(3.6268)\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n55.6247***\n\n\n55.6868***\n\n\n\n\n\n\n(2.1766)\n\n\n(2.1795)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n2,625\n\n\n1,699\n\n\n\n\nR2\n\n\n0.1563\n\n\n\n\n\n\nAdjusted R2\n\n\n0.1539\n\n\n\n\n\n\nResidual Std. Error\n\n\n\n\n14.8614\n\n\n\n\nF Statistic\n\n\n\n\n62.7490***\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\n\nLa magnitud de los coeficientes es práctiamente la misma entre el modelo estimado por máxima verosimilitud y con un procedimiento en dos etapas a mano. En este ejemplo las diferencias son sutiles, aunque recordemos que en general la estimación por MV es más eficiente si la verosimilitud está bien planteada."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#footnotes",
    "href": "tareas/tarea-2-respuestas.html#footnotes",
    "title": "Respuestas a la tarea 2",
    "section": "Notas",
    "text": "Notas\n\n\nMroz, T. A. (1987). The sensitivity of an empirical model of married women’s hours of work to economic and statistical assumptions. Econometrica: Journal of the econometric society, 765-799.↩︎"
  },
  {
    "objectID": "tareas/tarea-3-respuestas.html",
    "href": "tareas/tarea-3-respuestas.html",
    "title": "Respuestas a la tarea 3",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = TRUE,\n                      warning = FALSE,\n                      message = FALSE,\n                      indent = \"   \")\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(sandwich)\nlibrary(clubSandwich)\nlibrary(plm)\nlibrary(stargazer)\nlibrary(lmtest)\nlibrary(AER)\nlibrary(Rxtsum)\n\n\n\nEn este ejercicio continuaremos usando los datos del estudio de Card (1993) para estudiar los rendimientos a la educación. Los datos ingresos_iv.dta contiene una muestra de hombres de entre 24 y 36 años de edad. lwage es el logaritmo del ingreso y educ es la educación acumulada.\n\n[3 puntos] Estime una regresión por MCO para explicar el logaritmo del salario (lwage) en función de la educación educ y los siguientes controles: exper, expersq, black, south, smsa, reg661, reg662, reg663, reg664, reg665, reg666, reg667, reg668 y smsa66. Reporte errores clásicos y errores robustos. ¿Qué problema encuentra en la estimación de esta relación? ¿El coeficiente sobre educ tiene una interpretación causal del efecto de la educación en el salario?\nEstimamos por MCO la relación entre salarios y educación, controlando por un conjunto de regresores:\n\ndata.ingresos&lt;-read_csv(\"../files/ingresos_iv.csv\",\n                        locale = locale(encoding = \"latin1\"))\n\nregmco &lt;- lm(lwage ~ educ + exper + expersq + black + south + smsa + reg661 +\n              reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66,\n            data = data.ingresos)\n\nstargazer(regmco, regmco,\n          type = 'text',\n          se = list(NULL,\n                    sqrt(diag(vcovHC(regmco, type = \"HC0\")))),\n          keep = 'educ')\n\n\n============================================================\n                                    Dependent variable:     \n                                ----------------------------\n                                           lwage            \n                                     (1)            (2)     \n------------------------------------------------------------\neduc                               0.075***      0.075***   \n                                   (0.003)        (0.004)   \n\n------------------------------------------------------------\nObservations                        3,010          3,010    \nR2                                  0.300          0.300    \nAdjusted R2                         0.296          0.296    \nResidual Std. Error (df = 2994)     0.372          0.372    \nF Statistic (df = 15; 2994)       85.476***      85.476***  \n============================================================\nNote:                            *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nHay una relación de 7.4% mayor ingreso por cada año de educación adicional. Sin embargo, esta no es una relación causal pues es muy probable que la educación no sea exógena en la ecuación de salarios. Esto puede deberse, por ejemplo, a una variable omitida de habilidad que afecta tanto al número de años de educación alcanzados como al desempeño en el mercado de trabajo.\n[3 puntos] Se propone usar una variable dicotómica que indica si el individuo vivía cerca de una universidad cuando era niño, como instrumento de los años de educación. ¿Qué condiciones debe cumplir la variable propuesta para funcionar como instrumento válido?\nEl instrumento debe cumplir dos condiciones:\nExogeneidad: el instrumento no debe pertenecer a la ecuación de salarios. Es decir, el haber crecido cerca de una universidad no debe afectar el salario contemporáneo de forma directa.\nRelevancia: el instrumento debe estar correlacionado con la variable endógena. En este caso, haber crecido cerca de una universidad debe estar correlacionado con el número de años de educación completados.\n[4 puntos] ¿Cómo juzga la propuesta de usar la variable antes descrita como instrumento?\nEste argumento fue usado por Card (1995) para mostrar que los rendimientos a la educación están subestimados por un estimador de MCO. Card muestra que al usar variables instrumentales, el efecto estimado es de 25 a 60% más grande.\nNo hay una respuesta correcta o incorrecta. Quiero leer sus argumentos.\n[3 puntos] Estime la relación entre el logaritmo del salario y la educación usando la variable dicotómica de acceso a una universidad, nearc4, como instrumento. Emplee las mismas variables de control que en el modelo de MCO. Reporte errores clásicos y errores robustos.\n\nregvi &lt;- ivreg(lwage ~ educ + exper + expersq + black + south + smsa + reg661 +\n                 reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66  |\n                 nearc4 + exper + expersq + black + south + smsa + reg661 +\n                 reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66,\n               data=data.ingresos)\n\nstargazer(regmco, regmco, regvi, regvi,\n          type = 'text',\n          se = list(NULL,\n                    sqrt(diag(vcovHC(regmco, type = \"HC0\"))),\n                    NULL,\n                    sqrt(diag(vcovHC(regvi, type = \"HC0\")))),\n          keep = 'educ')\n\n\n===================================================================\n                                        Dependent variable:        \n                                -----------------------------------\n                                               lwage               \n                                        OLS          instrumental  \n                                                       variable    \n                                   (1)       (2)      (3)     (4)  \n-------------------------------------------------------------------\neduc                            0.075***  0.075***  0.132** 0.132**\n                                 (0.003)   (0.004)  (0.055) (0.054)\n\n-------------------------------------------------------------------\nObservations                      3,010     3,010    3,010   3,010 \nR2                                0.300     0.300    0.238   0.238 \nAdjusted R2                       0.296     0.296    0.234   0.234 \nResidual Std. Error (df = 2994)   0.372     0.372    0.388   0.388 \nF Statistic (df = 15; 2994)     85.476*** 85.476***                \n===================================================================\nNote:                                   *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n[4 puntos] Interprete la primera etapa en términos del coeficiente sobre el instrumento. Obtenga el estadístico \\(F\\) del instrumento excluido e interprete su magnitud.\nEn la primera etapa, haber vivido cerca de una universidad incrementa en 0.32 los años de escolaridad acumulados. Este efecto estadísticamente significativo al 1%. El estadístico F es de una magnitud de 13.256, por encima de 10, la regla de dedo comúnmente empleada para juzgar la presencia de instrumentos débiles.\n\nregpe &lt;- lm(educ ~ nearc4 + exper + expersq + black + south + smsa + reg661 +\n              reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66,\n            data=data.ingresos)\n\nstargazer(regpe,\n          type = 'text',\n          se = list(sqrt(diag(vcovHC(regpe, type = \"HC0\")))),\n          keep = 'nearc4')\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                               educ            \n-----------------------------------------------\nnearc4                       0.320***          \n                              (0.085)          \n\n-----------------------------------------------\nObservations                   3,010           \nR2                             0.477           \nAdjusted R2                    0.474           \nResidual Std. Error      1.941 (df = 2994)     \nF Statistic         182.129*** (df = 15; 2994) \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\nlinearHypothesis(regpe, \"nearc4=0\")\n\nLinear hypothesis test\n\nHypothesis:\nnearc4 = 0\n\nModel 1: restricted model\nModel 2: educ ~ nearc4 + exper + expersq + black + south + smsa + reg661 + \n    reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + \n    smsa66\n\n  Res.Df   RSS Df Sum of Sq      F    Pr(&gt;F)    \n1   2995 11324                                  \n2   2994 11274  1    49.917 13.256 0.0002763 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[3 puntos] Interprete el coeficiente sobre la variable de educación en el modelo estructural. Compare la magnitud del efecto estimado con el resultado de MCO.\nEl coeficiente estimado sobre los años de educación indica que un año adicional de escolaridad incrementa en 13.15% el salario. Este efecto es casi el doble del estimado por MCO y estadísticamente significativo al 5%.\n\nstargazer(regmco, regvi,\n          type = 'text',\n          title=\"Comparación de estimadores de MCO y VI\", \n          se = list(sqrt(diag(vcovHC(regmco, type = \"HC0\"))),\n                    sqrt(diag(vcovHC(regvi, type = \"HC0\")))),\n          keep = 'educ')\n\n\nComparación de estimadores de MCO y VI\n======================================================================\n                                         Dependent variable:          \n                                --------------------------------------\n                                                lwage                 \n                                           OLS            instrumental\n                                                            variable  \n                                           (1)                (2)     \n----------------------------------------------------------------------\neduc                                    0.075***            0.132**   \n                                         (0.004)            (0.054)   \n\n----------------------------------------------------------------------\nObservations                              3,010              3,010    \nR2                                        0.300              0.238    \nAdjusted R2                               0.296              0.234    \nResidual Std. Error (df = 2994)           0.372              0.388    \nF Statistic                     85.476*** (df = 15; 2994)             \n======================================================================\nNote:                                      *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n[3 puntos] Realice ahora el siguiente procedimiento. Primero, estime la primera etapa usando una regresión por MCO. Obtenga los valores ajustados de educación y llámelos educ_hat. Luego, estime la segunda etapa empleando educ_hat como variable independiente, además del resto de variables de control. ¿Cómo cambian sus resultados en comparación con la parte d.?\nLa magnitud de los coeficientes estimados es la misma. Esto es lo que esperábamos pues sabemos que el estimador de MC2E puede entenderse como un procedimiento donde primero se estiman los valores ajustados de la variable endógena usando el instrumento y las variables de control y luego se usan estos valores ajustados en la ecuación estructural. En cambio, los errores estándar son algo distintos.\n\ndata.ingresos &lt;- data.ingresos %&gt;% \n  mutate(educ_hat = predict(regpe, .))\n\nreg2e &lt;- lm(lwage ~ educ_hat + exper + expersq + black + south + smsa + reg661 +\n              reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66,\n            data=data.ingresos)\n\n#Comparamos\nstargazer(regvi, reg2e,   \n          title=\"Comparación de VI con la función ivreg y el estimador a mano\",\n          type=\"text\", \n          keep = c(\"educ\", \"educ_hat\"),\n          df=FALSE, digits=4)\n\n\nComparación de VI con la función ivreg y el estimador a mano\n================================================\n                        Dependent variable:     \n                    ----------------------------\n                               lwage            \n                     instrumental       OLS     \n                       variable                 \n                          (1)           (2)     \n------------------------------------------------\neduc                   0.1315**                 \n                       (0.0550)                 \n\neduc_hat                              0.1315**  \n                                      (0.0565)  \n\n------------------------------------------------\nObservations             3,010         3,010    \nR2                      0.2382         0.1947   \nAdjusted R2             0.2343         0.1907   \nResidual Std. Error     0.3883         0.3993   \nF Statistic                          48.2537*** \n================================================\nNote:                *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n[3 puntos] ¿A qué se deben las discrepancias que encuentra? ¿Cuál de las dos estrategias prefiere para estimar el modelo de variables instrumentales?\nLos coeficientes estimados son exactamente iguales, pero los errores estándar no. El problema es que nuestro procedimiento de MC2E a mano no toma en cuenta que en la ecuación estructural estamos usando valores ajustados de la variable endógena. Las funciones en la mayoría de los paquetes utilizados en econometría calculan los errores estándar de manera correcta. Preferimos usar las funciones previamente ya programadas cuando sea posible, aunque este ejercicio nos ayuda a reforzar la intuición del estimador de MC2E.\n[3 puntos] Reestime el modelo de variables instrumentales añadiendo un segundo instrumento, nearc2, y reporte errores robustos (no es necesario usar gmm, puede seguir con ivreg, por lo que no estaría obteniendo el estimador de MGM óptimo). ¿Cómo cambian sus resultados para la ecuación estructural con respecto al caso exactamente identificado?\nEl efecto estimado es significativo al 1% y en magnitud se incrementa ligeramente hasta 0.157.\n\nregvi2 &lt;- ivreg(lwage ~ educ + exper + expersq + black + south + smsa + reg661 +\n                 reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66  |\n                 nearc4 + nearc2 + exper + expersq + black + south + smsa + reg661 +\n                 reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66,\n               data=data.ingresos)\n\nstargazer(regmco, regvi, regvi2,\n          type = 'text',\n          se = list(sqrt(diag(vcovHC(regmco, type = \"HC0\"))),\n                    sqrt(diag(vcovHC(regvi, type = \"HC0\"))),\n                    sqrt(diag(vcovHC(regvi2, type = \"HC0\")))),\n          keep = 'educ')\n\n\n==========================================================================\n                                           Dependent variable:            \n                                ------------------------------------------\n                                                  lwage                   \n                                           OLS              instrumental  \n                                                              variable    \n                                           (1)              (2)     (3)   \n--------------------------------------------------------------------------\neduc                                    0.075***          0.132** 0.157***\n                                         (0.004)          (0.054) (0.052) \n\n--------------------------------------------------------------------------\nObservations                              3,010            3,010   3,010  \nR2                                        0.300            0.238   0.170  \nAdjusted R2                               0.296            0.234   0.166  \nResidual Std. Error (df = 2994)           0.372            0.388   0.405  \nF Statistic                     85.476*** (df = 15; 2994)                 \n==========================================================================\nNote:                                          *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n[3 puntos] Con el objeto que resulta de la estimación del modelo sobreidentificado, realice summary(OBJETO, vcov = sandwich, diagnostics = TRUE) para obtener las tres pruebas diagnóstico más usadas en variables instrumentales: prueba de instrumentos débiles, prueba de Hausman y prueba de Sargan. Interprete cada una de las pruebas.\n\nsummary(regvi2, vcov = sandwich, diagnostics = TRUE)\n\n\nCall:\nivreg(formula = lwage ~ educ + exper + expersq + black + south + \n    smsa + reg661 + reg662 + reg663 + reg664 + reg665 + reg666 + \n    reg667 + reg668 + smsa66 | nearc4 + nearc2 + exper + expersq + \n    black + south + smsa + reg661 + reg662 + reg663 + reg664 + \n    reg665 + reg666 + reg667 + reg668 + smsa66, data = data.ingresos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.93841 -0.25068  0.01932  0.26519  1.46998 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.3396868  0.8909170   3.749 0.000181 ***\neduc         0.1570594  0.0524127   2.997 0.002753 ** \nexper        0.1188149  0.0228905   5.191 2.24e-07 ***\nexpersq     -0.0023565  0.0003674  -6.414 1.64e-10 ***\nblack       -0.1232778  0.0514904  -2.394 0.016718 *  \nsouth       -0.1431945  0.0301873  -4.744 2.20e-06 ***\nsmsa         0.1007530  0.0313621   3.213 0.001329 ** \nreg661      -0.1029760  0.0425755  -2.419 0.015637 *  \nreg662      -0.0002286  0.0345230  -0.007 0.994716    \nreg663       0.0469556  0.0335252   1.401 0.161435    \nreg664      -0.0554084  0.0408927  -1.355 0.175529    \nreg665       0.0515041  0.0506274   1.017 0.309085    \nreg666       0.0699968  0.0534531   1.309 0.190466    \nreg667       0.0390596  0.0514309   0.759 0.447639    \nreg668      -0.1980371  0.0522335  -3.791 0.000153 ***\nsmsa66       0.0150626  0.0211120   0.713 0.475616    \n\nDiagnostic tests:\n                  df1  df2 statistic  p-value    \nWeak instruments    2 2993     8.366 0.000238 ***\nWu-Hausman          1 2993     2.978 0.084509 .  \nSargan              1   NA     1.248 0.263905    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4053 on 2994 degrees of freedom\nMultiple R-Squared: 0.1702,  Adjusted R-squared: 0.166 \nWald test: 51.65 on 15 and 2994 DF,  p-value: &lt; 2.2e-16 \n\n\nLa prueba de instrumentos débiles rechaza la \\(H_0\\) de que los instrumentos son débiles, por lo que tenemos primera etapa.\nLa prueba de Hausman rechaza al 10% que los estimadores de VI y de MCO sean iguales, por lo que se prefiere el de VI.\nLa prueba de Sargan no rechaza la \\(H_0\\) de que el modelo esté mal especificado.\n[4 puntos] Considere la primera etapa del modelo sobreidentificado. Compruebe que si realiza una prueba de significancia conjunta para los instrumentos obtiene la prueba de instrumentos débiles que se reporta en el resumen que obtuvo con summary.\nEn el apartado anterior, obtenemos un valor \\(p=0.000238\\) para la prueba de instrumentos débiles. Noten que se especificó una matriz de varianzas robustas. Entonces, tenemos que usar la misma matriz en la prueba \\(F\\):\n\nregpe2 &lt;- lm(educ ~ nearc4 + nearc2 + exper + expersq + black + south + smsa + reg661 +\n              reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66,\n            data=data.ingresos)\n\nlinearHypothesis(regpe2, c(\"nearc4=0\", \"nearc2=0\"), white.adjust = \"hc0\")\n\nLinear hypothesis test\n\nHypothesis:\nnearc4 = 0\nnearc2 = 0\n\nModel 1: restricted model\nModel 2: educ ~ nearc4 + nearc2 + exper + expersq + black + south + smsa + \n    reg661 + reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + \n    reg668 + smsa66\n\nNote: Coefficient covariance matrix supplied.\n\n  Res.Df Df      F    Pr(&gt;F)    \n1   2995                        \n2   2993  2 8.3662 0.0002381 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nObtenemos el mismo valor \\(p\\) y maginitud del estadístico \\(F\\).\n[4 puntos] Compruebe que si realiza el procedimiento de regresión auxiliar para la prueba de Hausman obtiene el mismo valor \\(p\\) que se reporta en el resumen que obtuvo con summary.\nDe la primera etapa, obtenemos los residuales:\n\n    data.ingresos &lt;- data.ingresos %&gt;% \n      mutate(vhat = resid(regpe2))\n\nCorremos la regresión auxiliar con los residuales:\n\n    regaux &lt;- lm(lwage ~ educ + exper + expersq + black + south + smsa + reg661 +\n                 reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66 + vhat,\n               data=data.ingresos)\n\nstargazer(regaux,\n          type = 'text',\n          se = list(sqrt(diag(vcovHC(regaux, type = \"HC0\")))),\n          keep = 'vhat',\n          report = c(\"c*s*p\"))\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                               lwage           \n-----------------------------------------------\n                              -0.083*          \n                             (0.048)*          \n                             p = 0.085         \n\n-----------------------------------------------\nObservations                   3,010           \nR2                             0.301           \nAdjusted R2                    0.297           \nResidual Std. Error      0.372 (df = 2993)     \nF Statistic          80.368*** (df = 16; 2993) \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nEl valor \\(p\\) es idéntico al obtenido con summary.\n\n\n\n\nConsidere los datos comportamiento_wide.csv, que contienen información individual de niñas y niños, incluyendo su género, edad, raza e información de sus madres. Además, se incluye una medida auto reportada de autoestima (self) y una evaluación de comportamiento antisocial (anti). Se quiere conocer cómo influye la autoestima en el comportamiento antisocial. Para cada niño o niña hay tres observaciones en el tiempo. Se busca explicar el comportamiento antisocial en función de la autoestima y la condición de pobreza (pov):\n\\[anti_{it}=\\alpha_i+\\beta_1 self_{it}+\\beta_2 pov_{it}+\\varepsilon_{it}\\]\n\n[2 puntos] La base se encuentra en formato wide. Ponga la base en formato long, donde haya una columna para cada variable y donde las filas representen a un individuo en un periodo.\nHay muchas formas de hacer esto. Podemos usar las funciones pivot_longer y pivot_wider, por ejemplo.\n\ndata.comp &lt;-read_csv(\"../files/comportamiento_wide.csv\",\n                      locale = locale(encoding = \"latin1\")) %&gt;%\n  pivot_longer(c(anti90:anti94,self90:self94,pov90:pov94),\n               names_to = c(\"measure\", \"year\"),\n               names_pattern = \"(.*)(..)\")  %&gt;%\n  pivot_wider(names_from = measure,\n              values_from = value)\n\ncolnames(data.comp)\n\n [1] \"id\"       \"momage\"   \"gender\"   \"childage\" \"hispanic\" \"black\"   \n [7] \"momwork\"  \"married\"  \"year\"     \"anti\"     \"self\"     \"pov\"     \n\n\n[2 puntos] Estime la ecuación de comportamiento antisocial empleando MCO pooled. ¿Cuáles son los supuestos que se deben cumplir para que \\(\\hat{\\beta}_1^{MCO}\\) sea consistente?\n\nsummary(m.mco &lt;- plm( anti ~ self + pov,\n                      data=data.comp,\n                      model=\"pooling\",\n                      index = c(\"id\", \"year\")))\n\nPooling Model\n\nCall:\nplm(formula = anti ~ self + pov, data = data.comp, model = \"pooling\", \n    index = c(\"id\", \"year\"))\n\nBalanced Panel: n = 581, T = 3, N = 1743\n\nResiduals:\n    Min.  1st Qu.   Median  3rd Qu.     Max. \n-2.65689 -1.29476 -0.33138  0.98912  4.77034 \n\nCoefficients:\n             Estimate Std. Error t-value  Pr(&gt;|t|)    \n(Intercept)  2.792098   0.231110 12.0812 &lt; 2.2e-16 ***\nself        -0.065102   0.011083 -5.8739 5.089e-09 ***\npov          0.515809   0.078730  6.5516 7.476e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    4333.1\nResidual Sum of Squares: 4140.6\nR-Squared:      0.044433\nAdj. R-Squared: 0.043335\nF-statistic: 40.4544 on 2 and 1740 DF, p-value: &lt; 2.22e-16\n\n\nLa variable self tiene un efecto negativo y estadísticamente significativo sobre anti. La variable pov tiene un efecto positivo y estadísticamente significativo. El estimador de MCO será consistente solo si las variables self y pov no están correlacionadas con el error. Además, para estimar este modelo, asumimos que la heterogeneidad no observada \\(\\alpha_i\\) puede escribirse simplemente como \\(\\alpha\\). Otra forma de pensar sobre este modelo es si el mismo modelo es válido para todos los periodos como para asumir una ordenada al origen y una pendiente común. El modelo pooled ignora la naturaleza en panel de los datos. Sin embargo, como tenemos a los mismos individuos en varios puntos del tiempo, los errores están agrupados, así que se deben de estimar errores con esta estructura. En este caso, al tomar en cuenta esta correlación entre grupos, los errores estándar son más grandes, pero los resultados siguen siendo significativos. En muchos casos, no tomar en cuenta la estructura agrupada de los errores puede llevar a rechazar hipótesis nulas que son ciertas.\n\ncoeftest(m.mco,\n         vcov = vcovHC(m.mco, type = \"HC1\", cluster=\"group\"))\n\n\nt test of coefficients:\n\n             Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  2.792098   0.293380  9.5170 &lt; 2.2e-16 ***\nself        -0.065102   0.013687 -4.7565 2.132e-06 ***\npov          0.515809   0.104963  4.9142 9.753e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[3 puntos] Estime la ecuación de comportamiento antisocial empleando el estimador within. ¿Cuáles son los supuestos que se deben cumplir para que \\(\\hat{\\beta}_1^{FE}\\) sea consistente?\nSi asumimos que la heterogeneidad no observada y el error están potencialmente correlacionados, entonces podemos usar un estimador de efectos fijos para deshacernos de la heterogeneidad no observada y estimar consistentemente los parámetros sobre self y pov.\n\nm.fe &lt;- plm( anti ~ self + pov,\n             data=data.comp,\n             model=\"within\",\n             index = c(\"id\", \"year\"))\n\ncoeftest(m.fe,\n         vcov = vcovHC(m.fe, type = \"HC1\", cluster=\"group\"))\n\n\nt test of coefficients:\n\n      Estimate Std. Error t value  Pr(&gt;|t|)    \nself -0.051495   0.011308 -4.5540 5.818e-06 ***\npov   0.104899   0.099188  1.0576    0.2905    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[3 puntos] Estime la ecuación de comportamiento antisocial empleando efectos aleatorios. ¿Cuáles son los supuestos que se deben cumplir para que \\(\\hat{\\beta}_1^{RE}\\) sea consistente?\nSi estamos dispuestos a asumir que la heterogeneidad no observada y el error son independientes, podemos emplear el estimador de efectos aleatorios. MCO pooled también es consistente pero no es eficiente.\n\nm.re &lt;- plm( anti ~ self + pov,\n             data=data.comp,\n             model=\"random\",\n             index = c(\"id\", \"year\"))\n\ncoeftest(m.re,\n         vcov = vcovHC(m.re, type = \"HC1\", cluster=\"group\"))\n\n\nt test of coefficients:\n\n             Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  2.695210   0.222607 12.1075 &lt; 2.2e-16 ***\nself        -0.056732   0.010216 -5.5534 3.234e-08 ***\npov          0.292407   0.081956  3.5679 0.0003696 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[3 puntos] Se desea incorporar en el análisis el género (gender) y una variable dicotómica para los hispanos (hispanic). Indique qué modelo usaría y estime dicho modelo.\nNo es posible estimar los coeficientes sobre variables que no varían en el tiempo usando efectos fijos, por lo que este modelo queda descartado. Podríamos usar MCO pooled, que impone supuestos muy fuertes. La otra alternativa es un modelo de efectos aleatorios, que asume que la heterogeneidad no observada y el error no están correlacionados.\n\nm.sex &lt;- plm( anti ~ self + pov + gender,\n              data=data.comp,\n              model=\"random\",\n              index = c(\"id\", \"year\"))\n\ncoeftest(m.sex,\n         vcov = vcovHC(m.sex, type = \"HC1\", cluster=\"group\"))\n\n\nt test of coefficients:\n\n             Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  2.970534   0.231591 12.8267 &lt; 2.2e-16 ***\nself        -0.058558   0.010223 -5.7278 1.197e-08 ***\npov          0.304997   0.081486  3.7429 0.0001878 ***\ngender      -0.480468   0.107126 -4.4851 7.766e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[2 puntos] Regrese al modelo que incluye solo la autoestima y el estado de pobreza como covariables. Realice una prueba de Hausman para determinar si se prefiere un modelo de efectos fijos o uno de efectos aleatorios.\nLa implementación de la prueba de Hausman indica que se rechaza la H0 de que los coeficientes estimados son iguales (y que el modelo de efectos aleatorios es el adecuado). Hay evidencia de que se prefiere un modelo de efectos fijos, aunque tendremos que vivir con el hecho de no poder estimar el coeficiente asociado a las variables que no varían en el tiempo en este caso.\n\nphtest(m.fe, m.re)\n\n\n Hausman Test\n\ndata:  anti ~ self + pov\nchisq = 13.578, df = 2, p-value = 0.001126\nalternative hypothesis: one model is inconsistent\n\n\n\n\n\n\nRetome los datos de la pregunta 2 y el modelo del comportamiento antisocial en función de la autoestima y la pobreza. En esta pregunta mostraremos la equivalencia del estimador within con otros estimadores.\n\n[3 puntos] Compruebe que el estimador de efectos fijos es equivalente a MCO con dummies de individuos.\nComprobamos:\n\nm.fe &lt;- plm( anti ~ self + pov,\n             data=data.comp,\n             model=\"within\",\n             index = c(\"id\", \"year\"))\n\nm.dummy &lt;- lm(anti ~ self + pov + factor(id),\n              data=data.comp)\n\nstargazer(m.fe, m.dummy, keep=c(\"self\", \"pov\"), type=\"text\")\n\n\n======================================================================\n                                   Dependent variable:                \n                    --------------------------------------------------\n                                           anti                       \n                             panel                      OLS           \n                             linear                                   \n                              (1)                       (2)           \n----------------------------------------------------------------------\nself                       -0.051***                 -0.051***        \n                            (0.011)                   (0.011)         \n\npov                          0.105                     0.105          \n                            (0.094)                   (0.094)         \n\n----------------------------------------------------------------------\nObservations                 1,743                     1,743          \nR2                           0.021                     0.731          \nAdjusted R2                  -0.470                    0.596          \nResidual Std. Error                              1.002 (df = 1160)    \nF Statistic         12.551*** (df = 2; 1160) 5.417*** (df = 582; 1160)\n======================================================================\nNote:                                      *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n[2 puntos] Compruebe que en un modelo de efectos fijos las características que no varían en el tiempo no pueden ser identificadas. Añada la variable black para comprobarlo.\nComprobamos que la variable simplemente es omitida del análisis:\n\nsummary(plm( anti ~ self + pov + black,\n             data=data.comp,\n             model=\"within\",\n             index = c(\"id\", \"year\")))\n\nOneway (individual) effect Within Model\n\nCall:\nplm(formula = anti ~ self + pov + black, data = data.comp, model = \"within\", \n    index = c(\"id\", \"year\"))\n\nBalanced Panel: n = 581, T = 3, N = 1743\n\nResiduals:\n      Min.    1st Qu.     Median    3rd Qu.       Max. \n-3.7868224 -0.4706542 -0.0012721  0.4534891  3.2646729 \n\nCoefficients:\n      Estimate Std. Error t-value  Pr(&gt;|t|)    \nself -0.051495   0.010530 -4.8902 1.149e-06 ***\npov   0.104899   0.093880  1.1174    0.2641    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    1190.7\nResidual Sum of Squares: 1165.4\nR-Squared:      0.021182\nAdj. R-Squared: -0.46991\nF-statistic: 12.5514 on 2 and 1160 DF, p-value: 4.0471e-06\n\n\n[5 puntos] Compruebe que el estimador de efectos fijos es equivalente a MCO sobre el modelo en diferencias con respecto a la media. Para esto, conserve dos periodos consecutivos de datos y solo observaciones que tengan datos para las variables dependientes e independientes en los dos años que elija. Luego estime por MCO el modelo con variables transformadas.\nNos quedamos con un subconjunto de datos:\n\ndata.comp.sub &lt;- data.comp %&gt;% \n  dplyr::select(id, year, anti, self, pov) %&gt;% \n  filter(year==90 | year==92)\n\n#Nos quedamos con los que no son NA\ndata.comp.sub &lt;- data.comp.sub[complete.cases(data.comp.sub), ]\n\nCreamos las variables como diferencias respecto a la media y estimamos el modelo within y el modelo de MCO en las variables transformadas:\n\ndata.comp.sub &lt;- data.comp.sub %&gt;%\n  group_by(id) %&gt;% \n  mutate(m.anti = mean(anti),\n         m.self = mean(self),\n         m.pov = mean(pov)) %&gt;% \n  mutate(dm.anti = anti - m.anti,\n         dm.self = self - m.self,\n         dm.pov = pov - m.pov)\n\nm.fe.sub &lt;- plm( anti ~ self + pov,\n                 data=data.comp.sub,\n                 model=\"within\",\n                 index = c(\"id\", \"year\"))\n\n\nm.demean &lt;- lm(dm.anti ~ dm.self + dm.pov,\n               data.comp.sub)\n\nstargazer(m.fe.sub, m.demean,\n          keep=c(\"self\", \"pov\", \"dm.self\",\"dm.pov\"),\n          type=\"text\")\n\n\n==================================================================\n                                 Dependent variable:              \n                    ----------------------------------------------\n                             anti                  dm.anti        \n                            panel                    OLS          \n                            linear                                \n                             (1)                     (2)          \n------------------------------------------------------------------\nself                      -0.038***                               \n                           (0.014)                                \n\npov                         0.195                                 \n                           (0.133)                                \n\ndm.self                                           -0.038***       \n                                                   (0.010)        \n\ndm.pov                                             0.195**        \n                                                   (0.094)        \n\n------------------------------------------------------------------\nObservations                1,162                   1,162         \nR2                          0.016                   0.016         \nAdjusted R2                 -0.972                  0.015         \nResidual Std. Error                           0.641 (df = 1159)   \nF Statistic         4.807*** (df = 2; 579) 9.621*** (df = 2; 1159)\n==================================================================\nNote:                                  *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n[5 puntos] Compruebe que el estimador de efectos fijos es equivalente a MCO sobre el modelo en primeras diferencias. Parta de la muestra con dos años de la parte d. para estimar por MCO el modelo con variables transformadas.\nUsando el mismo subconjunto, calculamos ahora las primeras diferencias y estimamos:\n\ndata.comp.sub &lt;- data.comp.sub %&gt;%\n  group_by(id) %&gt;% \n  mutate(d.anti = anti-dplyr::lag(anti, order_by = year),\n         d.self = self-dplyr::lag(self, order_by = year),\n         d.pov = pov-dplyr::lag(pov, order_by = year)) %&gt;% \n  ungroup()\n\n\nm.difs &lt;- lm(d.anti ~ -1 + d.self + d.pov,\n             data=data.comp.sub)\n\nstargazer(m.fe.sub, m.demean, keep=c(\"self\", \"pov\", \"d.self\",\"d.pov\"), type=\"text\")\n\n\n==================================================================\n                                 Dependent variable:              \n                    ----------------------------------------------\n                             anti                  dm.anti        \n                            panel                    OLS          \n                            linear                                \n                             (1)                     (2)          \n------------------------------------------------------------------\nself                      -0.038***                               \n                           (0.014)                                \n\npov                         0.195                                 \n                           (0.133)                                \n\ndm.self                                           -0.038***       \n                                                   (0.010)        \n\ndm.pov                                             0.195**        \n                                                   (0.094)        \n\n------------------------------------------------------------------\nObservations                1,162                   1,162         \nR2                          0.016                   0.016         \nAdjusted R2                 -0.972                  0.015         \nResidual Std. Error                           0.641 (df = 1159)   \nF Statistic         4.807*** (df = 2; 579) 9.621*** (df = 2; 1159)\n==================================================================\nNote:                                  *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n\n\n\n\nConsidere los datos mlbook1.csv con información sobre 2287 estudiantes en 131 escuelas. Nos interesa la relación entre una medida de aptitud verbal, (iq_vert) y el resultado de un examen de inglés (langpost). Las variables schoolnr y pupilnr identifican a las escuelas y los estudiantes, respectivamente. El modelo a estimar es el siguiente:\n\\[langpost_{i}=\\alpha+\\beta iqvert_{i}+BX_{i}+\\varepsilon_{i}\\] donde \\(i\\) indexa y \\(X_i\\) son tres características usadas como control: el sexo, sex, si el estudiante es de una población minoritaria, minority y el número de años repetidos, repeatgr.\n\n[3 puntos] ¿Por qué es posible que estemos frente a una situación de errores agrupados?\nLos datos están agrupados a nivel escuela. Los estudiantes en una misma escuela comparten características observadas y no observadas que hacen altamente probable que los factores no observables estén correlacionados entre los individuos, rompiendo el supuesto de independencia.\n[2 puntos] Estime la ecuación de calificación usando MCO ignorando la agrupación de datos. ¿Qué concluye respecto a la relación entre la aptitud verbal y la prueba de inglés?\nSe concluye que una hora más en la prueba de aptitud incrementa en 2.49 puntos la calificación del examen. El error estándar es 0.072.\n\ndata.examen&lt;-read_csv(\"../files/mlbook1.csv\",\n                      locale = locale(encoding = \"latin1\")) \n\n\nsummary(m.mco &lt;- lm(langpost ~ iq_verb + sex + minority + repeatgr, data=data.examen))\n\n\nCall:\nlm(formula = langpost ~ iq_verb + sex + minority + repeatgr, \n    data = data.examen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-28.0192  -4.2255   0.5218   4.8017  24.1421 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 10.93980    0.90504  12.088   &lt;2e-16 ***\niq_verb      2.48635    0.07233  34.374   &lt;2e-16 ***\nsex          2.42228    0.28871   8.390   &lt;2e-16 ***\nminority    -0.03701    0.62762  -0.059    0.953    \nrepeatgr    -4.40860    0.43222 -10.200   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.853 on 2282 degrees of freedom\nMultiple R-squared:  0.4217, Adjusted R-squared:  0.4207 \nF-statistic: 416.1 on 4 and 2282 DF,  p-value: &lt; 2.2e-16\n\n\n[3 puntos] Estime ahora los errores robustos a heteroscedasticidad del tipo HC1. ¿Qué cambia y por qué en la interpretación de la relación entre la prueba de aptitud y el examen?\nEl coeficiente estimado es el mismo. La fórmula empleada para calcular la varianza es una en forma de sándwich, que toma en cuenta la posible heterocedasticidad. El error estándar es apromximadamente 5% más grande, 0.076.\n\ncoeftest(m.mco, vcov = vcovHC(m.mco, type = \"HC1\"))\n\n\nt test of coefficients:\n\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 10.939796   0.985476 11.1010   &lt;2e-16 ***\niq_verb      2.486350   0.075871 32.7709   &lt;2e-16 ***\nsex          2.422279   0.288525  8.3954   &lt;2e-16 ***\nminority    -0.037006   0.612455 -0.0604   0.9518    \nrepeatgr    -4.408605   0.448615 -9.8271   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[2 puntos] Estime la ecuación de calificación usando MCO y efectos fijos de escuela. ¿Qué resuelve este procedimiento?\nAl incluir efectos fijos a nivel escuela controlamos por características no observadas a nivel escuela. Estas diferencias se incorporan en el modelo como desplazamientos de la ordenada al origen. Este procedimiento no tiene nada que ver con la agrupación de errores.\n\nsummary(m.mco.ef &lt;- lm(langpost ~ iq_verb + sex + minority + repeatgr + factor(schoolnr),\n                       data=data.examen))\n\n\nCall:\nlm(formula = langpost ~ iq_verb + sex + minority + repeatgr + \n    factor(schoolnr), data = data.examen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-24.8792  -3.6779   0.2729   4.0985  19.6755 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         12.50218    1.54290   8.103 8.89e-16 ***\niq_verb              2.25997    0.07093  31.860  &lt; 2e-16 ***\nsex                  2.41900    0.26850   9.009  &lt; 2e-16 ***\nminority             0.23262    0.71306   0.326 0.744280    \nrepeatgr            -4.43503    0.40938 -10.834  &lt; 2e-16 ***\nfactor(schoolnr)2   -8.29681    2.67144  -3.106 0.001923 ** \nfactor(schoolnr)10  -7.28322    3.06053  -2.380 0.017412 *  \nfactor(schoolnr)12  -4.56719    2.06924  -2.207 0.027407 *  \nfactor(schoolnr)15  -7.41516    2.54948  -2.909 0.003669 ** \nfactor(schoolnr)16   2.53410    2.54854   0.994 0.320173    \nfactor(schoolnr)18  -6.80332    1.81757  -3.743 0.000187 ***\nfactor(schoolnr)21  -0.53872    1.99103  -0.271 0.786746    \nfactor(schoolnr)24   4.20444    1.81839   2.312 0.020862 *  \nfactor(schoolnr)26  -0.36076    1.96000  -0.184 0.853984    \nfactor(schoolnr)27  -5.46850    1.87909  -2.910 0.003649 ** \nfactor(schoolnr)29   3.19018    2.35758   1.353 0.176147    \nfactor(schoolnr)33  -0.34896    2.84408  -0.123 0.902359    \nfactor(schoolnr)35   1.59577    2.08305   0.766 0.443718    \nfactor(schoolnr)36  -3.99135    1.83661  -2.173 0.029873 *  \nfactor(schoolnr)38   3.05382    1.75466   1.740 0.081931 .  \nfactor(schoolnr)40   0.09036    1.67651   0.054 0.957022    \nfactor(schoolnr)41  -2.94006    2.13296  -1.378 0.168226    \nfactor(schoolnr)42  -4.99799    2.10828  -2.371 0.017845 *  \nfactor(schoolnr)44  -1.49855    2.04728  -0.732 0.464268    \nfactor(schoolnr)47  -5.73732    2.52469  -2.272 0.023156 *  \nfactor(schoolnr)48  -1.83632    2.25583  -0.814 0.415717    \nfactor(schoolnr)49  -4.14690    2.41410  -1.718 0.085979 .  \nfactor(schoolnr)52  -3.60350    1.87627  -1.921 0.054918 .  \nfactor(schoolnr)54   2.91142    1.72017   1.693 0.090691 .  \nfactor(schoolnr)55   1.49383    1.73053   0.863 0.388111    \nfactor(schoolnr)57   0.79682    1.80093   0.442 0.658210    \nfactor(schoolnr)60  -1.79256    1.83760  -0.975 0.329426    \nfactor(schoolnr)61   0.39402    1.89130   0.208 0.834990    \nfactor(schoolnr)62   2.39062    1.88568   1.268 0.205016    \nfactor(schoolnr)65   5.66979    1.85875   3.050 0.002314 ** \nfactor(schoolnr)66   1.09325    2.28956   0.477 0.633058    \nfactor(schoolnr)67  -5.59969    1.78486  -3.137 0.001728 ** \nfactor(schoolnr)68  -1.22319    1.90619  -0.642 0.521140    \nfactor(schoolnr)76  -1.14607    2.02551  -0.566 0.571577    \nfactor(schoolnr)78   0.20198    1.99000   0.101 0.919167    \nfactor(schoolnr)79   2.10981    2.10998   1.000 0.317463    \nfactor(schoolnr)80   3.31569    1.87290   1.770 0.076810 .  \nfactor(schoolnr)86   1.45319    1.81855   0.799 0.424322    \nfactor(schoolnr)87  -0.20740    1.88076  -0.110 0.912200    \nfactor(schoolnr)88   1.25972    2.35398   0.535 0.592604    \nfactor(schoolnr)90   4.45169    2.06677   2.154 0.031356 *  \nfactor(schoolnr)94   3.05367    2.05599   1.485 0.137621    \nfactor(schoolnr)95  -0.76530    1.94512  -0.393 0.694027    \nfactor(schoolnr)97   1.48348    1.98190   0.749 0.454232    \nfactor(schoolnr)98  -1.40960    1.89893  -0.742 0.457977    \nfactor(schoolnr)101  4.26255    1.83026   2.329 0.019955 *  \nfactor(schoolnr)103 -4.54699    3.34961  -1.357 0.174775    \nfactor(schoolnr)106 -2.63664    2.33290  -1.130 0.258518    \nfactor(schoolnr)107 -4.50332    1.99406  -2.258 0.024023 *  \nfactor(schoolnr)108 -1.87255    2.44170  -0.767 0.443222    \nfactor(schoolnr)109 -4.40708    1.87743  -2.347 0.018995 *  \nfactor(schoolnr)110  3.08759    1.99160   1.550 0.121215    \nfactor(schoolnr)111  1.23407    1.94637   0.634 0.526125    \nfactor(schoolnr)112 -0.24997    2.67934  -0.093 0.925678    \nfactor(schoolnr)115 -0.13189    1.72755  -0.076 0.939152    \nfactor(schoolnr)116 -0.96627    1.93966  -0.498 0.618421    \nfactor(schoolnr)118 -4.19606    2.42987  -1.727 0.084335 .  \nfactor(schoolnr)119 -0.37636    2.21669  -0.170 0.865195    \nfactor(schoolnr)121 -3.16182    2.35853  -1.341 0.180196    \nfactor(schoolnr)123  2.76021    3.34170   0.826 0.408902    \nfactor(schoolnr)124  3.69157    1.89801   1.945 0.051909 .  \nfactor(schoolnr)125  1.79787    1.76911   1.016 0.309622    \nfactor(schoolnr)130  5.61009    2.16507   2.591 0.009629 ** \nfactor(schoolnr)132  6.28128    1.87651   3.347 0.000830 ***\nfactor(schoolnr)136  3.87282    2.03048   1.907 0.056610 .  \nfactor(schoolnr)137  4.40378    1.95919   2.248 0.024693 *  \nfactor(schoolnr)141  1.14473    1.90727   0.600 0.548441    \nfactor(schoolnr)142  5.13270    1.82046   2.819 0.004855 ** \nfactor(schoolnr)147  7.45698    1.85918   4.011 6.26e-05 ***\nfactor(schoolnr)148  2.09875    1.74675   1.202 0.229682    \nfactor(schoolnr)149  2.53123    1.88015   1.346 0.178351    \nfactor(schoolnr)150  1.56758    1.80115   0.870 0.384221    \nfactor(schoolnr)151  0.81632    1.83732   0.444 0.656871    \nfactor(schoolnr)152  6.20977    1.99227   3.117 0.001852 ** \nfactor(schoolnr)155  4.06995    1.69447   2.402 0.016394 *  \nfactor(schoolnr)156  1.03255    2.21442   0.466 0.641061    \nfactor(schoolnr)159  2.82606    1.71234   1.650 0.099006 .  \nfactor(schoolnr)160  3.52358    1.80662   1.950 0.051261 .  \nfactor(schoolnr)161  5.47210    1.70824   3.203 0.001378 ** \nfactor(schoolnr)164  4.69601    1.81787   2.583 0.009853 ** \nfactor(schoolnr)167  3.85744    1.79977   2.143 0.032201 *  \nfactor(schoolnr)170  1.92686    1.78368   1.080 0.280143    \nfactor(schoolnr)175  4.18579    2.10407   1.989 0.046785 *  \nfactor(schoolnr)176  6.59497    1.83757   3.589 0.000339 ***\nfactor(schoolnr)177  1.42445    1.99027   0.716 0.474249    \nfactor(schoolnr)179 -7.16566    2.82071  -2.540 0.011143 *  \nfactor(schoolnr)182  1.78603    2.41396   0.740 0.459456    \nfactor(schoolnr)183  0.85895    1.70516   0.504 0.614499    \nfactor(schoolnr)184  0.99731    1.74622   0.571 0.567974    \nfactor(schoolnr)188 -0.58465    2.19526  -0.266 0.790015    \nfactor(schoolnr)189  3.22324    1.98341   1.625 0.104287    \nfactor(schoolnr)192 -1.80905    2.55487  -0.708 0.478973    \nfactor(schoolnr)193  6.24675    2.21572   2.819 0.004857 ** \nfactor(schoolnr)195  0.62668    1.90527   0.329 0.742247    \nfactor(schoolnr)196  2.79306    1.77499   1.574 0.115735    \nfactor(schoolnr)197  1.31643    1.90977   0.689 0.490700    \nfactor(schoolnr)198 -2.54503    2.66624  -0.955 0.339919    \nfactor(schoolnr)199 -4.10925    1.69994  -2.417 0.015719 *  \nfactor(schoolnr)204  0.98462    1.81798   0.542 0.588149    \nfactor(schoolnr)206  3.79180    2.28001   1.663 0.096446 .  \nfactor(schoolnr)209  2.44276    1.83923   1.328 0.184272    \nfactor(schoolnr)210 -0.40756    2.02750  -0.201 0.840706    \nfactor(schoolnr)212  1.37659    1.80057   0.765 0.444637    \nfactor(schoolnr)214 -3.50270    1.85506  -1.888 0.059136 .  \nfactor(schoolnr)215  2.42072    2.21308   1.094 0.274155    \nfactor(schoolnr)216  3.25053    2.68121   1.212 0.225516    \nfactor(schoolnr)217  3.17962    2.55021   1.247 0.212604    \nfactor(schoolnr)218  5.14348    1.79490   2.866 0.004203 ** \nfactor(schoolnr)219  5.03571    2.10754   2.389 0.016962 *  \nfactor(schoolnr)222  1.27021    1.81917   0.698 0.485106    \nfactor(schoolnr)224  0.16178    2.15792   0.075 0.940246    \nfactor(schoolnr)226  0.43861    2.55025   0.172 0.863464    \nfactor(schoolnr)227  3.11551    1.95897   1.590 0.111895    \nfactor(schoolnr)228  7.82086    1.88038   4.159 3.32e-05 ***\nfactor(schoolnr)231  4.99594    1.87985   2.658 0.007928 ** \nfactor(schoolnr)233 -3.62877    2.44368  -1.485 0.137700    \nfactor(schoolnr)234  4.45798    2.13964   2.084 0.037322 *  \nfactor(schoolnr)235  4.18463    2.35443   1.777 0.075653 .  \nfactor(schoolnr)237  1.69607    2.06447   0.822 0.411422    \nfactor(schoolnr)240 -0.21368    2.21446  -0.096 0.923139    \nfactor(schoolnr)241  1.82195    1.83630   0.992 0.321219    \nfactor(schoolnr)242  5.11955    2.27771   2.248 0.024698 *  \nfactor(schoolnr)243  4.71818    2.54942   1.851 0.064352 .  \nfactor(schoolnr)244 -0.81472    2.15710  -0.378 0.705695    \nfactor(schoolnr)246  3.94809    2.21570   1.782 0.074911 .  \nfactor(schoolnr)249  0.18111    1.81893   0.100 0.920695    \nfactor(schoolnr)250 -0.69331    2.06691  -0.335 0.737332    \nfactor(schoolnr)252 -0.36370    2.27756  -0.160 0.873140    \nfactor(schoolnr)256 -8.25432    2.35336  -3.507 0.000462 ***\nfactor(schoolnr)258 -8.24124    2.68111  -3.074 0.002140 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.186 on 2152 degrees of freedom\nMultiple R-squared:  0.5557, Adjusted R-squared:  0.528 \nF-statistic: 20.08 on 134 and 2152 DF,  p-value: &lt; 2.2e-16\n\n\n[5 puntos] Estime la ecuación de calificación usando MCO y con errores agrupados a nivel escuela (sin efectos fijos de escuela). ¿Qué resuelve este procedimiento?\nAl estimar los errores agrupados y robustos a heterocedasticidad se toma en cuenta la correlación que existe en los errores dentro de cada escuela. Los errores agrupados estimados con la opción cluster asumen correlación de errores dentro del grupo, pero no entre grupos. Con respecto a las partes b. y c., el error estándar asociado al tiempo dedicado a la tarea es aproximadamente 20% mayor. Este es un ejemplo típico en el que los errores agrupados se inflan con respecto a los errores de MCO clásicos y los errores robustos.\nNota: es posible que los errores agrupados sean menores que los errores de MCO. Para ver eso, considere un modelo simple con datos agrupados de la forma siguiente: \\[y_{ig=\\alpha+\\beta x_{ig}+u_{ig}}\\] donde \\(x_{ig}\\) es un regresor escalar.\nSe asume que el tamaño promedio de los grupos es \\(\\bar{N}_g\\). Moulton (1990) muestra que el error estándar de MCO esta sesgado hacia abajo por una cantidad igual a la raíz de \\(\\tau \\approx 1 +\\rho_x \\rho_u (\\bar{N}_g-1)\\), donde \\(\\rho_x\\) es la correlación dentro de los grupos de \\(x\\) y \\(\\rho_u\\) es la correlación dentro de los grupos de los errores. Esto implica que para obtener el error correcto que toma en cuenta la agrupación hay que multiplicar el error de MCO por la raíz de \\(\\tau\\). Sin embargo, note que dependiendo del signo y la magnitud de \\(\\rho_x\\) y \\(\\rho_u\\), la raíz de \\(\\tau\\) puede llegar a ser menor que 1 y, por tanto, el error agrupado puede llegar a ser menor que el de MCO. \\(\\tau\\) se conoce como el factor de Moulton y puede ser extendido para un modelo más complicado. La intuición funciona de manera similar para un modelo más complicado: todo depende de las correlaciones entre grupos de los regresores y la correlación de los errores.\n\ncoef_test(m.mco, vcov = \"CR1S\", cluster = data.examen$schoolnr)\n\n       Coef. Estimate     SE   t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)   10.940 1.2559   8.7109        95.2       &lt;0.001  ***\n     iq_verb    2.486 0.0899  27.6464        94.5       &lt;0.001  ***\n         sex    2.422 0.2846   8.5110       110.0       &lt;0.001  ***\n    minority   -0.037 0.8547  -0.0433        20.0        0.966     \n    repeatgr   -4.409 0.3958 -11.1381        81.8       &lt;0.001  ***\n\n\n[5 puntos] Estime la ecuación de calificación usando MCO, variables indicadoras de escuela y con errores agrupados a nivel escuela. ¿Qué resuelve este procedimiento?\nAl controlar por características no observadas de las escuelas empleando efectos fijos por escuela y además estimando los errores que toman en cuenta la estructura agrupada de los errores obtenemos un coeficiente estimado de 2.26, pero con un error estándar mayor, 0.0915.\n\ncoef_test(m.mco.ef, vcov = \"CR1S\", cluster = data.examen$schoolnr)\n\n               Coef. Estimate     SE  t-stat d.f. (Satt) p-val (Satt) Sig.\n         (Intercept)  12.5022 1.1668  10.715        86.2      &lt; 0.001  ***\n             iq_verb   2.2600 0.0915  24.695        94.0      &lt; 0.001  ***\n                 sex   2.4190 0.2836   8.529       106.5      &lt; 0.001  ***\n            minority   0.2326 0.7172   0.324        32.0      0.74778     \n            repeatgr  -4.4350 0.4083 -10.862        82.3      &lt; 0.001  ***\n   factor(schoolnr)2  -8.2968 0.3795 -21.863        42.8      &lt; 0.001  ***\n  factor(schoolnr)10  -7.2832 0.4270 -17.058        32.6      &lt; 0.001  ***\n  factor(schoolnr)12  -4.5672 0.4565 -10.005        37.0      &lt; 0.001  ***\n  factor(schoolnr)15  -7.4152 0.4211 -17.611        31.8      &lt; 0.001  ***\n  factor(schoolnr)16   2.5341 0.4252   5.960        30.8      &lt; 0.001  ***\n  factor(schoolnr)18  -6.8033 0.4225 -16.101        30.3      &lt; 0.001  ***\n  factor(schoolnr)21  -0.5387 0.4188  -1.286        31.1      0.20787     \n  factor(schoolnr)24   4.2044 0.4187  10.042        31.3      &lt; 0.001  ***\n  factor(schoolnr)26  -0.3608 0.4253  -0.848        31.4      0.40275     \n  factor(schoolnr)27  -5.4685 0.4170 -13.113        30.4      &lt; 0.001  ***\n  factor(schoolnr)29   3.1902 0.4536   7.033        34.2      &lt; 0.001  ***\n  factor(schoolnr)33  -0.3490 0.4205  -0.830        30.8      0.41305     \n  factor(schoolnr)35   1.5958 0.2760   5.783        31.3      &lt; 0.001  ***\n  factor(schoolnr)36  -3.9913 0.4175  -9.560        30.5      &lt; 0.001  ***\n  factor(schoolnr)38   3.0538 0.4171   7.322        31.0      &lt; 0.001  ***\n  factor(schoolnr)40   0.0904 0.4264   0.212        32.0      0.83352     \n  factor(schoolnr)41  -2.9401 0.2796 -10.515        33.9      &lt; 0.001  ***\n  factor(schoolnr)42  -4.9980 0.4168 -11.992        31.1      &lt; 0.001  ***\n  factor(schoolnr)44  -1.4985 0.3315  -4.520        30.9      &lt; 0.001  ***\n  factor(schoolnr)47  -5.7373 0.2712 -21.152        81.0      &lt; 0.001  ***\n  factor(schoolnr)48  -1.8363 0.2637  -6.963        47.5      &lt; 0.001  ***\n  factor(schoolnr)49  -4.1469 0.2037 -20.359        44.2      &lt; 0.001  ***\n  factor(schoolnr)52  -3.6035 0.3986  -9.041        34.0      &lt; 0.001  ***\n  factor(schoolnr)54   2.9114 0.4389   6.634        33.4      &lt; 0.001  ***\n  factor(schoolnr)55   1.4938 0.4230   3.532        32.1      0.00127   **\n  factor(schoolnr)57   0.7968 0.3384   2.354        32.6      0.02472    *\n  factor(schoolnr)60  -1.7926 0.3208  -5.588        30.8      &lt; 0.001  ***\n  factor(schoolnr)61   0.3940 0.3533   1.115        33.0      0.27283     \n  factor(schoolnr)62   2.3906 0.4618   5.177        34.7      &lt; 0.001  ***\n  factor(schoolnr)65   5.6698 0.4298  13.192        31.4      &lt; 0.001  ***\n  factor(schoolnr)66   1.0933 0.4601   2.376        40.1      0.02237    *\n  factor(schoolnr)67  -5.5997 0.4214 -13.289        31.4      &lt; 0.001  ***\n  factor(schoolnr)68  -1.2232 0.4360  -2.806        32.6      0.00841   **\n  factor(schoolnr)76  -1.1461 0.4266  -2.687        31.5      0.01142    *\n  factor(schoolnr)78   0.2020 0.4157   0.486        30.7      0.63054     \n  factor(schoolnr)79   2.1098 0.4214   5.006        32.2      &lt; 0.001  ***\n  factor(schoolnr)80   3.3157 0.3850   8.613        31.6      &lt; 0.001  ***\n  factor(schoolnr)86   1.4532 0.4241   3.427        30.8      0.00175   **\n  factor(schoolnr)87  -0.2074 0.4152  -0.500        31.8      0.62085     \n  factor(schoolnr)88   1.2597 0.4166   3.024        31.5      0.00493   **\n  factor(schoolnr)90   4.4517 0.4252  10.470        33.8      &lt; 0.001  ***\n  factor(schoolnr)94   3.0537 0.3997   7.641        41.1      &lt; 0.001  ***\n  factor(schoolnr)95  -0.7653 0.3455  -2.215        32.8      0.03383    *\n  factor(schoolnr)97   1.4835 0.3802   3.902        30.6      &lt; 0.001  ***\n  factor(schoolnr)98  -1.4096 0.3875  -3.637        33.2      &lt; 0.001  ***\n factor(schoolnr)101   4.2626 0.3876  10.997        31.6      &lt; 0.001  ***\n factor(schoolnr)103  -4.5470 0.4170 -10.903        85.5      &lt; 0.001  ***\n factor(schoolnr)106  -2.6366 0.2861  -9.217        35.1      &lt; 0.001  ***\n factor(schoolnr)107  -4.5033 0.4439 -10.144        33.2      &lt; 0.001  ***\n factor(schoolnr)108  -1.8726 0.4256  -4.399        30.5      &lt; 0.001  ***\n factor(schoolnr)109  -4.4071 0.2769 -15.917        31.5      &lt; 0.001  ***\n factor(schoolnr)110   3.0876 0.4218   7.319        31.6      &lt; 0.001  ***\n factor(schoolnr)111   1.2341 0.3645   3.386        33.6      0.00182   **\n factor(schoolnr)112  -0.2500 0.4327  -0.578        32.0      0.56748     \n factor(schoolnr)115  -0.1319 0.4179  -0.316        30.4      0.75445     \n factor(schoolnr)116  -0.9663 0.4511  -2.142        37.6      0.03872    *\n factor(schoolnr)118  -4.1961 0.3504 -11.975        31.3      &lt; 0.001  ***\n factor(schoolnr)119  -0.3764 0.4254  -0.885        33.3      0.38261     \n factor(schoolnr)121  -3.1618 0.4610  -6.858        35.0      &lt; 0.001  ***\n factor(schoolnr)123   2.7602 0.2742  10.065        79.0      &lt; 0.001  ***\n factor(schoolnr)124   3.6916 0.3958   9.328        32.1      &lt; 0.001  ***\n factor(schoolnr)125   1.7979 0.3552   5.061        33.4      &lt; 0.001  ***\n factor(schoolnr)130   5.6101 0.4385  12.793        37.4      &lt; 0.001  ***\n factor(schoolnr)132   6.2813 0.4103  15.310        33.7      &lt; 0.001  ***\n factor(schoolnr)136   3.8728 0.4443   8.717        35.6      &lt; 0.001  ***\n factor(schoolnr)137   4.4038 0.4166  10.572        31.2      &lt; 0.001  ***\n factor(schoolnr)141   1.1447 0.4237   2.702        33.3      0.01076    *\n factor(schoolnr)142   5.1327 0.4232  12.128        32.3      &lt; 0.001  ***\n factor(schoolnr)147   7.4570 0.4345  17.162        31.5      &lt; 0.001  ***\n factor(schoolnr)148   2.0988 0.4457   4.709        34.9      &lt; 0.001  ***\n factor(schoolnr)149   2.5312 0.4209   6.014        30.9      &lt; 0.001  ***\n factor(schoolnr)150   1.5676 0.4150   3.777        31.5      &lt; 0.001  ***\n factor(schoolnr)151   0.8163 0.4195   1.946        31.6      0.06058    .\n factor(schoolnr)152   6.2098 0.4255  14.593        32.5      &lt; 0.001  ***\n factor(schoolnr)155   4.0699 0.4161   9.782        31.0      &lt; 0.001  ***\n factor(schoolnr)156   1.0325 0.4308   2.397        31.4      0.02266    *\n factor(schoolnr)159   2.8261 0.4024   7.023        31.8      &lt; 0.001  ***\n factor(schoolnr)160   3.5236 0.2557  13.779        38.4      &lt; 0.001  ***\n factor(schoolnr)161   5.4721 0.3829  14.293        32.8      &lt; 0.001  ***\n factor(schoolnr)164   4.6960 0.4234  11.091        30.5      &lt; 0.001  ***\n factor(schoolnr)167   3.8574 0.4182   9.224        30.6      &lt; 0.001  ***\n factor(schoolnr)170   1.9269 0.4180   4.610        31.1      &lt; 0.001  ***\n factor(schoolnr)175   4.1858 0.4077  10.267        35.7      &lt; 0.001  ***\n factor(schoolnr)176   6.5950 0.4201  15.700        31.0      &lt; 0.001  ***\n factor(schoolnr)177   1.4245 0.4199   3.392        30.5      0.00194   **\n factor(schoolnr)179  -7.1657 0.2125 -33.715        41.9      &lt; 0.001  ***\n factor(schoolnr)182   1.7860 0.2113   8.451        34.4      &lt; 0.001  ***\n factor(schoolnr)183   0.8589 0.3729   2.303        30.5      0.02826    *\n factor(schoolnr)184   0.9973 0.3839   2.598        33.5      0.01383    *\n factor(schoolnr)188  -0.5847 0.3032  -1.928        33.1      0.06242    .\n factor(schoolnr)189   3.2232 0.3779   8.530        32.1      &lt; 0.001  ***\n factor(schoolnr)192  -1.8091 0.4496  -4.023        37.0      &lt; 0.001  ***\n factor(schoolnr)193   6.2468 0.4308  14.501        32.7      &lt; 0.001  ***\n factor(schoolnr)195   0.6267 0.4210   1.488        31.7      0.14650     \n factor(schoolnr)196   2.7931 0.4324   6.459        35.0      &lt; 0.001  ***\n factor(schoolnr)197   1.3164 0.4603   2.860        34.6      0.00713   **\n factor(schoolnr)198  -2.5450 0.3200  -7.953        34.3      &lt; 0.001  ***\n factor(schoolnr)199  -4.1093 0.2785 -14.757        32.7      &lt; 0.001  ***\n factor(schoolnr)204   0.9846 0.4150   2.373        31.2      0.02399    *\n factor(schoolnr)206   3.7918 0.4353   8.710        32.0      &lt; 0.001  ***\n factor(schoolnr)209   2.4428 0.4206   5.807        32.5      &lt; 0.001  ***\n factor(schoolnr)210  -0.4076 0.4372  -0.932        32.1      0.35823     \n factor(schoolnr)212   1.3766 0.4185   3.289        31.1      0.00250   **\n factor(schoolnr)214  -3.5027 0.2946 -11.888        32.9      &lt; 0.001  ***\n factor(schoolnr)215   2.4207 0.4178   5.794        30.4      &lt; 0.001  ***\n factor(schoolnr)216   3.2505 0.4410   7.372        32.5      &lt; 0.001  ***\n factor(schoolnr)217   3.1796 0.4449   7.147        32.2      &lt; 0.001  ***\n factor(schoolnr)218   5.1435 0.3697  13.911        62.4      &lt; 0.001  ***\n factor(schoolnr)219   5.0357 0.4230  11.905        30.3      &lt; 0.001  ***\n factor(schoolnr)222   1.2702 0.4156   3.056        31.8      0.00451   **\n factor(schoolnr)224   0.1618 0.4265   0.379        31.1      0.70703     \n factor(schoolnr)226   0.4386 0.4260   1.030        32.3      0.31078     \n factor(schoolnr)227   3.1155 0.4252   7.328        30.6      &lt; 0.001  ***\n factor(schoolnr)228   7.8209 0.4246  18.420        31.2      &lt; 0.001  ***\n factor(schoolnr)231   4.9959 0.4204  11.882        31.2      &lt; 0.001  ***\n factor(schoolnr)233  -3.6288 0.4254  -8.531        33.5      &lt; 0.001  ***\n factor(schoolnr)234   4.4580 0.3188  13.983        32.4      &lt; 0.001  ***\n factor(schoolnr)235   4.1846 0.4228   9.897        31.6      &lt; 0.001  ***\n factor(schoolnr)237   1.6961 0.4150   4.087        31.1      &lt; 0.001  ***\n factor(schoolnr)240  -0.2137 0.4258  -0.502        31.8      0.61922     \n factor(schoolnr)241   1.8219 0.4171   4.368        30.5      &lt; 0.001  ***\n factor(schoolnr)242   5.1196 0.4241  12.072        31.1      &lt; 0.001  ***\n factor(schoolnr)243   4.7182 0.4237  11.135        32.9      &lt; 0.001  ***\n factor(schoolnr)244  -0.8147 0.4161  -1.958        31.0      0.05931    .\n factor(schoolnr)246   3.9481 0.4392   8.989        32.1      &lt; 0.001  ***\n factor(schoolnr)249   0.1811 0.4219   0.429        31.6      0.67064     \n factor(schoolnr)250  -0.6933 0.4225  -1.641        33.8      0.11005     \n factor(schoolnr)252  -0.3637 0.4199  -0.866        30.4      0.39321     \n factor(schoolnr)256  -8.2543 0.4278 -19.295        31.9      &lt; 0.001  ***\n factor(schoolnr)258  -8.2412 0.4220 -19.529        33.5      &lt; 0.001  ***"
  },
  {
    "objectID": "tareas/tarea-3-respuestas.html#pregunta-1",
    "href": "tareas/tarea-3-respuestas.html#pregunta-1",
    "title": "Respuestas a la tarea 3",
    "section": "",
    "text": "En este ejercicio continuaremos usando los datos del estudio de Card (1993) para estudiar los rendimientos a la educación. Los datos ingresos_iv.dta contiene una muestra de hombres de entre 24 y 36 años de edad. lwage es el logaritmo del ingreso y educ es la educación acumulada.\n\n[3 puntos] Estime una regresión por MCO para explicar el logaritmo del salario (lwage) en función de la educación educ y los siguientes controles: exper, expersq, black, south, smsa, reg661, reg662, reg663, reg664, reg665, reg666, reg667, reg668 y smsa66. Reporte errores clásicos y errores robustos. ¿Qué problema encuentra en la estimación de esta relación? ¿El coeficiente sobre educ tiene una interpretación causal del efecto de la educación en el salario?\nEstimamos por MCO la relación entre salarios y educación, controlando por un conjunto de regresores:\n\ndata.ingresos&lt;-read_csv(\"../files/ingresos_iv.csv\",\n                        locale = locale(encoding = \"latin1\"))\n\nregmco &lt;- lm(lwage ~ educ + exper + expersq + black + south + smsa + reg661 +\n              reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66,\n            data = data.ingresos)\n\nstargazer(regmco, regmco,\n          type = 'text',\n          se = list(NULL,\n                    sqrt(diag(vcovHC(regmco, type = \"HC0\")))),\n          keep = 'educ')\n\n\n============================================================\n                                    Dependent variable:     \n                                ----------------------------\n                                           lwage            \n                                     (1)            (2)     \n------------------------------------------------------------\neduc                               0.075***      0.075***   \n                                   (0.003)        (0.004)   \n\n------------------------------------------------------------\nObservations                        3,010          3,010    \nR2                                  0.300          0.300    \nAdjusted R2                         0.296          0.296    \nResidual Std. Error (df = 2994)     0.372          0.372    \nF Statistic (df = 15; 2994)       85.476***      85.476***  \n============================================================\nNote:                            *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nHay una relación de 7.4% mayor ingreso por cada año de educación adicional. Sin embargo, esta no es una relación causal pues es muy probable que la educación no sea exógena en la ecuación de salarios. Esto puede deberse, por ejemplo, a una variable omitida de habilidad que afecta tanto al número de años de educación alcanzados como al desempeño en el mercado de trabajo.\n[3 puntos] Se propone usar una variable dicotómica que indica si el individuo vivía cerca de una universidad cuando era niño, como instrumento de los años de educación. ¿Qué condiciones debe cumplir la variable propuesta para funcionar como instrumento válido?\nEl instrumento debe cumplir dos condiciones:\nExogeneidad: el instrumento no debe pertenecer a la ecuación de salarios. Es decir, el haber crecido cerca de una universidad no debe afectar el salario contemporáneo de forma directa.\nRelevancia: el instrumento debe estar correlacionado con la variable endógena. En este caso, haber crecido cerca de una universidad debe estar correlacionado con el número de años de educación completados.\n[4 puntos] ¿Cómo juzga la propuesta de usar la variable antes descrita como instrumento?\nEste argumento fue usado por Card (1995) para mostrar que los rendimientos a la educación están subestimados por un estimador de MCO. Card muestra que al usar variables instrumentales, el efecto estimado es de 25 a 60% más grande.\nNo hay una respuesta correcta o incorrecta. Quiero leer sus argumentos.\n[3 puntos] Estime la relación entre el logaritmo del salario y la educación usando la variable dicotómica de acceso a una universidad, nearc4, como instrumento. Emplee las mismas variables de control que en el modelo de MCO. Reporte errores clásicos y errores robustos.\n\nregvi &lt;- ivreg(lwage ~ educ + exper + expersq + black + south + smsa + reg661 +\n                 reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66  |\n                 nearc4 + exper + expersq + black + south + smsa + reg661 +\n                 reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66,\n               data=data.ingresos)\n\nstargazer(regmco, regmco, regvi, regvi,\n          type = 'text',\n          se = list(NULL,\n                    sqrt(diag(vcovHC(regmco, type = \"HC0\"))),\n                    NULL,\n                    sqrt(diag(vcovHC(regvi, type = \"HC0\")))),\n          keep = 'educ')\n\n\n===================================================================\n                                        Dependent variable:        \n                                -----------------------------------\n                                               lwage               \n                                        OLS          instrumental  \n                                                       variable    \n                                   (1)       (2)      (3)     (4)  \n-------------------------------------------------------------------\neduc                            0.075***  0.075***  0.132** 0.132**\n                                 (0.003)   (0.004)  (0.055) (0.054)\n\n-------------------------------------------------------------------\nObservations                      3,010     3,010    3,010   3,010 \nR2                                0.300     0.300    0.238   0.238 \nAdjusted R2                       0.296     0.296    0.234   0.234 \nResidual Std. Error (df = 2994)   0.372     0.372    0.388   0.388 \nF Statistic (df = 15; 2994)     85.476*** 85.476***                \n===================================================================\nNote:                                   *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n[4 puntos] Interprete la primera etapa en términos del coeficiente sobre el instrumento. Obtenga el estadístico \\(F\\) del instrumento excluido e interprete su magnitud.\nEn la primera etapa, haber vivido cerca de una universidad incrementa en 0.32 los años de escolaridad acumulados. Este efecto estadísticamente significativo al 1%. El estadístico F es de una magnitud de 13.256, por encima de 10, la regla de dedo comúnmente empleada para juzgar la presencia de instrumentos débiles.\n\nregpe &lt;- lm(educ ~ nearc4 + exper + expersq + black + south + smsa + reg661 +\n              reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66,\n            data=data.ingresos)\n\nstargazer(regpe,\n          type = 'text',\n          se = list(sqrt(diag(vcovHC(regpe, type = \"HC0\")))),\n          keep = 'nearc4')\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                               educ            \n-----------------------------------------------\nnearc4                       0.320***          \n                              (0.085)          \n\n-----------------------------------------------\nObservations                   3,010           \nR2                             0.477           \nAdjusted R2                    0.474           \nResidual Std. Error      1.941 (df = 2994)     \nF Statistic         182.129*** (df = 15; 2994) \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\nlinearHypothesis(regpe, \"nearc4=0\")\n\nLinear hypothesis test\n\nHypothesis:\nnearc4 = 0\n\nModel 1: restricted model\nModel 2: educ ~ nearc4 + exper + expersq + black + south + smsa + reg661 + \n    reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + \n    smsa66\n\n  Res.Df   RSS Df Sum of Sq      F    Pr(&gt;F)    \n1   2995 11324                                  \n2   2994 11274  1    49.917 13.256 0.0002763 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[3 puntos] Interprete el coeficiente sobre la variable de educación en el modelo estructural. Compare la magnitud del efecto estimado con el resultado de MCO.\nEl coeficiente estimado sobre los años de educación indica que un año adicional de escolaridad incrementa en 13.15% el salario. Este efecto es casi el doble del estimado por MCO y estadísticamente significativo al 5%.\n\nstargazer(regmco, regvi,\n          type = 'text',\n          title=\"Comparación de estimadores de MCO y VI\", \n          se = list(sqrt(diag(vcovHC(regmco, type = \"HC0\"))),\n                    sqrt(diag(vcovHC(regvi, type = \"HC0\")))),\n          keep = 'educ')\n\n\nComparación de estimadores de MCO y VI\n======================================================================\n                                         Dependent variable:          \n                                --------------------------------------\n                                                lwage                 \n                                           OLS            instrumental\n                                                            variable  \n                                           (1)                (2)     \n----------------------------------------------------------------------\neduc                                    0.075***            0.132**   \n                                         (0.004)            (0.054)   \n\n----------------------------------------------------------------------\nObservations                              3,010              3,010    \nR2                                        0.300              0.238    \nAdjusted R2                               0.296              0.234    \nResidual Std. Error (df = 2994)           0.372              0.388    \nF Statistic                     85.476*** (df = 15; 2994)             \n======================================================================\nNote:                                      *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n[3 puntos] Realice ahora el siguiente procedimiento. Primero, estime la primera etapa usando una regresión por MCO. Obtenga los valores ajustados de educación y llámelos educ_hat. Luego, estime la segunda etapa empleando educ_hat como variable independiente, además del resto de variables de control. ¿Cómo cambian sus resultados en comparación con la parte d.?\nLa magnitud de los coeficientes estimados es la misma. Esto es lo que esperábamos pues sabemos que el estimador de MC2E puede entenderse como un procedimiento donde primero se estiman los valores ajustados de la variable endógena usando el instrumento y las variables de control y luego se usan estos valores ajustados en la ecuación estructural. En cambio, los errores estándar son algo distintos.\n\ndata.ingresos &lt;- data.ingresos %&gt;% \n  mutate(educ_hat = predict(regpe, .))\n\nreg2e &lt;- lm(lwage ~ educ_hat + exper + expersq + black + south + smsa + reg661 +\n              reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66,\n            data=data.ingresos)\n\n#Comparamos\nstargazer(regvi, reg2e,   \n          title=\"Comparación de VI con la función ivreg y el estimador a mano\",\n          type=\"text\", \n          keep = c(\"educ\", \"educ_hat\"),\n          df=FALSE, digits=4)\n\n\nComparación de VI con la función ivreg y el estimador a mano\n================================================\n                        Dependent variable:     \n                    ----------------------------\n                               lwage            \n                     instrumental       OLS     \n                       variable                 \n                          (1)           (2)     \n------------------------------------------------\neduc                   0.1315**                 \n                       (0.0550)                 \n\neduc_hat                              0.1315**  \n                                      (0.0565)  \n\n------------------------------------------------\nObservations             3,010         3,010    \nR2                      0.2382         0.1947   \nAdjusted R2             0.2343         0.1907   \nResidual Std. Error     0.3883         0.3993   \nF Statistic                          48.2537*** \n================================================\nNote:                *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n[3 puntos] ¿A qué se deben las discrepancias que encuentra? ¿Cuál de las dos estrategias prefiere para estimar el modelo de variables instrumentales?\nLos coeficientes estimados son exactamente iguales, pero los errores estándar no. El problema es que nuestro procedimiento de MC2E a mano no toma en cuenta que en la ecuación estructural estamos usando valores ajustados de la variable endógena. Las funciones en la mayoría de los paquetes utilizados en econometría calculan los errores estándar de manera correcta. Preferimos usar las funciones previamente ya programadas cuando sea posible, aunque este ejercicio nos ayuda a reforzar la intuición del estimador de MC2E.\n[3 puntos] Reestime el modelo de variables instrumentales añadiendo un segundo instrumento, nearc2, y reporte errores robustos (no es necesario usar gmm, puede seguir con ivreg, por lo que no estaría obteniendo el estimador de MGM óptimo). ¿Cómo cambian sus resultados para la ecuación estructural con respecto al caso exactamente identificado?\nEl efecto estimado es significativo al 1% y en magnitud se incrementa ligeramente hasta 0.157.\n\nregvi2 &lt;- ivreg(lwage ~ educ + exper + expersq + black + south + smsa + reg661 +\n                 reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66  |\n                 nearc4 + nearc2 + exper + expersq + black + south + smsa + reg661 +\n                 reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66,\n               data=data.ingresos)\n\nstargazer(regmco, regvi, regvi2,\n          type = 'text',\n          se = list(sqrt(diag(vcovHC(regmco, type = \"HC0\"))),\n                    sqrt(diag(vcovHC(regvi, type = \"HC0\"))),\n                    sqrt(diag(vcovHC(regvi2, type = \"HC0\")))),\n          keep = 'educ')\n\n\n==========================================================================\n                                           Dependent variable:            \n                                ------------------------------------------\n                                                  lwage                   \n                                           OLS              instrumental  \n                                                              variable    \n                                           (1)              (2)     (3)   \n--------------------------------------------------------------------------\neduc                                    0.075***          0.132** 0.157***\n                                         (0.004)          (0.054) (0.052) \n\n--------------------------------------------------------------------------\nObservations                              3,010            3,010   3,010  \nR2                                        0.300            0.238   0.170  \nAdjusted R2                               0.296            0.234   0.166  \nResidual Std. Error (df = 2994)           0.372            0.388   0.405  \nF Statistic                     85.476*** (df = 15; 2994)                 \n==========================================================================\nNote:                                          *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n[3 puntos] Con el objeto que resulta de la estimación del modelo sobreidentificado, realice summary(OBJETO, vcov = sandwich, diagnostics = TRUE) para obtener las tres pruebas diagnóstico más usadas en variables instrumentales: prueba de instrumentos débiles, prueba de Hausman y prueba de Sargan. Interprete cada una de las pruebas.\n\nsummary(regvi2, vcov = sandwich, diagnostics = TRUE)\n\n\nCall:\nivreg(formula = lwage ~ educ + exper + expersq + black + south + \n    smsa + reg661 + reg662 + reg663 + reg664 + reg665 + reg666 + \n    reg667 + reg668 + smsa66 | nearc4 + nearc2 + exper + expersq + \n    black + south + smsa + reg661 + reg662 + reg663 + reg664 + \n    reg665 + reg666 + reg667 + reg668 + smsa66, data = data.ingresos)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.93841 -0.25068  0.01932  0.26519  1.46998 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  3.3396868  0.8909170   3.749 0.000181 ***\neduc         0.1570594  0.0524127   2.997 0.002753 ** \nexper        0.1188149  0.0228905   5.191 2.24e-07 ***\nexpersq     -0.0023565  0.0003674  -6.414 1.64e-10 ***\nblack       -0.1232778  0.0514904  -2.394 0.016718 *  \nsouth       -0.1431945  0.0301873  -4.744 2.20e-06 ***\nsmsa         0.1007530  0.0313621   3.213 0.001329 ** \nreg661      -0.1029760  0.0425755  -2.419 0.015637 *  \nreg662      -0.0002286  0.0345230  -0.007 0.994716    \nreg663       0.0469556  0.0335252   1.401 0.161435    \nreg664      -0.0554084  0.0408927  -1.355 0.175529    \nreg665       0.0515041  0.0506274   1.017 0.309085    \nreg666       0.0699968  0.0534531   1.309 0.190466    \nreg667       0.0390596  0.0514309   0.759 0.447639    \nreg668      -0.1980371  0.0522335  -3.791 0.000153 ***\nsmsa66       0.0150626  0.0211120   0.713 0.475616    \n\nDiagnostic tests:\n                  df1  df2 statistic  p-value    \nWeak instruments    2 2993     8.366 0.000238 ***\nWu-Hausman          1 2993     2.978 0.084509 .  \nSargan              1   NA     1.248 0.263905    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4053 on 2994 degrees of freedom\nMultiple R-Squared: 0.1702,  Adjusted R-squared: 0.166 \nWald test: 51.65 on 15 and 2994 DF,  p-value: &lt; 2.2e-16 \n\n\nLa prueba de instrumentos débiles rechaza la \\(H_0\\) de que los instrumentos son débiles, por lo que tenemos primera etapa.\nLa prueba de Hausman rechaza al 10% que los estimadores de VI y de MCO sean iguales, por lo que se prefiere el de VI.\nLa prueba de Sargan no rechaza la \\(H_0\\) de que el modelo esté mal especificado.\n[4 puntos] Considere la primera etapa del modelo sobreidentificado. Compruebe que si realiza una prueba de significancia conjunta para los instrumentos obtiene la prueba de instrumentos débiles que se reporta en el resumen que obtuvo con summary.\nEn el apartado anterior, obtenemos un valor \\(p=0.000238\\) para la prueba de instrumentos débiles. Noten que se especificó una matriz de varianzas robustas. Entonces, tenemos que usar la misma matriz en la prueba \\(F\\):\n\nregpe2 &lt;- lm(educ ~ nearc4 + nearc2 + exper + expersq + black + south + smsa + reg661 +\n              reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66,\n            data=data.ingresos)\n\nlinearHypothesis(regpe2, c(\"nearc4=0\", \"nearc2=0\"), white.adjust = \"hc0\")\n\nLinear hypothesis test\n\nHypothesis:\nnearc4 = 0\nnearc2 = 0\n\nModel 1: restricted model\nModel 2: educ ~ nearc4 + nearc2 + exper + expersq + black + south + smsa + \n    reg661 + reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + \n    reg668 + smsa66\n\nNote: Coefficient covariance matrix supplied.\n\n  Res.Df Df      F    Pr(&gt;F)    \n1   2995                        \n2   2993  2 8.3662 0.0002381 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nObtenemos el mismo valor \\(p\\) y maginitud del estadístico \\(F\\).\n[4 puntos] Compruebe que si realiza el procedimiento de regresión auxiliar para la prueba de Hausman obtiene el mismo valor \\(p\\) que se reporta en el resumen que obtuvo con summary.\nDe la primera etapa, obtenemos los residuales:\n\n    data.ingresos &lt;- data.ingresos %&gt;% \n      mutate(vhat = resid(regpe2))\n\nCorremos la regresión auxiliar con los residuales:\n\n    regaux &lt;- lm(lwage ~ educ + exper + expersq + black + south + smsa + reg661 +\n                 reg662 + reg663 + reg664 + reg665 + reg666 + reg667 + reg668 + smsa66 + vhat,\n               data=data.ingresos)\n\nstargazer(regaux,\n          type = 'text',\n          se = list(sqrt(diag(vcovHC(regaux, type = \"HC0\")))),\n          keep = 'vhat',\n          report = c(\"c*s*p\"))\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                               lwage           \n-----------------------------------------------\n                              -0.083*          \n                             (0.048)*          \n                             p = 0.085         \n\n-----------------------------------------------\nObservations                   3,010           \nR2                             0.301           \nAdjusted R2                    0.297           \nResidual Std. Error      0.372 (df = 2993)     \nF Statistic          80.368*** (df = 16; 2993) \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nEl valor \\(p\\) es idéntico al obtenido con summary."
  },
  {
    "objectID": "tareas/tarea-3-respuestas.html#pregunta-2",
    "href": "tareas/tarea-3-respuestas.html#pregunta-2",
    "title": "Respuestas a la tarea 3",
    "section": "",
    "text": "Considere los datos comportamiento_wide.csv, que contienen información individual de niñas y niños, incluyendo su género, edad, raza e información de sus madres. Además, se incluye una medida auto reportada de autoestima (self) y una evaluación de comportamiento antisocial (anti). Se quiere conocer cómo influye la autoestima en el comportamiento antisocial. Para cada niño o niña hay tres observaciones en el tiempo. Se busca explicar el comportamiento antisocial en función de la autoestima y la condición de pobreza (pov):\n\\[anti_{it}=\\alpha_i+\\beta_1 self_{it}+\\beta_2 pov_{it}+\\varepsilon_{it}\\]\n\n[2 puntos] La base se encuentra en formato wide. Ponga la base en formato long, donde haya una columna para cada variable y donde las filas representen a un individuo en un periodo.\nHay muchas formas de hacer esto. Podemos usar las funciones pivot_longer y pivot_wider, por ejemplo.\n\ndata.comp &lt;-read_csv(\"../files/comportamiento_wide.csv\",\n                      locale = locale(encoding = \"latin1\")) %&gt;%\n  pivot_longer(c(anti90:anti94,self90:self94,pov90:pov94),\n               names_to = c(\"measure\", \"year\"),\n               names_pattern = \"(.*)(..)\")  %&gt;%\n  pivot_wider(names_from = measure,\n              values_from = value)\n\ncolnames(data.comp)\n\n [1] \"id\"       \"momage\"   \"gender\"   \"childage\" \"hispanic\" \"black\"   \n [7] \"momwork\"  \"married\"  \"year\"     \"anti\"     \"self\"     \"pov\"     \n\n\n[2 puntos] Estime la ecuación de comportamiento antisocial empleando MCO pooled. ¿Cuáles son los supuestos que se deben cumplir para que \\(\\hat{\\beta}_1^{MCO}\\) sea consistente?\n\nsummary(m.mco &lt;- plm( anti ~ self + pov,\n                      data=data.comp,\n                      model=\"pooling\",\n                      index = c(\"id\", \"year\")))\n\nPooling Model\n\nCall:\nplm(formula = anti ~ self + pov, data = data.comp, model = \"pooling\", \n    index = c(\"id\", \"year\"))\n\nBalanced Panel: n = 581, T = 3, N = 1743\n\nResiduals:\n    Min.  1st Qu.   Median  3rd Qu.     Max. \n-2.65689 -1.29476 -0.33138  0.98912  4.77034 \n\nCoefficients:\n             Estimate Std. Error t-value  Pr(&gt;|t|)    \n(Intercept)  2.792098   0.231110 12.0812 &lt; 2.2e-16 ***\nself        -0.065102   0.011083 -5.8739 5.089e-09 ***\npov          0.515809   0.078730  6.5516 7.476e-11 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    4333.1\nResidual Sum of Squares: 4140.6\nR-Squared:      0.044433\nAdj. R-Squared: 0.043335\nF-statistic: 40.4544 on 2 and 1740 DF, p-value: &lt; 2.22e-16\n\n\nLa variable self tiene un efecto negativo y estadísticamente significativo sobre anti. La variable pov tiene un efecto positivo y estadísticamente significativo. El estimador de MCO será consistente solo si las variables self y pov no están correlacionadas con el error. Además, para estimar este modelo, asumimos que la heterogeneidad no observada \\(\\alpha_i\\) puede escribirse simplemente como \\(\\alpha\\). Otra forma de pensar sobre este modelo es si el mismo modelo es válido para todos los periodos como para asumir una ordenada al origen y una pendiente común. El modelo pooled ignora la naturaleza en panel de los datos. Sin embargo, como tenemos a los mismos individuos en varios puntos del tiempo, los errores están agrupados, así que se deben de estimar errores con esta estructura. En este caso, al tomar en cuenta esta correlación entre grupos, los errores estándar son más grandes, pero los resultados siguen siendo significativos. En muchos casos, no tomar en cuenta la estructura agrupada de los errores puede llevar a rechazar hipótesis nulas que son ciertas.\n\ncoeftest(m.mco,\n         vcov = vcovHC(m.mco, type = \"HC1\", cluster=\"group\"))\n\n\nt test of coefficients:\n\n             Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  2.792098   0.293380  9.5170 &lt; 2.2e-16 ***\nself        -0.065102   0.013687 -4.7565 2.132e-06 ***\npov          0.515809   0.104963  4.9142 9.753e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[3 puntos] Estime la ecuación de comportamiento antisocial empleando el estimador within. ¿Cuáles son los supuestos que se deben cumplir para que \\(\\hat{\\beta}_1^{FE}\\) sea consistente?\nSi asumimos que la heterogeneidad no observada y el error están potencialmente correlacionados, entonces podemos usar un estimador de efectos fijos para deshacernos de la heterogeneidad no observada y estimar consistentemente los parámetros sobre self y pov.\n\nm.fe &lt;- plm( anti ~ self + pov,\n             data=data.comp,\n             model=\"within\",\n             index = c(\"id\", \"year\"))\n\ncoeftest(m.fe,\n         vcov = vcovHC(m.fe, type = \"HC1\", cluster=\"group\"))\n\n\nt test of coefficients:\n\n      Estimate Std. Error t value  Pr(&gt;|t|)    \nself -0.051495   0.011308 -4.5540 5.818e-06 ***\npov   0.104899   0.099188  1.0576    0.2905    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[3 puntos] Estime la ecuación de comportamiento antisocial empleando efectos aleatorios. ¿Cuáles son los supuestos que se deben cumplir para que \\(\\hat{\\beta}_1^{RE}\\) sea consistente?\nSi estamos dispuestos a asumir que la heterogeneidad no observada y el error son independientes, podemos emplear el estimador de efectos aleatorios. MCO pooled también es consistente pero no es eficiente.\n\nm.re &lt;- plm( anti ~ self + pov,\n             data=data.comp,\n             model=\"random\",\n             index = c(\"id\", \"year\"))\n\ncoeftest(m.re,\n         vcov = vcovHC(m.re, type = \"HC1\", cluster=\"group\"))\n\n\nt test of coefficients:\n\n             Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  2.695210   0.222607 12.1075 &lt; 2.2e-16 ***\nself        -0.056732   0.010216 -5.5534 3.234e-08 ***\npov          0.292407   0.081956  3.5679 0.0003696 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[3 puntos] Se desea incorporar en el análisis el género (gender) y una variable dicotómica para los hispanos (hispanic). Indique qué modelo usaría y estime dicho modelo.\nNo es posible estimar los coeficientes sobre variables que no varían en el tiempo usando efectos fijos, por lo que este modelo queda descartado. Podríamos usar MCO pooled, que impone supuestos muy fuertes. La otra alternativa es un modelo de efectos aleatorios, que asume que la heterogeneidad no observada y el error no están correlacionados.\n\nm.sex &lt;- plm( anti ~ self + pov + gender,\n              data=data.comp,\n              model=\"random\",\n              index = c(\"id\", \"year\"))\n\ncoeftest(m.sex,\n         vcov = vcovHC(m.sex, type = \"HC1\", cluster=\"group\"))\n\n\nt test of coefficients:\n\n             Estimate Std. Error t value  Pr(&gt;|t|)    \n(Intercept)  2.970534   0.231591 12.8267 &lt; 2.2e-16 ***\nself        -0.058558   0.010223 -5.7278 1.197e-08 ***\npov          0.304997   0.081486  3.7429 0.0001878 ***\ngender      -0.480468   0.107126 -4.4851 7.766e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[2 puntos] Regrese al modelo que incluye solo la autoestima y el estado de pobreza como covariables. Realice una prueba de Hausman para determinar si se prefiere un modelo de efectos fijos o uno de efectos aleatorios.\nLa implementación de la prueba de Hausman indica que se rechaza la H0 de que los coeficientes estimados son iguales (y que el modelo de efectos aleatorios es el adecuado). Hay evidencia de que se prefiere un modelo de efectos fijos, aunque tendremos que vivir con el hecho de no poder estimar el coeficiente asociado a las variables que no varían en el tiempo en este caso.\n\nphtest(m.fe, m.re)\n\n\n Hausman Test\n\ndata:  anti ~ self + pov\nchisq = 13.578, df = 2, p-value = 0.001126\nalternative hypothesis: one model is inconsistent"
  },
  {
    "objectID": "tareas/tarea-3-respuestas.html#pregunta-3",
    "href": "tareas/tarea-3-respuestas.html#pregunta-3",
    "title": "Respuestas a la tarea 3",
    "section": "",
    "text": "Retome los datos de la pregunta 2 y el modelo del comportamiento antisocial en función de la autoestima y la pobreza. En esta pregunta mostraremos la equivalencia del estimador within con otros estimadores.\n\n[3 puntos] Compruebe que el estimador de efectos fijos es equivalente a MCO con dummies de individuos.\nComprobamos:\n\nm.fe &lt;- plm( anti ~ self + pov,\n             data=data.comp,\n             model=\"within\",\n             index = c(\"id\", \"year\"))\n\nm.dummy &lt;- lm(anti ~ self + pov + factor(id),\n              data=data.comp)\n\nstargazer(m.fe, m.dummy, keep=c(\"self\", \"pov\"), type=\"text\")\n\n\n======================================================================\n                                   Dependent variable:                \n                    --------------------------------------------------\n                                           anti                       \n                             panel                      OLS           \n                             linear                                   \n                              (1)                       (2)           \n----------------------------------------------------------------------\nself                       -0.051***                 -0.051***        \n                            (0.011)                   (0.011)         \n\npov                          0.105                     0.105          \n                            (0.094)                   (0.094)         \n\n----------------------------------------------------------------------\nObservations                 1,743                     1,743          \nR2                           0.021                     0.731          \nAdjusted R2                  -0.470                    0.596          \nResidual Std. Error                              1.002 (df = 1160)    \nF Statistic         12.551*** (df = 2; 1160) 5.417*** (df = 582; 1160)\n======================================================================\nNote:                                      *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n[2 puntos] Compruebe que en un modelo de efectos fijos las características que no varían en el tiempo no pueden ser identificadas. Añada la variable black para comprobarlo.\nComprobamos que la variable simplemente es omitida del análisis:\n\nsummary(plm( anti ~ self + pov + black,\n             data=data.comp,\n             model=\"within\",\n             index = c(\"id\", \"year\")))\n\nOneway (individual) effect Within Model\n\nCall:\nplm(formula = anti ~ self + pov + black, data = data.comp, model = \"within\", \n    index = c(\"id\", \"year\"))\n\nBalanced Panel: n = 581, T = 3, N = 1743\n\nResiduals:\n      Min.    1st Qu.     Median    3rd Qu.       Max. \n-3.7868224 -0.4706542 -0.0012721  0.4534891  3.2646729 \n\nCoefficients:\n      Estimate Std. Error t-value  Pr(&gt;|t|)    \nself -0.051495   0.010530 -4.8902 1.149e-06 ***\npov   0.104899   0.093880  1.1174    0.2641    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nTotal Sum of Squares:    1190.7\nResidual Sum of Squares: 1165.4\nR-Squared:      0.021182\nAdj. R-Squared: -0.46991\nF-statistic: 12.5514 on 2 and 1160 DF, p-value: 4.0471e-06\n\n\n[5 puntos] Compruebe que el estimador de efectos fijos es equivalente a MCO sobre el modelo en diferencias con respecto a la media. Para esto, conserve dos periodos consecutivos de datos y solo observaciones que tengan datos para las variables dependientes e independientes en los dos años que elija. Luego estime por MCO el modelo con variables transformadas.\nNos quedamos con un subconjunto de datos:\n\ndata.comp.sub &lt;- data.comp %&gt;% \n  dplyr::select(id, year, anti, self, pov) %&gt;% \n  filter(year==90 | year==92)\n\n#Nos quedamos con los que no son NA\ndata.comp.sub &lt;- data.comp.sub[complete.cases(data.comp.sub), ]\n\nCreamos las variables como diferencias respecto a la media y estimamos el modelo within y el modelo de MCO en las variables transformadas:\n\ndata.comp.sub &lt;- data.comp.sub %&gt;%\n  group_by(id) %&gt;% \n  mutate(m.anti = mean(anti),\n         m.self = mean(self),\n         m.pov = mean(pov)) %&gt;% \n  mutate(dm.anti = anti - m.anti,\n         dm.self = self - m.self,\n         dm.pov = pov - m.pov)\n\nm.fe.sub &lt;- plm( anti ~ self + pov,\n                 data=data.comp.sub,\n                 model=\"within\",\n                 index = c(\"id\", \"year\"))\n\n\nm.demean &lt;- lm(dm.anti ~ dm.self + dm.pov,\n               data.comp.sub)\n\nstargazer(m.fe.sub, m.demean,\n          keep=c(\"self\", \"pov\", \"dm.self\",\"dm.pov\"),\n          type=\"text\")\n\n\n==================================================================\n                                 Dependent variable:              \n                    ----------------------------------------------\n                             anti                  dm.anti        \n                            panel                    OLS          \n                            linear                                \n                             (1)                     (2)          \n------------------------------------------------------------------\nself                      -0.038***                               \n                           (0.014)                                \n\npov                         0.195                                 \n                           (0.133)                                \n\ndm.self                                           -0.038***       \n                                                   (0.010)        \n\ndm.pov                                             0.195**        \n                                                   (0.094)        \n\n------------------------------------------------------------------\nObservations                1,162                   1,162         \nR2                          0.016                   0.016         \nAdjusted R2                 -0.972                  0.015         \nResidual Std. Error                           0.641 (df = 1159)   \nF Statistic         4.807*** (df = 2; 579) 9.621*** (df = 2; 1159)\n==================================================================\nNote:                                  *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\n[5 puntos] Compruebe que el estimador de efectos fijos es equivalente a MCO sobre el modelo en primeras diferencias. Parta de la muestra con dos años de la parte d. para estimar por MCO el modelo con variables transformadas.\nUsando el mismo subconjunto, calculamos ahora las primeras diferencias y estimamos:\n\ndata.comp.sub &lt;- data.comp.sub %&gt;%\n  group_by(id) %&gt;% \n  mutate(d.anti = anti-dplyr::lag(anti, order_by = year),\n         d.self = self-dplyr::lag(self, order_by = year),\n         d.pov = pov-dplyr::lag(pov, order_by = year)) %&gt;% \n  ungroup()\n\n\nm.difs &lt;- lm(d.anti ~ -1 + d.self + d.pov,\n             data=data.comp.sub)\n\nstargazer(m.fe.sub, m.demean, keep=c(\"self\", \"pov\", \"d.self\",\"d.pov\"), type=\"text\")\n\n\n==================================================================\n                                 Dependent variable:              \n                    ----------------------------------------------\n                             anti                  dm.anti        \n                            panel                    OLS          \n                            linear                                \n                             (1)                     (2)          \n------------------------------------------------------------------\nself                      -0.038***                               \n                           (0.014)                                \n\npov                         0.195                                 \n                           (0.133)                                \n\ndm.self                                           -0.038***       \n                                                   (0.010)        \n\ndm.pov                                             0.195**        \n                                                   (0.094)        \n\n------------------------------------------------------------------\nObservations                1,162                   1,162         \nR2                          0.016                   0.016         \nAdjusted R2                 -0.972                  0.015         \nResidual Std. Error                           0.641 (df = 1159)   \nF Statistic         4.807*** (df = 2; 579) 9.621*** (df = 2; 1159)\n==================================================================\nNote:                                  *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01"
  },
  {
    "objectID": "tareas/tarea-3-respuestas.html#pregunta-4",
    "href": "tareas/tarea-3-respuestas.html#pregunta-4",
    "title": "Respuestas a la tarea 3",
    "section": "",
    "text": "Considere los datos mlbook1.csv con información sobre 2287 estudiantes en 131 escuelas. Nos interesa la relación entre una medida de aptitud verbal, (iq_vert) y el resultado de un examen de inglés (langpost). Las variables schoolnr y pupilnr identifican a las escuelas y los estudiantes, respectivamente. El modelo a estimar es el siguiente:\n\\[langpost_{i}=\\alpha+\\beta iqvert_{i}+BX_{i}+\\varepsilon_{i}\\] donde \\(i\\) indexa y \\(X_i\\) son tres características usadas como control: el sexo, sex, si el estudiante es de una población minoritaria, minority y el número de años repetidos, repeatgr.\n\n[3 puntos] ¿Por qué es posible que estemos frente a una situación de errores agrupados?\nLos datos están agrupados a nivel escuela. Los estudiantes en una misma escuela comparten características observadas y no observadas que hacen altamente probable que los factores no observables estén correlacionados entre los individuos, rompiendo el supuesto de independencia.\n[2 puntos] Estime la ecuación de calificación usando MCO ignorando la agrupación de datos. ¿Qué concluye respecto a la relación entre la aptitud verbal y la prueba de inglés?\nSe concluye que una hora más en la prueba de aptitud incrementa en 2.49 puntos la calificación del examen. El error estándar es 0.072.\n\ndata.examen&lt;-read_csv(\"../files/mlbook1.csv\",\n                      locale = locale(encoding = \"latin1\")) \n\n\nsummary(m.mco &lt;- lm(langpost ~ iq_verb + sex + minority + repeatgr, data=data.examen))\n\n\nCall:\nlm(formula = langpost ~ iq_verb + sex + minority + repeatgr, \n    data = data.examen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-28.0192  -4.2255   0.5218   4.8017  24.1421 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 10.93980    0.90504  12.088   &lt;2e-16 ***\niq_verb      2.48635    0.07233  34.374   &lt;2e-16 ***\nsex          2.42228    0.28871   8.390   &lt;2e-16 ***\nminority    -0.03701    0.62762  -0.059    0.953    \nrepeatgr    -4.40860    0.43222 -10.200   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.853 on 2282 degrees of freedom\nMultiple R-squared:  0.4217, Adjusted R-squared:  0.4207 \nF-statistic: 416.1 on 4 and 2282 DF,  p-value: &lt; 2.2e-16\n\n\n[3 puntos] Estime ahora los errores robustos a heteroscedasticidad del tipo HC1. ¿Qué cambia y por qué en la interpretación de la relación entre la prueba de aptitud y el examen?\nEl coeficiente estimado es el mismo. La fórmula empleada para calcular la varianza es una en forma de sándwich, que toma en cuenta la posible heterocedasticidad. El error estándar es apromximadamente 5% más grande, 0.076.\n\ncoeftest(m.mco, vcov = vcovHC(m.mco, type = \"HC1\"))\n\n\nt test of coefficients:\n\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 10.939796   0.985476 11.1010   &lt;2e-16 ***\niq_verb      2.486350   0.075871 32.7709   &lt;2e-16 ***\nsex          2.422279   0.288525  8.3954   &lt;2e-16 ***\nminority    -0.037006   0.612455 -0.0604   0.9518    \nrepeatgr    -4.408605   0.448615 -9.8271   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n[2 puntos] Estime la ecuación de calificación usando MCO y efectos fijos de escuela. ¿Qué resuelve este procedimiento?\nAl incluir efectos fijos a nivel escuela controlamos por características no observadas a nivel escuela. Estas diferencias se incorporan en el modelo como desplazamientos de la ordenada al origen. Este procedimiento no tiene nada que ver con la agrupación de errores.\n\nsummary(m.mco.ef &lt;- lm(langpost ~ iq_verb + sex + minority + repeatgr + factor(schoolnr),\n                       data=data.examen))\n\n\nCall:\nlm(formula = langpost ~ iq_verb + sex + minority + repeatgr + \n    factor(schoolnr), data = data.examen)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-24.8792  -3.6779   0.2729   4.0985  19.6755 \n\nCoefficients:\n                    Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)         12.50218    1.54290   8.103 8.89e-16 ***\niq_verb              2.25997    0.07093  31.860  &lt; 2e-16 ***\nsex                  2.41900    0.26850   9.009  &lt; 2e-16 ***\nminority             0.23262    0.71306   0.326 0.744280    \nrepeatgr            -4.43503    0.40938 -10.834  &lt; 2e-16 ***\nfactor(schoolnr)2   -8.29681    2.67144  -3.106 0.001923 ** \nfactor(schoolnr)10  -7.28322    3.06053  -2.380 0.017412 *  \nfactor(schoolnr)12  -4.56719    2.06924  -2.207 0.027407 *  \nfactor(schoolnr)15  -7.41516    2.54948  -2.909 0.003669 ** \nfactor(schoolnr)16   2.53410    2.54854   0.994 0.320173    \nfactor(schoolnr)18  -6.80332    1.81757  -3.743 0.000187 ***\nfactor(schoolnr)21  -0.53872    1.99103  -0.271 0.786746    \nfactor(schoolnr)24   4.20444    1.81839   2.312 0.020862 *  \nfactor(schoolnr)26  -0.36076    1.96000  -0.184 0.853984    \nfactor(schoolnr)27  -5.46850    1.87909  -2.910 0.003649 ** \nfactor(schoolnr)29   3.19018    2.35758   1.353 0.176147    \nfactor(schoolnr)33  -0.34896    2.84408  -0.123 0.902359    \nfactor(schoolnr)35   1.59577    2.08305   0.766 0.443718    \nfactor(schoolnr)36  -3.99135    1.83661  -2.173 0.029873 *  \nfactor(schoolnr)38   3.05382    1.75466   1.740 0.081931 .  \nfactor(schoolnr)40   0.09036    1.67651   0.054 0.957022    \nfactor(schoolnr)41  -2.94006    2.13296  -1.378 0.168226    \nfactor(schoolnr)42  -4.99799    2.10828  -2.371 0.017845 *  \nfactor(schoolnr)44  -1.49855    2.04728  -0.732 0.464268    \nfactor(schoolnr)47  -5.73732    2.52469  -2.272 0.023156 *  \nfactor(schoolnr)48  -1.83632    2.25583  -0.814 0.415717    \nfactor(schoolnr)49  -4.14690    2.41410  -1.718 0.085979 .  \nfactor(schoolnr)52  -3.60350    1.87627  -1.921 0.054918 .  \nfactor(schoolnr)54   2.91142    1.72017   1.693 0.090691 .  \nfactor(schoolnr)55   1.49383    1.73053   0.863 0.388111    \nfactor(schoolnr)57   0.79682    1.80093   0.442 0.658210    \nfactor(schoolnr)60  -1.79256    1.83760  -0.975 0.329426    \nfactor(schoolnr)61   0.39402    1.89130   0.208 0.834990    \nfactor(schoolnr)62   2.39062    1.88568   1.268 0.205016    \nfactor(schoolnr)65   5.66979    1.85875   3.050 0.002314 ** \nfactor(schoolnr)66   1.09325    2.28956   0.477 0.633058    \nfactor(schoolnr)67  -5.59969    1.78486  -3.137 0.001728 ** \nfactor(schoolnr)68  -1.22319    1.90619  -0.642 0.521140    \nfactor(schoolnr)76  -1.14607    2.02551  -0.566 0.571577    \nfactor(schoolnr)78   0.20198    1.99000   0.101 0.919167    \nfactor(schoolnr)79   2.10981    2.10998   1.000 0.317463    \nfactor(schoolnr)80   3.31569    1.87290   1.770 0.076810 .  \nfactor(schoolnr)86   1.45319    1.81855   0.799 0.424322    \nfactor(schoolnr)87  -0.20740    1.88076  -0.110 0.912200    \nfactor(schoolnr)88   1.25972    2.35398   0.535 0.592604    \nfactor(schoolnr)90   4.45169    2.06677   2.154 0.031356 *  \nfactor(schoolnr)94   3.05367    2.05599   1.485 0.137621    \nfactor(schoolnr)95  -0.76530    1.94512  -0.393 0.694027    \nfactor(schoolnr)97   1.48348    1.98190   0.749 0.454232    \nfactor(schoolnr)98  -1.40960    1.89893  -0.742 0.457977    \nfactor(schoolnr)101  4.26255    1.83026   2.329 0.019955 *  \nfactor(schoolnr)103 -4.54699    3.34961  -1.357 0.174775    \nfactor(schoolnr)106 -2.63664    2.33290  -1.130 0.258518    \nfactor(schoolnr)107 -4.50332    1.99406  -2.258 0.024023 *  \nfactor(schoolnr)108 -1.87255    2.44170  -0.767 0.443222    \nfactor(schoolnr)109 -4.40708    1.87743  -2.347 0.018995 *  \nfactor(schoolnr)110  3.08759    1.99160   1.550 0.121215    \nfactor(schoolnr)111  1.23407    1.94637   0.634 0.526125    \nfactor(schoolnr)112 -0.24997    2.67934  -0.093 0.925678    \nfactor(schoolnr)115 -0.13189    1.72755  -0.076 0.939152    \nfactor(schoolnr)116 -0.96627    1.93966  -0.498 0.618421    \nfactor(schoolnr)118 -4.19606    2.42987  -1.727 0.084335 .  \nfactor(schoolnr)119 -0.37636    2.21669  -0.170 0.865195    \nfactor(schoolnr)121 -3.16182    2.35853  -1.341 0.180196    \nfactor(schoolnr)123  2.76021    3.34170   0.826 0.408902    \nfactor(schoolnr)124  3.69157    1.89801   1.945 0.051909 .  \nfactor(schoolnr)125  1.79787    1.76911   1.016 0.309622    \nfactor(schoolnr)130  5.61009    2.16507   2.591 0.009629 ** \nfactor(schoolnr)132  6.28128    1.87651   3.347 0.000830 ***\nfactor(schoolnr)136  3.87282    2.03048   1.907 0.056610 .  \nfactor(schoolnr)137  4.40378    1.95919   2.248 0.024693 *  \nfactor(schoolnr)141  1.14473    1.90727   0.600 0.548441    \nfactor(schoolnr)142  5.13270    1.82046   2.819 0.004855 ** \nfactor(schoolnr)147  7.45698    1.85918   4.011 6.26e-05 ***\nfactor(schoolnr)148  2.09875    1.74675   1.202 0.229682    \nfactor(schoolnr)149  2.53123    1.88015   1.346 0.178351    \nfactor(schoolnr)150  1.56758    1.80115   0.870 0.384221    \nfactor(schoolnr)151  0.81632    1.83732   0.444 0.656871    \nfactor(schoolnr)152  6.20977    1.99227   3.117 0.001852 ** \nfactor(schoolnr)155  4.06995    1.69447   2.402 0.016394 *  \nfactor(schoolnr)156  1.03255    2.21442   0.466 0.641061    \nfactor(schoolnr)159  2.82606    1.71234   1.650 0.099006 .  \nfactor(schoolnr)160  3.52358    1.80662   1.950 0.051261 .  \nfactor(schoolnr)161  5.47210    1.70824   3.203 0.001378 ** \nfactor(schoolnr)164  4.69601    1.81787   2.583 0.009853 ** \nfactor(schoolnr)167  3.85744    1.79977   2.143 0.032201 *  \nfactor(schoolnr)170  1.92686    1.78368   1.080 0.280143    \nfactor(schoolnr)175  4.18579    2.10407   1.989 0.046785 *  \nfactor(schoolnr)176  6.59497    1.83757   3.589 0.000339 ***\nfactor(schoolnr)177  1.42445    1.99027   0.716 0.474249    \nfactor(schoolnr)179 -7.16566    2.82071  -2.540 0.011143 *  \nfactor(schoolnr)182  1.78603    2.41396   0.740 0.459456    \nfactor(schoolnr)183  0.85895    1.70516   0.504 0.614499    \nfactor(schoolnr)184  0.99731    1.74622   0.571 0.567974    \nfactor(schoolnr)188 -0.58465    2.19526  -0.266 0.790015    \nfactor(schoolnr)189  3.22324    1.98341   1.625 0.104287    \nfactor(schoolnr)192 -1.80905    2.55487  -0.708 0.478973    \nfactor(schoolnr)193  6.24675    2.21572   2.819 0.004857 ** \nfactor(schoolnr)195  0.62668    1.90527   0.329 0.742247    \nfactor(schoolnr)196  2.79306    1.77499   1.574 0.115735    \nfactor(schoolnr)197  1.31643    1.90977   0.689 0.490700    \nfactor(schoolnr)198 -2.54503    2.66624  -0.955 0.339919    \nfactor(schoolnr)199 -4.10925    1.69994  -2.417 0.015719 *  \nfactor(schoolnr)204  0.98462    1.81798   0.542 0.588149    \nfactor(schoolnr)206  3.79180    2.28001   1.663 0.096446 .  \nfactor(schoolnr)209  2.44276    1.83923   1.328 0.184272    \nfactor(schoolnr)210 -0.40756    2.02750  -0.201 0.840706    \nfactor(schoolnr)212  1.37659    1.80057   0.765 0.444637    \nfactor(schoolnr)214 -3.50270    1.85506  -1.888 0.059136 .  \nfactor(schoolnr)215  2.42072    2.21308   1.094 0.274155    \nfactor(schoolnr)216  3.25053    2.68121   1.212 0.225516    \nfactor(schoolnr)217  3.17962    2.55021   1.247 0.212604    \nfactor(schoolnr)218  5.14348    1.79490   2.866 0.004203 ** \nfactor(schoolnr)219  5.03571    2.10754   2.389 0.016962 *  \nfactor(schoolnr)222  1.27021    1.81917   0.698 0.485106    \nfactor(schoolnr)224  0.16178    2.15792   0.075 0.940246    \nfactor(schoolnr)226  0.43861    2.55025   0.172 0.863464    \nfactor(schoolnr)227  3.11551    1.95897   1.590 0.111895    \nfactor(schoolnr)228  7.82086    1.88038   4.159 3.32e-05 ***\nfactor(schoolnr)231  4.99594    1.87985   2.658 0.007928 ** \nfactor(schoolnr)233 -3.62877    2.44368  -1.485 0.137700    \nfactor(schoolnr)234  4.45798    2.13964   2.084 0.037322 *  \nfactor(schoolnr)235  4.18463    2.35443   1.777 0.075653 .  \nfactor(schoolnr)237  1.69607    2.06447   0.822 0.411422    \nfactor(schoolnr)240 -0.21368    2.21446  -0.096 0.923139    \nfactor(schoolnr)241  1.82195    1.83630   0.992 0.321219    \nfactor(schoolnr)242  5.11955    2.27771   2.248 0.024698 *  \nfactor(schoolnr)243  4.71818    2.54942   1.851 0.064352 .  \nfactor(schoolnr)244 -0.81472    2.15710  -0.378 0.705695    \nfactor(schoolnr)246  3.94809    2.21570   1.782 0.074911 .  \nfactor(schoolnr)249  0.18111    1.81893   0.100 0.920695    \nfactor(schoolnr)250 -0.69331    2.06691  -0.335 0.737332    \nfactor(schoolnr)252 -0.36370    2.27756  -0.160 0.873140    \nfactor(schoolnr)256 -8.25432    2.35336  -3.507 0.000462 ***\nfactor(schoolnr)258 -8.24124    2.68111  -3.074 0.002140 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6.186 on 2152 degrees of freedom\nMultiple R-squared:  0.5557, Adjusted R-squared:  0.528 \nF-statistic: 20.08 on 134 and 2152 DF,  p-value: &lt; 2.2e-16\n\n\n[5 puntos] Estime la ecuación de calificación usando MCO y con errores agrupados a nivel escuela (sin efectos fijos de escuela). ¿Qué resuelve este procedimiento?\nAl estimar los errores agrupados y robustos a heterocedasticidad se toma en cuenta la correlación que existe en los errores dentro de cada escuela. Los errores agrupados estimados con la opción cluster asumen correlación de errores dentro del grupo, pero no entre grupos. Con respecto a las partes b. y c., el error estándar asociado al tiempo dedicado a la tarea es aproximadamente 20% mayor. Este es un ejemplo típico en el que los errores agrupados se inflan con respecto a los errores de MCO clásicos y los errores robustos.\nNota: es posible que los errores agrupados sean menores que los errores de MCO. Para ver eso, considere un modelo simple con datos agrupados de la forma siguiente: \\[y_{ig=\\alpha+\\beta x_{ig}+u_{ig}}\\] donde \\(x_{ig}\\) es un regresor escalar.\nSe asume que el tamaño promedio de los grupos es \\(\\bar{N}_g\\). Moulton (1990) muestra que el error estándar de MCO esta sesgado hacia abajo por una cantidad igual a la raíz de \\(\\tau \\approx 1 +\\rho_x \\rho_u (\\bar{N}_g-1)\\), donde \\(\\rho_x\\) es la correlación dentro de los grupos de \\(x\\) y \\(\\rho_u\\) es la correlación dentro de los grupos de los errores. Esto implica que para obtener el error correcto que toma en cuenta la agrupación hay que multiplicar el error de MCO por la raíz de \\(\\tau\\). Sin embargo, note que dependiendo del signo y la magnitud de \\(\\rho_x\\) y \\(\\rho_u\\), la raíz de \\(\\tau\\) puede llegar a ser menor que 1 y, por tanto, el error agrupado puede llegar a ser menor que el de MCO. \\(\\tau\\) se conoce como el factor de Moulton y puede ser extendido para un modelo más complicado. La intuición funciona de manera similar para un modelo más complicado: todo depende de las correlaciones entre grupos de los regresores y la correlación de los errores.\n\ncoef_test(m.mco, vcov = \"CR1S\", cluster = data.examen$schoolnr)\n\n       Coef. Estimate     SE   t-stat d.f. (Satt) p-val (Satt) Sig.\n (Intercept)   10.940 1.2559   8.7109        95.2       &lt;0.001  ***\n     iq_verb    2.486 0.0899  27.6464        94.5       &lt;0.001  ***\n         sex    2.422 0.2846   8.5110       110.0       &lt;0.001  ***\n    minority   -0.037 0.8547  -0.0433        20.0        0.966     \n    repeatgr   -4.409 0.3958 -11.1381        81.8       &lt;0.001  ***\n\n\n[5 puntos] Estime la ecuación de calificación usando MCO, variables indicadoras de escuela y con errores agrupados a nivel escuela. ¿Qué resuelve este procedimiento?\nAl controlar por características no observadas de las escuelas empleando efectos fijos por escuela y además estimando los errores que toman en cuenta la estructura agrupada de los errores obtenemos un coeficiente estimado de 2.26, pero con un error estándar mayor, 0.0915.\n\ncoef_test(m.mco.ef, vcov = \"CR1S\", cluster = data.examen$schoolnr)\n\n               Coef. Estimate     SE  t-stat d.f. (Satt) p-val (Satt) Sig.\n         (Intercept)  12.5022 1.1668  10.715        86.2      &lt; 0.001  ***\n             iq_verb   2.2600 0.0915  24.695        94.0      &lt; 0.001  ***\n                 sex   2.4190 0.2836   8.529       106.5      &lt; 0.001  ***\n            minority   0.2326 0.7172   0.324        32.0      0.74778     \n            repeatgr  -4.4350 0.4083 -10.862        82.3      &lt; 0.001  ***\n   factor(schoolnr)2  -8.2968 0.3795 -21.863        42.8      &lt; 0.001  ***\n  factor(schoolnr)10  -7.2832 0.4270 -17.058        32.6      &lt; 0.001  ***\n  factor(schoolnr)12  -4.5672 0.4565 -10.005        37.0      &lt; 0.001  ***\n  factor(schoolnr)15  -7.4152 0.4211 -17.611        31.8      &lt; 0.001  ***\n  factor(schoolnr)16   2.5341 0.4252   5.960        30.8      &lt; 0.001  ***\n  factor(schoolnr)18  -6.8033 0.4225 -16.101        30.3      &lt; 0.001  ***\n  factor(schoolnr)21  -0.5387 0.4188  -1.286        31.1      0.20787     \n  factor(schoolnr)24   4.2044 0.4187  10.042        31.3      &lt; 0.001  ***\n  factor(schoolnr)26  -0.3608 0.4253  -0.848        31.4      0.40275     \n  factor(schoolnr)27  -5.4685 0.4170 -13.113        30.4      &lt; 0.001  ***\n  factor(schoolnr)29   3.1902 0.4536   7.033        34.2      &lt; 0.001  ***\n  factor(schoolnr)33  -0.3490 0.4205  -0.830        30.8      0.41305     \n  factor(schoolnr)35   1.5958 0.2760   5.783        31.3      &lt; 0.001  ***\n  factor(schoolnr)36  -3.9913 0.4175  -9.560        30.5      &lt; 0.001  ***\n  factor(schoolnr)38   3.0538 0.4171   7.322        31.0      &lt; 0.001  ***\n  factor(schoolnr)40   0.0904 0.4264   0.212        32.0      0.83352     \n  factor(schoolnr)41  -2.9401 0.2796 -10.515        33.9      &lt; 0.001  ***\n  factor(schoolnr)42  -4.9980 0.4168 -11.992        31.1      &lt; 0.001  ***\n  factor(schoolnr)44  -1.4985 0.3315  -4.520        30.9      &lt; 0.001  ***\n  factor(schoolnr)47  -5.7373 0.2712 -21.152        81.0      &lt; 0.001  ***\n  factor(schoolnr)48  -1.8363 0.2637  -6.963        47.5      &lt; 0.001  ***\n  factor(schoolnr)49  -4.1469 0.2037 -20.359        44.2      &lt; 0.001  ***\n  factor(schoolnr)52  -3.6035 0.3986  -9.041        34.0      &lt; 0.001  ***\n  factor(schoolnr)54   2.9114 0.4389   6.634        33.4      &lt; 0.001  ***\n  factor(schoolnr)55   1.4938 0.4230   3.532        32.1      0.00127   **\n  factor(schoolnr)57   0.7968 0.3384   2.354        32.6      0.02472    *\n  factor(schoolnr)60  -1.7926 0.3208  -5.588        30.8      &lt; 0.001  ***\n  factor(schoolnr)61   0.3940 0.3533   1.115        33.0      0.27283     \n  factor(schoolnr)62   2.3906 0.4618   5.177        34.7      &lt; 0.001  ***\n  factor(schoolnr)65   5.6698 0.4298  13.192        31.4      &lt; 0.001  ***\n  factor(schoolnr)66   1.0933 0.4601   2.376        40.1      0.02237    *\n  factor(schoolnr)67  -5.5997 0.4214 -13.289        31.4      &lt; 0.001  ***\n  factor(schoolnr)68  -1.2232 0.4360  -2.806        32.6      0.00841   **\n  factor(schoolnr)76  -1.1461 0.4266  -2.687        31.5      0.01142    *\n  factor(schoolnr)78   0.2020 0.4157   0.486        30.7      0.63054     \n  factor(schoolnr)79   2.1098 0.4214   5.006        32.2      &lt; 0.001  ***\n  factor(schoolnr)80   3.3157 0.3850   8.613        31.6      &lt; 0.001  ***\n  factor(schoolnr)86   1.4532 0.4241   3.427        30.8      0.00175   **\n  factor(schoolnr)87  -0.2074 0.4152  -0.500        31.8      0.62085     \n  factor(schoolnr)88   1.2597 0.4166   3.024        31.5      0.00493   **\n  factor(schoolnr)90   4.4517 0.4252  10.470        33.8      &lt; 0.001  ***\n  factor(schoolnr)94   3.0537 0.3997   7.641        41.1      &lt; 0.001  ***\n  factor(schoolnr)95  -0.7653 0.3455  -2.215        32.8      0.03383    *\n  factor(schoolnr)97   1.4835 0.3802   3.902        30.6      &lt; 0.001  ***\n  factor(schoolnr)98  -1.4096 0.3875  -3.637        33.2      &lt; 0.001  ***\n factor(schoolnr)101   4.2626 0.3876  10.997        31.6      &lt; 0.001  ***\n factor(schoolnr)103  -4.5470 0.4170 -10.903        85.5      &lt; 0.001  ***\n factor(schoolnr)106  -2.6366 0.2861  -9.217        35.1      &lt; 0.001  ***\n factor(schoolnr)107  -4.5033 0.4439 -10.144        33.2      &lt; 0.001  ***\n factor(schoolnr)108  -1.8726 0.4256  -4.399        30.5      &lt; 0.001  ***\n factor(schoolnr)109  -4.4071 0.2769 -15.917        31.5      &lt; 0.001  ***\n factor(schoolnr)110   3.0876 0.4218   7.319        31.6      &lt; 0.001  ***\n factor(schoolnr)111   1.2341 0.3645   3.386        33.6      0.00182   **\n factor(schoolnr)112  -0.2500 0.4327  -0.578        32.0      0.56748     \n factor(schoolnr)115  -0.1319 0.4179  -0.316        30.4      0.75445     \n factor(schoolnr)116  -0.9663 0.4511  -2.142        37.6      0.03872    *\n factor(schoolnr)118  -4.1961 0.3504 -11.975        31.3      &lt; 0.001  ***\n factor(schoolnr)119  -0.3764 0.4254  -0.885        33.3      0.38261     \n factor(schoolnr)121  -3.1618 0.4610  -6.858        35.0      &lt; 0.001  ***\n factor(schoolnr)123   2.7602 0.2742  10.065        79.0      &lt; 0.001  ***\n factor(schoolnr)124   3.6916 0.3958   9.328        32.1      &lt; 0.001  ***\n factor(schoolnr)125   1.7979 0.3552   5.061        33.4      &lt; 0.001  ***\n factor(schoolnr)130   5.6101 0.4385  12.793        37.4      &lt; 0.001  ***\n factor(schoolnr)132   6.2813 0.4103  15.310        33.7      &lt; 0.001  ***\n factor(schoolnr)136   3.8728 0.4443   8.717        35.6      &lt; 0.001  ***\n factor(schoolnr)137   4.4038 0.4166  10.572        31.2      &lt; 0.001  ***\n factor(schoolnr)141   1.1447 0.4237   2.702        33.3      0.01076    *\n factor(schoolnr)142   5.1327 0.4232  12.128        32.3      &lt; 0.001  ***\n factor(schoolnr)147   7.4570 0.4345  17.162        31.5      &lt; 0.001  ***\n factor(schoolnr)148   2.0988 0.4457   4.709        34.9      &lt; 0.001  ***\n factor(schoolnr)149   2.5312 0.4209   6.014        30.9      &lt; 0.001  ***\n factor(schoolnr)150   1.5676 0.4150   3.777        31.5      &lt; 0.001  ***\n factor(schoolnr)151   0.8163 0.4195   1.946        31.6      0.06058    .\n factor(schoolnr)152   6.2098 0.4255  14.593        32.5      &lt; 0.001  ***\n factor(schoolnr)155   4.0699 0.4161   9.782        31.0      &lt; 0.001  ***\n factor(schoolnr)156   1.0325 0.4308   2.397        31.4      0.02266    *\n factor(schoolnr)159   2.8261 0.4024   7.023        31.8      &lt; 0.001  ***\n factor(schoolnr)160   3.5236 0.2557  13.779        38.4      &lt; 0.001  ***\n factor(schoolnr)161   5.4721 0.3829  14.293        32.8      &lt; 0.001  ***\n factor(schoolnr)164   4.6960 0.4234  11.091        30.5      &lt; 0.001  ***\n factor(schoolnr)167   3.8574 0.4182   9.224        30.6      &lt; 0.001  ***\n factor(schoolnr)170   1.9269 0.4180   4.610        31.1      &lt; 0.001  ***\n factor(schoolnr)175   4.1858 0.4077  10.267        35.7      &lt; 0.001  ***\n factor(schoolnr)176   6.5950 0.4201  15.700        31.0      &lt; 0.001  ***\n factor(schoolnr)177   1.4245 0.4199   3.392        30.5      0.00194   **\n factor(schoolnr)179  -7.1657 0.2125 -33.715        41.9      &lt; 0.001  ***\n factor(schoolnr)182   1.7860 0.2113   8.451        34.4      &lt; 0.001  ***\n factor(schoolnr)183   0.8589 0.3729   2.303        30.5      0.02826    *\n factor(schoolnr)184   0.9973 0.3839   2.598        33.5      0.01383    *\n factor(schoolnr)188  -0.5847 0.3032  -1.928        33.1      0.06242    .\n factor(schoolnr)189   3.2232 0.3779   8.530        32.1      &lt; 0.001  ***\n factor(schoolnr)192  -1.8091 0.4496  -4.023        37.0      &lt; 0.001  ***\n factor(schoolnr)193   6.2468 0.4308  14.501        32.7      &lt; 0.001  ***\n factor(schoolnr)195   0.6267 0.4210   1.488        31.7      0.14650     \n factor(schoolnr)196   2.7931 0.4324   6.459        35.0      &lt; 0.001  ***\n factor(schoolnr)197   1.3164 0.4603   2.860        34.6      0.00713   **\n factor(schoolnr)198  -2.5450 0.3200  -7.953        34.3      &lt; 0.001  ***\n factor(schoolnr)199  -4.1093 0.2785 -14.757        32.7      &lt; 0.001  ***\n factor(schoolnr)204   0.9846 0.4150   2.373        31.2      0.02399    *\n factor(schoolnr)206   3.7918 0.4353   8.710        32.0      &lt; 0.001  ***\n factor(schoolnr)209   2.4428 0.4206   5.807        32.5      &lt; 0.001  ***\n factor(schoolnr)210  -0.4076 0.4372  -0.932        32.1      0.35823     \n factor(schoolnr)212   1.3766 0.4185   3.289        31.1      0.00250   **\n factor(schoolnr)214  -3.5027 0.2946 -11.888        32.9      &lt; 0.001  ***\n factor(schoolnr)215   2.4207 0.4178   5.794        30.4      &lt; 0.001  ***\n factor(schoolnr)216   3.2505 0.4410   7.372        32.5      &lt; 0.001  ***\n factor(schoolnr)217   3.1796 0.4449   7.147        32.2      &lt; 0.001  ***\n factor(schoolnr)218   5.1435 0.3697  13.911        62.4      &lt; 0.001  ***\n factor(schoolnr)219   5.0357 0.4230  11.905        30.3      &lt; 0.001  ***\n factor(schoolnr)222   1.2702 0.4156   3.056        31.8      0.00451   **\n factor(schoolnr)224   0.1618 0.4265   0.379        31.1      0.70703     \n factor(schoolnr)226   0.4386 0.4260   1.030        32.3      0.31078     \n factor(schoolnr)227   3.1155 0.4252   7.328        30.6      &lt; 0.001  ***\n factor(schoolnr)228   7.8209 0.4246  18.420        31.2      &lt; 0.001  ***\n factor(schoolnr)231   4.9959 0.4204  11.882        31.2      &lt; 0.001  ***\n factor(schoolnr)233  -3.6288 0.4254  -8.531        33.5      &lt; 0.001  ***\n factor(schoolnr)234   4.4580 0.3188  13.983        32.4      &lt; 0.001  ***\n factor(schoolnr)235   4.1846 0.4228   9.897        31.6      &lt; 0.001  ***\n factor(schoolnr)237   1.6961 0.4150   4.087        31.1      &lt; 0.001  ***\n factor(schoolnr)240  -0.2137 0.4258  -0.502        31.8      0.61922     \n factor(schoolnr)241   1.8219 0.4171   4.368        30.5      &lt; 0.001  ***\n factor(schoolnr)242   5.1196 0.4241  12.072        31.1      &lt; 0.001  ***\n factor(schoolnr)243   4.7182 0.4237  11.135        32.9      &lt; 0.001  ***\n factor(schoolnr)244  -0.8147 0.4161  -1.958        31.0      0.05931    .\n factor(schoolnr)246   3.9481 0.4392   8.989        32.1      &lt; 0.001  ***\n factor(schoolnr)249   0.1811 0.4219   0.429        31.6      0.67064     \n factor(schoolnr)250  -0.6933 0.4225  -1.641        33.8      0.11005     \n factor(schoolnr)252  -0.3637 0.4199  -0.866        30.4      0.39321     \n factor(schoolnr)256  -8.2543 0.4278 -19.295        31.9      &lt; 0.001  ***\n factor(schoolnr)258  -8.2412 0.4220 -19.529        33.5      &lt; 0.001  ***"
  },
  {
    "objectID": "tareas/tarea-4-respuestas.html",
    "href": "tareas/tarea-4-respuestas.html",
    "title": "Respuestas a la tarea 4",
    "section": "",
    "text": "knitr::opts_chunk$set(echo = TRUE,\n                      warning = FALSE,\n                      message = FALSE,\n                      indent = \"   \")\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(sandwich)\nlibrary(clubSandwich)\nlibrary(plm)\nlibrary(stargazer)\nlibrary(lmtest)\nlibrary(AER)\nlibrary(quantreg)\nlibrary(np)\n\n\n\nConsidere los datos en el archivo capital_trabajo.csv. Con una función de producción Cobb-Douglas las participaciones del capital y el trabajo en el valor de la producción se pueden estimar usando una regresión lineal. En algunas aplicaciones es de interés conocer el cociente de las participaciones estimadas.\n\n[10 puntos] Usando 500 repeticiones bootstrap estime el error estándar del cociente capital-trabajo. Para ello realice el siguiente procedimiento:\n\nGenere una matriz vacía de 500 filas para coleccionar sus relaciones estimadas.\nEn cada una de las repeticiones obtenga una muestra con remplazo a partir de la muestra original.\nEstime por MCO los coeficientes sobre el log del capital y el log del trabajo. La variable dependiente es el log del valor de la producción. Calcule el cociente de los coeficientes estimados. Guarde el cociente en la matriz.\nRepita ii. y iii. 500 veces.\nCalcule la desviación estándar de los cocientes estimados.\n\nEn cada repetición bootstrap debemos estimar el siguiente modelo y obtener el ratio de los coeficientes:\n\ndata.kl &lt;- read_csv(\"../files/capital_trabajo.csv\") \n\nsummary(m1 &lt;- lm(lvalor ~ lcapital + ltrabajo, data=data.kl))\n\n\nCall:\nlm(formula = lvalor ~ lcapital + ltrabajo, data = data.kl)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.53523 -0.25678  0.03835  0.26003  0.49631 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 10.56478    0.05303  199.24   &lt;2e-16 ***\nlcapital     0.38502    0.03072   12.53   &lt;2e-16 ***\nltrabajo     0.66108    0.02813   23.50   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2999 on 97 degrees of freedom\nMultiple R-squared:  0.8768, Adjusted R-squared:  0.8742 \nF-statistic: 345.1 on 2 and 97 DF,  p-value: &lt; 2.2e-16\n\n\nFijamos una semilla y los parámetros de la rutina:\n\nset.seed(120)\nB=500\nobs &lt;- nrow(data.kl)\nbeta &lt;- data.frame(beta=matrix(ncol = 1, nrow = B))\n\nRealizamos la regresión y el cálculo del cociente en cada una de las \\(b\\) repeticiones:\n\nfor (i in 1:B)\n{\n  data.b &lt;-data.kl[sample(nrow(data.kl),obs, replace = TRUE),]\n\n  #Corremos regresión\n\n  m&lt;-lm(lvalor ~ lcapital + ltrabajo,\n        data=data.b)\n\n  #Guardamos en cada entrada el ratio estimado\n  beta[i,1] &lt;- as.numeric(m$coefficients[2] / m$coefficients[3])\n}\n\nEl error estimado es simplemente la desviación estándar de los B estadísticos estimados:\n\nsd(beta$beta)\n\n[1] 0.05090312\n\n\nEl error estándar estimado es de 0.0509.\n[10 puntos] Calcule ahora el error estándar jackknife, para lo que realizará \\(N\\) estimaciones de la ecuación del valor de la producción y en cada una de ellas calculará el cociente de interés. En cada una de las \\(i=1,\\ldots,N\\) repeticiones, eliminará de la muestra la observación \\(i\\), por lo que cada regresión será estimada con \\(N-1\\) observaciones. Obtenga la desviación estándar de los \\(N\\) cocientes estimados.\nFijamos los parámetros de la rutina:\n\nbeta.jackknife &lt;- data.frame(beta.jackknife=matrix(ncol = 1, nrow = nrow(data.kl)))\n\nEn cada repetición eliminamos la \\(i\\)-ésima observación, estimamos la regresión y calculamos el cociente de interés:\n\nfor (i in 1:nrow(data.kl))\n{\n  data.j &lt;- data.kl %&gt;%\n    filter(!row_number() == i )\n\n  #Corremos regresión\n\n  m &lt;-lm(lvalor ~ lcapital + ltrabajo,\n         data=data.j)\n\n  #Guardamos en cada entrada el ratio estimado\n  beta.jackknife[i,1] &lt;- as.numeric(m$coefficients[2] / m$coefficients[3])\n}\n\nObtenemos el error estándar. En clase quizás nos faltó ver la fórmula del error estándar, pero es la siguiente:\n\\[ee(\\hat{\\theta}_{jackknife})=\\sqrt{\\frac{N-1}{N}\\sum_{i=1}^{N}(\\hat\\theta_{-i}-\\bar{\\hat\\theta})^2}\\]\ndonde \\(\\hat\\theta_{-i}\\) es el estadístico estimado usando la muestra que omite la \\(i\\)-ésima observación y \\(\\bar{\\hat\\theta}\\) es la media de los \\(N\\) estadísticos estimados.\n\nbeta.jackknife &lt;- beta.jackknife %&gt;% \n  mutate(mean.beta = mean(beta.jackknife),\n         sq.desv = (beta.jackknife - mean.beta)^2)\n\nsqrt(((nrow(data.kl)-1) / nrow(data.kl))*sum(beta.jackknife$sq.desv))\n\n[1] 0.04807774\n\n\nEl error jackknife resulta ser 0.048.\n[10 puntos] Compruebe que sus cálculos aproximan el error estándar obtenido con el Método Delta. Para ello, después de estimar la ecuación del valor de la producción con la muestra original, use la función deltaMethod del paquete car.\nSi usamos el método Delta para calcular el error estándar de la combinación no lineal, obtenemos algo muy parecido, 0.052\n\ndeltaMethod(m1, \"lcapital/ltrabajo\")\n\n                  Estimate       SE    2.5 % 97.5 %\nlcapital/ltrabajo 0.582406 0.051923 0.480639 0.6842\n\n\n\n\n\n\nConsidere los datos en MunichRent.rda. Estos archivos contienen información sobre rentas en la ciudad de Munich, rent. Se desea explicar la renta en función de la antiguedad de los edificios en renta, controlando por el área, area. La variable yearc indica cuándo fue construido el edificio. Construya la antiguedad como antiguedad=2023-yearc. Para leer los datos basta con ejecutar load(“MunichRent.rda”).\n\n[10 puntos] Estime por MCO la relación entre la renta, rent y la antiguedad del edificio, controlando por area y efectos fijos de bath y kitchen. Interprete el coeficiente sobre la antiguedad.\nPrimero por MCO obtenemos una relación positiva entre la renta y el área y una relación negativa entre la renta y la antiguedad, como era de esperarse. Ambos coeficientes estimados son estadísticamente significativos.\n\nload(\"../files/MunichRent.rda\")\n\nMunichRent &lt;- MunichRent %&gt;% \n  mutate(antiguedad=2023-yearc)\n\n#Por MCO\nsummary(r.mco &lt;- lm(rent  ~ area + antiguedad,\n                    data=MunichRent))\n\n\nCall:\nlm(formula = rent ~ area + antiguedad, data = MunichRent)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-734.76  -94.75  -10.87   82.55 1063.17 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 264.3407    10.3561   25.52   &lt;2e-16 ***\narea          5.3618     0.1165   46.01   &lt;2e-16 ***\nantiguedad   -2.4913     0.1239  -20.11   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 149.3 on 3079 degrees of freedom\nMultiple R-squared:  0.4181, Adjusted R-squared:  0.4177 \nF-statistic:  1106 on 2 and 3079 DF,  p-value: &lt; 2.2e-16\n\n\n[10 puntos] Estime la misma relación que en la parte a., pero con una regresión mediana. Interprete el coeficiente sobre la antiguedad.\nAhora realizamos un modelo LAD:\n\nsummary(r.q50 &lt;- rq(rent  ~ area + antiguedad,\n                    data=MunichRent,\n                    tau=0.5))\n\n\nCall: rq(formula = rent ~ area + antiguedad, tau = 0.5, data = MunichRent)\n\ntau: [1] 0.5\n\nCoefficients:\n            Value     Std. Error t value   Pr(&gt;|t|) \n(Intercept) 310.17202  11.60978   26.71643   0.00000\narea          4.97688   0.14688   33.88284   0.00000\nantiguedad   -3.02031   0.14599  -20.68795   0.00000\n\n\nLos coeficientes estimados son de una magnitud similar a los de MCO.\n[10 puntos] Estime ahora una regresión cuantil para cada uno de los deciles de la distribución condicional de la renta y represente en una gráfica los coeficientes por regresión cuantil junto con el coeficiente de MCO para las variables del área y la antiguedad. ¿Concluye que vale la pena modelar la relación de las rentas en función del área y la antiguedad usando regresión cuantil?\nRegresión cuantil para cada decil:\n\nr.q1_9 &lt;- rq(rent  ~ area + antiguedad,\n                    data=MunichRent,\n                    tau= 1:9/10)\n\nplot(summary(r.q1_9), parm=c(\"area\",\"antiguedad\"))\n\n\n\n\nLos efectos de la antiguedad en la distribución de precios son no lineales. Los efectos en los cuantiles superiores crecen más rápido con la antiguedad. Quizás esto sugiera una preferencia por edificios viejos. La regresión cuantil sí fue útil para revelar esta característica.\n[10 puntos] Suponga que no está dispuesto a imponer una relación lineal entre la antiguedad y la renta. Considere entonces el siguiente modelo:\n\\[rent_i=\\beta_0+\\beta_1 area + \\lambda(antiguedad_i)+\\varepsilon_i\\]\nUse el estimador de Robinson (1988) para estimar este modelo parcialmente lineal. Grafique sus resultados e interprételos.\nSeleccionamos el ancho de banda:\n\nbw &lt;- npplregbw(formula=rent ~ area | antiguedad,\n                data=MunichRent,\n                regtype=\"ll\")\n\nImplementamos el estimador de Robinson:\n\nmodel.pl &lt;- npplreg(bw)\nsummary(model.pl)\n\n\nPartially Linear Model\nRegression data: 3082 training points, in 2 variable(s)\nWith 1 linear parametric regressor(s), 1 nonparametric regressor(s)\n\n                  y(z)\nBandwidth(s): 2.368969\n\n                   x(z)\nBandwidth(s): 0.8672961\n\n                    area\nCoefficient(s): 5.143053\n\nKernel Regression Estimator: Local-Linear\nBandwidth Type: Fixed\n\nResidual standard error: 145.801\nR-squared: 0.4445272\n\nContinuous Kernel Type: Second-Order Gaussian\nNo. Continuous Explanatory Vars.: 1\n\n\nPara obtener el gráfico usamos npplot:\n\ng.robinson &lt;- npplot(bw,\n       perspective=F,\n       plot.errors.method=\"bootstrap\",\n       plot.errors.boot.num=5,\n       plot.behavior=\"plot-data\")\n\n\n\ng &lt;- fitted(g.robinson$plr2)\nse &lt;- g.robinson[[\"plr2\"]][[\"merr\"]]\nlci &lt;- g - se[,1]\nuci &lt;- g + se[,2]\n\n#Este objeto nos dicen dónde fueron evaluados\nantiguedad.eval &lt;- g.robinson[[\"plr2\"]][[\"evalz\"]][[\"V1\"]]\n\nfitted &lt;- data.frame(antiguedad.eval, g,lci,uci)\n\nggplot() + \n  geom_point(data=MunichRent, aes(antiguedad,rent), color='black', alpha=0.5) + \n  geom_line(data=fitted, aes(antiguedad.eval, g), linetype='solid')+\n  geom_line(data=fitted, aes(antiguedad.eval, uci), linetype='dashed')+\n  geom_line(data=fitted, aes(antiguedad.eval, lci), linetype='dashed')"
  },
  {
    "objectID": "tareas/tarea-4-respuestas.html#pregunta-1",
    "href": "tareas/tarea-4-respuestas.html#pregunta-1",
    "title": "Respuestas a la tarea 4",
    "section": "",
    "text": "Considere los datos en el archivo capital_trabajo.csv. Con una función de producción Cobb-Douglas las participaciones del capital y el trabajo en el valor de la producción se pueden estimar usando una regresión lineal. En algunas aplicaciones es de interés conocer el cociente de las participaciones estimadas.\n\n[10 puntos] Usando 500 repeticiones bootstrap estime el error estándar del cociente capital-trabajo. Para ello realice el siguiente procedimiento:\n\nGenere una matriz vacía de 500 filas para coleccionar sus relaciones estimadas.\nEn cada una de las repeticiones obtenga una muestra con remplazo a partir de la muestra original.\nEstime por MCO los coeficientes sobre el log del capital y el log del trabajo. La variable dependiente es el log del valor de la producción. Calcule el cociente de los coeficientes estimados. Guarde el cociente en la matriz.\nRepita ii. y iii. 500 veces.\nCalcule la desviación estándar de los cocientes estimados.\n\nEn cada repetición bootstrap debemos estimar el siguiente modelo y obtener el ratio de los coeficientes:\n\ndata.kl &lt;- read_csv(\"../files/capital_trabajo.csv\") \n\nsummary(m1 &lt;- lm(lvalor ~ lcapital + ltrabajo, data=data.kl))\n\n\nCall:\nlm(formula = lvalor ~ lcapital + ltrabajo, data = data.kl)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.53523 -0.25678  0.03835  0.26003  0.49631 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 10.56478    0.05303  199.24   &lt;2e-16 ***\nlcapital     0.38502    0.03072   12.53   &lt;2e-16 ***\nltrabajo     0.66108    0.02813   23.50   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2999 on 97 degrees of freedom\nMultiple R-squared:  0.8768, Adjusted R-squared:  0.8742 \nF-statistic: 345.1 on 2 and 97 DF,  p-value: &lt; 2.2e-16\n\n\nFijamos una semilla y los parámetros de la rutina:\n\nset.seed(120)\nB=500\nobs &lt;- nrow(data.kl)\nbeta &lt;- data.frame(beta=matrix(ncol = 1, nrow = B))\n\nRealizamos la regresión y el cálculo del cociente en cada una de las \\(b\\) repeticiones:\n\nfor (i in 1:B)\n{\n  data.b &lt;-data.kl[sample(nrow(data.kl),obs, replace = TRUE),]\n\n  #Corremos regresión\n\n  m&lt;-lm(lvalor ~ lcapital + ltrabajo,\n        data=data.b)\n\n  #Guardamos en cada entrada el ratio estimado\n  beta[i,1] &lt;- as.numeric(m$coefficients[2] / m$coefficients[3])\n}\n\nEl error estimado es simplemente la desviación estándar de los B estadísticos estimados:\n\nsd(beta$beta)\n\n[1] 0.05090312\n\n\nEl error estándar estimado es de 0.0509.\n[10 puntos] Calcule ahora el error estándar jackknife, para lo que realizará \\(N\\) estimaciones de la ecuación del valor de la producción y en cada una de ellas calculará el cociente de interés. En cada una de las \\(i=1,\\ldots,N\\) repeticiones, eliminará de la muestra la observación \\(i\\), por lo que cada regresión será estimada con \\(N-1\\) observaciones. Obtenga la desviación estándar de los \\(N\\) cocientes estimados.\nFijamos los parámetros de la rutina:\n\nbeta.jackknife &lt;- data.frame(beta.jackknife=matrix(ncol = 1, nrow = nrow(data.kl)))\n\nEn cada repetición eliminamos la \\(i\\)-ésima observación, estimamos la regresión y calculamos el cociente de interés:\n\nfor (i in 1:nrow(data.kl))\n{\n  data.j &lt;- data.kl %&gt;%\n    filter(!row_number() == i )\n\n  #Corremos regresión\n\n  m &lt;-lm(lvalor ~ lcapital + ltrabajo,\n         data=data.j)\n\n  #Guardamos en cada entrada el ratio estimado\n  beta.jackknife[i,1] &lt;- as.numeric(m$coefficients[2] / m$coefficients[3])\n}\n\nObtenemos el error estándar. En clase quizás nos faltó ver la fórmula del error estándar, pero es la siguiente:\n\\[ee(\\hat{\\theta}_{jackknife})=\\sqrt{\\frac{N-1}{N}\\sum_{i=1}^{N}(\\hat\\theta_{-i}-\\bar{\\hat\\theta})^2}\\]\ndonde \\(\\hat\\theta_{-i}\\) es el estadístico estimado usando la muestra que omite la \\(i\\)-ésima observación y \\(\\bar{\\hat\\theta}\\) es la media de los \\(N\\) estadísticos estimados.\n\nbeta.jackknife &lt;- beta.jackknife %&gt;% \n  mutate(mean.beta = mean(beta.jackknife),\n         sq.desv = (beta.jackknife - mean.beta)^2)\n\nsqrt(((nrow(data.kl)-1) / nrow(data.kl))*sum(beta.jackknife$sq.desv))\n\n[1] 0.04807774\n\n\nEl error jackknife resulta ser 0.048.\n[10 puntos] Compruebe que sus cálculos aproximan el error estándar obtenido con el Método Delta. Para ello, después de estimar la ecuación del valor de la producción con la muestra original, use la función deltaMethod del paquete car.\nSi usamos el método Delta para calcular el error estándar de la combinación no lineal, obtenemos algo muy parecido, 0.052\n\ndeltaMethod(m1, \"lcapital/ltrabajo\")\n\n                  Estimate       SE    2.5 % 97.5 %\nlcapital/ltrabajo 0.582406 0.051923 0.480639 0.6842"
  },
  {
    "objectID": "tareas/tarea-4-respuestas.html#pregunta-2",
    "href": "tareas/tarea-4-respuestas.html#pregunta-2",
    "title": "Respuestas a la tarea 4",
    "section": "",
    "text": "Considere los datos en MunichRent.rda. Estos archivos contienen información sobre rentas en la ciudad de Munich, rent. Se desea explicar la renta en función de la antiguedad de los edificios en renta, controlando por el área, area. La variable yearc indica cuándo fue construido el edificio. Construya la antiguedad como antiguedad=2023-yearc. Para leer los datos basta con ejecutar load(“MunichRent.rda”).\n\n[10 puntos] Estime por MCO la relación entre la renta, rent y la antiguedad del edificio, controlando por area y efectos fijos de bath y kitchen. Interprete el coeficiente sobre la antiguedad.\nPrimero por MCO obtenemos una relación positiva entre la renta y el área y una relación negativa entre la renta y la antiguedad, como era de esperarse. Ambos coeficientes estimados son estadísticamente significativos.\n\nload(\"../files/MunichRent.rda\")\n\nMunichRent &lt;- MunichRent %&gt;% \n  mutate(antiguedad=2023-yearc)\n\n#Por MCO\nsummary(r.mco &lt;- lm(rent  ~ area + antiguedad,\n                    data=MunichRent))\n\n\nCall:\nlm(formula = rent ~ area + antiguedad, data = MunichRent)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-734.76  -94.75  -10.87   82.55 1063.17 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 264.3407    10.3561   25.52   &lt;2e-16 ***\narea          5.3618     0.1165   46.01   &lt;2e-16 ***\nantiguedad   -2.4913     0.1239  -20.11   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 149.3 on 3079 degrees of freedom\nMultiple R-squared:  0.4181, Adjusted R-squared:  0.4177 \nF-statistic:  1106 on 2 and 3079 DF,  p-value: &lt; 2.2e-16\n\n\n[10 puntos] Estime la misma relación que en la parte a., pero con una regresión mediana. Interprete el coeficiente sobre la antiguedad.\nAhora realizamos un modelo LAD:\n\nsummary(r.q50 &lt;- rq(rent  ~ area + antiguedad,\n                    data=MunichRent,\n                    tau=0.5))\n\n\nCall: rq(formula = rent ~ area + antiguedad, tau = 0.5, data = MunichRent)\n\ntau: [1] 0.5\n\nCoefficients:\n            Value     Std. Error t value   Pr(&gt;|t|) \n(Intercept) 310.17202  11.60978   26.71643   0.00000\narea          4.97688   0.14688   33.88284   0.00000\nantiguedad   -3.02031   0.14599  -20.68795   0.00000\n\n\nLos coeficientes estimados son de una magnitud similar a los de MCO.\n[10 puntos] Estime ahora una regresión cuantil para cada uno de los deciles de la distribución condicional de la renta y represente en una gráfica los coeficientes por regresión cuantil junto con el coeficiente de MCO para las variables del área y la antiguedad. ¿Concluye que vale la pena modelar la relación de las rentas en función del área y la antiguedad usando regresión cuantil?\nRegresión cuantil para cada decil:\n\nr.q1_9 &lt;- rq(rent  ~ area + antiguedad,\n                    data=MunichRent,\n                    tau= 1:9/10)\n\nplot(summary(r.q1_9), parm=c(\"area\",\"antiguedad\"))\n\n\n\n\nLos efectos de la antiguedad en la distribución de precios son no lineales. Los efectos en los cuantiles superiores crecen más rápido con la antiguedad. Quizás esto sugiera una preferencia por edificios viejos. La regresión cuantil sí fue útil para revelar esta característica.\n[10 puntos] Suponga que no está dispuesto a imponer una relación lineal entre la antiguedad y la renta. Considere entonces el siguiente modelo:\n\\[rent_i=\\beta_0+\\beta_1 area + \\lambda(antiguedad_i)+\\varepsilon_i\\]\nUse el estimador de Robinson (1988) para estimar este modelo parcialmente lineal. Grafique sus resultados e interprételos.\nSeleccionamos el ancho de banda:\n\nbw &lt;- npplregbw(formula=rent ~ area | antiguedad,\n                data=MunichRent,\n                regtype=\"ll\")\n\nImplementamos el estimador de Robinson:\n\nmodel.pl &lt;- npplreg(bw)\nsummary(model.pl)\n\n\nPartially Linear Model\nRegression data: 3082 training points, in 2 variable(s)\nWith 1 linear parametric regressor(s), 1 nonparametric regressor(s)\n\n                  y(z)\nBandwidth(s): 2.368969\n\n                   x(z)\nBandwidth(s): 0.8672961\n\n                    area\nCoefficient(s): 5.143053\n\nKernel Regression Estimator: Local-Linear\nBandwidth Type: Fixed\n\nResidual standard error: 145.801\nR-squared: 0.4445272\n\nContinuous Kernel Type: Second-Order Gaussian\nNo. Continuous Explanatory Vars.: 1\n\n\nPara obtener el gráfico usamos npplot:\n\ng.robinson &lt;- npplot(bw,\n       perspective=F,\n       plot.errors.method=\"bootstrap\",\n       plot.errors.boot.num=5,\n       plot.behavior=\"plot-data\")\n\n\n\ng &lt;- fitted(g.robinson$plr2)\nse &lt;- g.robinson[[\"plr2\"]][[\"merr\"]]\nlci &lt;- g - se[,1]\nuci &lt;- g + se[,2]\n\n#Este objeto nos dicen dónde fueron evaluados\nantiguedad.eval &lt;- g.robinson[[\"plr2\"]][[\"evalz\"]][[\"V1\"]]\n\nfitted &lt;- data.frame(antiguedad.eval, g,lci,uci)\n\nggplot() + \n  geom_point(data=MunichRent, aes(antiguedad,rent), color='black', alpha=0.5) + \n  geom_line(data=fitted, aes(antiguedad.eval, g), linetype='solid')+\n  geom_line(data=fitted, aes(antiguedad.eval, uci), linetype='dashed')+\n  geom_line(data=fitted, aes(antiguedad.eval, lci), linetype='dashed')"
  },
  {
    "objectID": "cronograma.html",
    "href": "cronograma.html",
    "title": "Cronograma",
    "section": "",
    "text": "El siguiente cronograma es informativo sobre la organización del curso:",
    "crumbs": [
      "Cronograma"
    ]
  },
  {
    "objectID": "lecturas.html#extensiones",
    "href": "lecturas.html#extensiones",
    "title": "Lecturas",
    "section": "Extensiones",
    "text": "Extensiones\n\nPanel no lineal\n\nCT, Capítulo 23\n* Panel Poisson: Castillo, J. C., Mejía, D., & Restrepo, P. (2020). Scarcity without leviathan: The violent effects of cocaine supply shortages in the mexican drug war. Review of Economics and Statistics, 102(2), 269-286.\n\nPanel con endogeneidad\n\nCT, Capítulo 22 (secciones 22.1 - 22.5)\n* Panel + VI: Antman, F. M. (2011). The intergenerational effects of paternal migration on schooling and work: What can we learn from children’s time allocations?. Journal of Development Economics, 96(2), 200-208.\n* Wooldridge, J. (2012). Panel data models with heterogeneity and endogeneity. Institute for Fiscal Studies.\n* Semykina, A., & Wooldridge, J. M. (2010). Estimating panel data models in the presence of endogeneity and selection. Journal of Econometrics, 157(2), 375-380.\n\nModelos de riesgo y sobrevivencia\n\nCT, Capítulo 17 (secciones 17.1 – 17.4 y 17.6-17.11)\n* Riesgo: De Uña-Alvarez, J., Otero-Giráldez, M. S., & Alvarez-Llorente, G. (2003). Estimation under length-bias and right-censoring: an application to unemployment duration analysis for married women. Journal of Applied Statistics, 30(3), 283-291.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "tareas/tarea-1.html#preguntas",
    "href": "tareas/tarea-1.html#preguntas",
    "title": "Tarea 1",
    "section": "",
    "text": "Fecha de entrega: viernes 13 de septiembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los lenguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-4-1",
    "href": "tareas/tarea-1.html#pregunta-4-1",
    "title": "Tarea 1",
    "section": "Pregunta 4",
    "text": "Pregunta 4\nSea \\(x_1\\) un vector de variables continuas, \\(x_2\\) una variable continua y \\(d_1\\) una variable dicotómica. Considere el siguiente modelo probit: \\[P(y=1│x_1,x_2 )=\\Phi(x_1'\\alpha+\\beta x_2+\\gamma x_2^2 )\\]\n\n[2 punto] Provea una expresión para el efecto marginal de \\(x_2\\) en la probabilidad. ¿Cómo estimaría este efecto marginal?\n[2 punto] Considere ahora el modelo: \\[P(y=1│x_1  ,x_2 ,d_1)=\\Phi(x_1 '\\delta+\\pi x_2+\\rho d_1+\\nu x_2 d_1 )\\] Provea la nueva expresión para el efecto marginal de \\(x_2\\).\n[2 punto] En el modelo de la parte b., ¿cómo evaluaría el efecto de un cambio en \\(d_1\\) en la probabilidad? Provea una expresión para este efecto."
  },
  {
    "objectID": "econometria-ii/tareas/tarea-1.html",
    "href": "econometria-ii/tareas/tarea-1.html",
    "title": "Tarea 1",
    "section": "",
    "text": "Fecha de entrega: viernes 13 de septiembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los lenguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "econometria-ii/tareas/tarea-1.html#preguntas",
    "href": "econometria-ii/tareas/tarea-1.html#preguntas",
    "title": "Tarea 1",
    "section": "",
    "text": "Fecha de entrega: viernes 13 de septiembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los lenguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "econometria-ii/tareas/tarea-1.html#pregunta-1",
    "href": "econometria-ii/tareas/tarea-1.html#pregunta-1",
    "title": "Tarea 1",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nConsidere el problema de regresión no lineal en el que la variable dependiente escalar \\(y\\) tiene una media condicional \\(E(y_i)=g(x_i,\\beta)\\), siendo \\(g(\\cdot)\\) una función no lineal. Suponga que:\n\nEl proceso generador de datos es \\(y_i=g(x_i,\\beta_0)+u_i\\).\nEn el proceso generador de datos \\(E(u_i|x_i)=0\\) y \\(E(uu'|X)=\\Omega\\), donde \\(\\Omega_{0,ij}=\\sigma_{ij}\\).\nLa función \\(g(\\cdot)\\) satisface \\(g(x, \\beta^{(1)})=g(x, \\beta^{(2)})\\) si y solo si \\(\\beta^{(1)}=\\beta^{(2)}\\).\nLa matriz \\(A_0\\) existe y es finita y no singular y donde \\(A_0=p\\lim\\frac{1}{N}\\sum_{i=1}^{N}\\left.\\frac{\\partial g_i}{\\partial \\beta}\\right|_{\\beta_0}\\left.\\frac{\\partial g_i}{\\partial \\beta'}\\right|_{\\beta_0}=p\\lim\\frac{1}{N}\\left.\\frac{\\partial g'}{\\partial \\beta}\\frac{\\partial g'}{\\partial \\beta'}\\right|_{\\beta_0}\\)\n\\(N^{-1/2}\\sum_{i=1}^N \\left.\\frac{\\partial g_i}{\\partial \\beta}u_i \\right|_{\\beta_0}\\xrightarrow{d}\\mathcal{N}(0,B_0)\\), donde \\(B_0=p\\lim \\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\sigma_{ij}\\left.\\frac{\\partial g_i}{\\partial \\beta}\\frac{\\partial g_i}{\\partial \\beta'}\\right|_{\\beta_0}=p\\lim\\frac{1}{N}\\left.\\frac{\\partial g'}{\\partial \\beta}\\Omega_0 \\frac{\\partial g}{\\partial \\beta'}\\right|_{\\beta_0}\\).\n\n\n[5 puntos] Plantee el problema de optimización para la minimización de la suma de los errores cuadráticos y obtenga las condiciones de primer orden.\n[10 puntos] Pruebe que \\(\\hat{\\beta}_{MCNL}\\), el estimador de mínimos cuadrados no lineales (MCNL) y definido como una raíz de las condiciones de primer orden, es consistente para \\(\\beta_0\\).\n[10 puntos] Derive una expresión para \\(\\sqrt{N}(\\hat{\\beta}_{MCNL}-\\beta_0)\\) y pruebe que \\(\\sqrt{N}(\\hat{\\beta}_{MCNL}-\\beta_0)\\xrightarrow{d}\\mathcal{N}(0,A_0^{-1}B_0A_0^{-1})\\). Tip: utilice una expansión de Taylor exacta de primer orden.\n[5 puntos] ¿Cómo estimaría \\(V(\\hat{\\beta}_{MCNL})\\)?"
  },
  {
    "objectID": "econometria-ii/tareas/tarea-1.html#pregunta-2",
    "href": "econometria-ii/tareas/tarea-1.html#pregunta-2",
    "title": "Tarea 1",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nSuponga que está interesado en una variable aleatoria que tiene una distribución Bernoulli con parámetro \\(p\\). La función de densidad está definida como:\n\\[f(x_;p)=\\left\\{\\begin{array} .1 & \\text{con probabilidad } p \\\\ 0 & \\text{con probabilidad } 1-p \\end{array} \\right.\\] Suponga que tiene una muestra de \\(N\\) observaciones independientes e idénticamente distribuidas.\n\n[4 puntos] Plantee la función de log verosimilitud del problema.\n[4 puntos] Obtenga las condiciones de primer orden y resuelva para \\(\\hat{p}\\).\n[2 puntos] ¿Cuál es la media y la varianza del estimador de máxima verosimilitud que ha encontrado?"
  },
  {
    "objectID": "econometria-ii/tareas/tarea-1.html#pregunta-3",
    "href": "econometria-ii/tareas/tarea-1.html#pregunta-3",
    "title": "Tarea 1",
    "section": "Pregunta 3",
    "text": "Pregunta 3\nConsidere el modelo logit:\n\\[f(y_i|x_i;\\theta_0)=\\left\\{ \\begin{array} .1 & \\frac{\\exp\\{x_i'\\theta_0\\}}{1+\\exp\\{x_i'\\theta_0\\}}  \\\\ 0 &  \\frac{1}{1+\\exp\\{x_i'\\theta_0\\}} \\end{array} \\right.\\] donde \\(x_i\\) es un vector de variables explicativas, \\(\\theta_0\\) y es el vector de parámetros poblacional. Asuma que dispone de observaciones \\((y_i,x_i)\\) que son iid.\n\n[5 puntos] Escriba la función de log verosimilitud condicional para la observación \\(i\\).\n[5 puntos] Encuentre el vector score para la observación \\(i\\).\n[5 puntos] Encuentre la hesiana de la función de log verosimilitud con respecto a \\(\\mathbf{\\theta}\\).\n[5 puntos] Obtenga la matriz de información para la observación \\(i\\)."
  },
  {
    "objectID": "econometria-ii/tareas/tarea-1.html#pregunta-4",
    "href": "econometria-ii/tareas/tarea-1.html#pregunta-4",
    "title": "Tarea 1",
    "section": "Pregunta 4",
    "text": "Pregunta 4\nSuponga una variable aleatoria \\(X_i\\) con distribución desconocida. Sin embargo, sí conocemos que \\(E(X)=\\mu=54\\) y que \\(\\sqrt{V(X)}=\\sigma=6\\). Suponga que se recolecta una muestra de 50 observaciones.\n\n[2 punto] ¿Cuál es la distribución asintótica de la media muestral \\(\\bar{X}\\)?\n[4 punto] ¿Cuál es la probabilidad de que \\(\\bar{X}&gt;58\\)?\n[2 punto] ¿Cuál es la probabilidad de que una observación elegida al azar sea tal que \\(X_i&gt;58\\)?\n[2 punto] Provea un intervalo de confianza de 99% para la media muestral."
  },
  {
    "objectID": "econometria-ii/tareas/tarea-1.html#pregunta-5",
    "href": "econometria-ii/tareas/tarea-1.html#pregunta-5",
    "title": "Tarea 1",
    "section": "Pregunta 5",
    "text": "Pregunta 5\nEn esta pregunta mostraremos los alcances de los teoremas del límite central. Para esto, generaremos muchas muestras de tamaño \\(N\\) con una distribución \\(Bernoulli\\) con probabilidad de éxito \\(p=0.7\\). Recuerde que cuando realice simulaciones, siempre debe fijar una semilla al inicio para poder replicar su trabajo.\n\n[2 puntos] ¿Cuál es la media y la varianza de una variable aleatoria \\(y_i \\sim Bernoulli(0.7)\\)?\n[2 puntos] Si \\(y_i\\) son iid y podemos aplicar un teorema de límite central, ¿cuál es la distribución teórica de \\(\\bar{y}\\) cuando \\(N\\to\\infty\\)?\n[5 puntos] Realice el siguiente procedimiento \\(J=1,000\\) veces. Obtenga una muestra de tamaño \\(N=3\\) a partir de la distribución \\(Bernoulli(0.7)\\) y calcule la media muestral \\(\\bar{y}\\). Coleccione las \\(J\\) medias muestrales y luego grafique un histograma de las medias muestrales obtenidas junto con una curva teórica normal con la media y varianza obtenida en la parte b. Comente sobre lo que observa.\n[3 puntos] Repita lo realizado en la parte b., ahora con \\(N=15\\). Comente sobre lo que observa.\n[3 puntos] Repita lo realizado en la parte b., ahora con \\(N=1,500\\). Comente sobre lo que observa.\n[5 puntos] ¿Cómo usaría este ejercicio con palabras simples para explicar a una persona que no sabe mucho de estadística sobre la importancia de los teoremas de límite central?"
  },
  {
    "objectID": "econometria-ii/tareas/tarea-1.html#pregunta-6",
    "href": "econometria-ii/tareas/tarea-1.html#pregunta-6",
    "title": "Tarea 1",
    "section": "Pregunta 6",
    "text": "Pregunta 6\nSea \\(x_1\\) un vector de variables continuas, \\(x_2\\) una variable continua y \\(d_1\\) una variable dicotómica. Considere el siguiente modelo probit: \\[P(y=1│x_1,x_2 )=\\Phi(x_1'\\alpha+\\beta x_2+\\gamma x_2^2 )\\]\n\n[5 punto] Provea una expresión para el efecto marginal de \\(x_2\\) en la probabilidad. ¿Cómo estimaría este efecto marginal?\n[3 punto] Considere ahora el modelo: \\[P(y=1│x_1  ,x_2 ,d_1)=\\Phi(x_1 '\\delta+\\pi x_2+\\rho d_1+\\nu x_2 d_1 )\\] Provea la nueva expresión para el efecto marginal de \\(x_2\\).\n[2 punto] En el modelo de la parte b., ¿cómo evaluaría el efecto de un cambio en \\(d_1\\) en la probabilidad? Provea una expresión para este efecto."
  },
  {
    "objectID": "econometria-ii/schedule.html",
    "href": "econometria-ii/schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Example schedule:\n\n\n\n\n\n\n\n\n\nMorning\nAfternoon\n\n\n\n\nL\nIntro + Data manipulation\ngit / GitHub\n\n\nM\nGeneralised Linear Models\nData visualisation\n\n\nX\nMixed models / GAM / Bayes\nFunctional programming + Students work\n\n\nJ\nMultivariate analyses\nReproducible workflows\n\n\nV\nUsing R as GIS + Students work\nProject presentations"
  },
  {
    "objectID": "econometria-ii/programa.html",
    "href": "econometria-ii/programa.html",
    "title": "Programa",
    "section": "",
    "text": "Conocer la teoría sobre la que se fundamentan los métodos para la estimación de relaciones empíricas y la inferencia usando datos de sección cruzada y de panel.\nDiseñar estrategias econométricas usando los modelos adecuados de acuerdo con la pregunta de investigación.\nEmplear software para estimar los modelos econométricos apropiados de acuerdo con la naturaleza de los datos disponibles.\nConocer e implementar buenas prácticas en el uso de software, orientadas a la transparencia y la replicabilidad en la investigación.\nConocer los métodos que se emplean en la investigación económica actual."
  },
  {
    "objectID": "econometria-ii/programa.html#objetivos",
    "href": "econometria-ii/programa.html#objetivos",
    "title": "Programa",
    "section": "",
    "text": "Conocer la teoría sobre la que se fundamentan los métodos para la estimación de relaciones empíricas y la inferencia usando datos de sección cruzada y de panel.\nDiseñar estrategias econométricas usando los modelos adecuados de acuerdo con la pregunta de investigación.\nEmplear software para estimar los modelos econométricos apropiados de acuerdo con la naturaleza de los datos disponibles.\nConocer e implementar buenas prácticas en el uso de software, orientadas a la transparencia y la replicabilidad en la investigación.\nConocer los métodos que se emplean en la investigación económica actual."
  },
  {
    "objectID": "econometria-ii/programa.html#referencias",
    "href": "econometria-ii/programa.html#referencias",
    "title": "Programa",
    "section": "Referencias",
    "text": "Referencias\nEl curso se basa en los siguientes textos:\n\n(MHE) Angrist, J.D. y Pischke, J.S. (2013). Mostly Harmless Econometrics: An Empiricists Companion. Princeton University Press.\n* (CT) Cameron, A.C. y Trivedi, P.K. (2005). Microeconometrics: Methods and applications. Oxford University Press.\nHansen, B. (2022). Econometrics. Princeton University Press.\nHayashi, F. (2000). Econometrics. Princeton University Press.\n* (W) Wooldridge, J.M. (2010). Econometric analysis of cross section and panel data. Segunda edición, MIT Press."
  },
  {
    "objectID": "econometria-ii/programa.html#contenido-temático",
    "href": "econometria-ii/programa.html#contenido-temático",
    "title": "Programa",
    "section": "Contenido temático",
    "text": "Contenido temático\nUnidad 1. Introducción\n\nRevisión de fundamentos de estadística y regresión lineal\nTeoría asintótica\nEstimadores extremos\nMáxima verosimilitud\nMínimos cuadrados no lineales\nInferencia estadística\n\nUnidad 2. Modelos de variable dependiente no continua\n\nModelos de variable dependiente binaria\n\nModelos de conteo\n\nUnidad 3. Modelos de selección\n\nModelo de Tobit\nModelo de Heckman\n\nUnidad 4. Endogeneidad\n\nVariables instrumentales\nMétodo generalizado de momentos\nEstimación con instrumentos débiles\n\nUnidad 5. Datos de panel\n\nModelos de efectos fijos y de efectos aleatorios\nEstimadores between y within\nEstimadores de primeras diferencias y de efectos aleatorios\nErrores estándar agrupados\n\nUnidad 6. Extensiones\n\nBootstrap\nRegresión por cuantiles\nMétodos semi paramétricos y no paramétricos\nModelos de panel no lineales\nModelos de panel con endogeneidad\nModelos de riesgo y de sobrevivencia"
  },
  {
    "objectID": "econometria-ii/programa.html#evaluación-del-curso",
    "href": "econometria-ii/programa.html#evaluación-del-curso",
    "title": "Programa",
    "section": "Evaluación del curso",
    "text": "Evaluación del curso\n\nExamen parcial: 30%.\nExamen final acumulativo: 45%\nTareas (4): 20% (5% cada una)\nExposición: 5%"
  },
  {
    "objectID": "econometria-ii/programa.html#tareas",
    "href": "econometria-ii/programa.html#tareas",
    "title": "Programa",
    "section": "Tareas",
    "text": "Tareas\nCuatro tareas teórico-prácticas. Las tareas deben entregarse de manera individual, pero se recomienda ampliamente colaborar en grupos de estudio. Las tareas deberán entregarse en Teams antes de la fecha y hora señalada. No se aceptarán tareas fuera de tiempo. Por favor, no comprima los archivos en carpetas comprimidas. Las tareas deberán contener dos archivos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad de manera aleatoria."
  },
  {
    "objectID": "econometria-ii/programa.html#software",
    "href": "econometria-ii/programa.html#software",
    "title": "Programa",
    "section": "Software",
    "text": "Software\nR será el paquete standard usado en las sesiones prácticas. Más aún, el uso de cualquier software es aceptado siempre que se cumplan con los requisitos de replicabilidad y reportes de las tareas y exámenes. Habrá una sesión especial para introducir el uso de Quarto para la generación de reportes científicos."
  },
  {
    "objectID": "econometria-ii/programa.html#exámenes",
    "href": "econometria-ii/programa.html#exámenes",
    "title": "Programa",
    "section": "Exámenes",
    "text": "Exámenes\n\nExamen parcial: miércoles 9 de octubre en el horario de clase.\nExamen final: por definir."
  },
  {
    "objectID": "econometria-ii/programa.html#exposición",
    "href": "econometria-ii/programa.html#exposición",
    "title": "Programa",
    "section": "Exposición",
    "text": "Exposición\nCada alumno realizará una presentación de uno de los artículos aplicados marcados con negritas en la lista de lecturas. Cada presentación deberá ser de máximo 15 minutos y deberá incluir el contenido que el presentador considere más relevante. La presentación deberá abordar, mínimamente: 1) el problema a investigar, 2) la metodología empleada, 3) la relación entre la metodología y la teoría vista en el curso, 4) los datos empleados, 5) los principales resultados, y 6) una crítica sobre la validez y las conclusiones del estudio."
  },
  {
    "objectID": "econometria-ii/programa.html#lista-de-lecturas",
    "href": "econometria-ii/programa.html#lista-de-lecturas",
    "title": "Programa",
    "section": "Lista de lecturas",
    "text": "Lista de lecturas\nTodas las lecturas de capítulos de libro son obligatorias pues permiten una discusión informada en la clase. Las lecturas marcadas con “*” no serán cubiertas en clase, pero son ampliamente recomendables. En las sesiones de exposiciones cada alumno presentará uno de los artículos enlistados con negritas, por lo que se espera que el resto de la clase tenga el conocimiento suficiente para participar en la discusión.\nLa lista de lecturas está disponible aquí."
  },
  {
    "objectID": "econometria-ii/materials.html",
    "href": "econometria-ii/materials.html",
    "title": "Course Materials",
    "section": "",
    "text": "Datasets\nSlides"
  },
  {
    "objectID": "econometria-ii/index.html",
    "href": "econometria-ii/index.html",
    "title": "Econometría II 2024",
    "section": "",
    "text": "Profesor: Irvin Rojas (irvin.rojas@cide.edu).\nLaboratorista: por definir.\nHorario de clases: miércoles y jueves (8:00 a 9:30).\nHorario de laboratorio: por definir.\nPlataforma del curso: Microsoft Teams.\nHorario de oficina: martes y jueves (17:00)\n\n¡Bienvenidas, bienvenidos!\nEste es un sitio para las y los estudiantes del curso de Econometría II de la Maestría en Economía del CIDE. Sin embargo, otras personas pueden encontrar útiles los recursos de este sitio, como el programa del curso, las tareas y la lista de lecturas."
  },
  {
    "objectID": "econometria-ii/cronograma.html",
    "href": "econometria-ii/cronograma.html",
    "title": "Cronograma",
    "section": "",
    "text": "El siguiente cronograma es informativo sobre la organización del curso:"
  },
  {
    "objectID": "econometria-ii/lecturas.html",
    "href": "econometria-ii/lecturas.html",
    "title": "Lecturas",
    "section": "",
    "text": "Todas las lecturas de capítulos de libro son obligatorias pues permiten una discusión informada en la clase. Las lecturas marcadas con “*” no serán cubiertas en clase, pero son ampliamente recomendables. En las sesiones de exposiciones cada alumno presentará uno de los artículos enlistados con negritas, por lo que se espera que el resto de la clase tenga el conocimiento suficiente para participar en la discusión."
  },
  {
    "objectID": "econometria-ii/lecturas.html#prerrequisitos",
    "href": "econometria-ii/lecturas.html#prerrequisitos",
    "title": "Lecturas",
    "section": "Prerrequisitos",
    "text": "Prerrequisitos\n\nModelos lineales\n\nW, Capítulos 1-4"
  },
  {
    "objectID": "econometria-ii/lecturas.html#semana-1",
    "href": "econometria-ii/lecturas.html#semana-1",
    "title": "Lecturas",
    "section": "Semana 1",
    "text": "Semana 1\n\nIntroducción\n\nAngrist, J. D., & Pischke, J. S. (2017). Undergraduate Econometrics Instruction: Through Our Classes, Darkly. Journal of Economic Perspectives,31(2), 125-44.\n* Nakamura, E., & Steinsson, J. (2018). Identification in macroeconomics. Journal of Economic Perspectives, 32(3), 59-86.\n\nMCO\n\nCT, Capítulo 4 (secciones 4.1 a 4.3)"
  },
  {
    "objectID": "econometria-ii/lecturas.html#semana-2",
    "href": "econometria-ii/lecturas.html#semana-2",
    "title": "Lecturas",
    "section": "Semana 2",
    "text": "Semana 2\n\nTeoría asintótica\n\nCT, Capítulo 4, (sección 4.4)\n\nEstimadores extremos\n\nCT, Capítulo 5"
  },
  {
    "objectID": "econometria-ii/lecturas.html#semana-3",
    "href": "econometria-ii/lecturas.html#semana-3",
    "title": "Lecturas",
    "section": "Semana 3",
    "text": "Semana 3\n\nPrueba de hipótesis\n\nCT, Capítulo 7"
  },
  {
    "objectID": "econometria-ii/lecturas.html#semana-4",
    "href": "econometria-ii/lecturas.html#semana-4",
    "title": "Lecturas",
    "section": "Semana 4",
    "text": "Semana 4\n\nVariable dependiente binaria\n\nCT, Capítulo 14 (secciones 14.1 - 14.4)\nBinaria: Avila-Foucat, V. S., & Pérez-Campuzano, E. (2015). Municipality socioeconomic characteristics and the probability of occurrence of Wildlife Management Units in Mexico. Environmental Science & Policy, 45, 146-153.\n* Ordenados: Conigliani, C., Manca, A., & Tancredi, A. (2015). Prediction of patient-reported outcome measures via multivariate ordered probit models. Journal of the Royal Statistical Society. Series A (Statistics in Society), 567-591.\n\nVariable dependiente categórica\n\nCT, Capítulo 15 (secciones 15.1 - 15.4)\nMultinomial: Kveder, C. L. M., & Flahaux, M. L. (2013). Returning to Dakar: A mixed methods analysis of the role of migration experience for occupational status. World Development, 45, 223-238."
  },
  {
    "objectID": "econometria-ii/lecturas.html#semana-5",
    "href": "econometria-ii/lecturas.html#semana-5",
    "title": "Lecturas",
    "section": "Semana 5",
    "text": "Semana 5\n\nModelos de conteo\n\nCT, Capítulo 20 (secciones 21.1 - 20.4).\n* Poisson: White, K., & Buckley, C. J. (2011). Exposure to international migration and its effect on childbearing in Turkey. International Migration Review, 45(1), 123-147.\n* Negativo binomial: Antón, J. I., & De Bustillo, R. M. (2010). Health care utilisation and immigration in Spain. The European Journal of Health Economics, 11(5), 487-498.\n* Inflado en cero: Young, J. D., Anderson, N. M., Naughton, H. T., & Mullan, K. (2018). Economic and policy factors driving adoption of institutional woody biomass heating systems in the US. Energy Economics, 69, 456-470.\n* Dos partes: Colchero, M. A., Molina, M., & Guerrero-López, C. M. (2017). After Mexico implemented a tax, purchases of sugar-sweetened beverages decreased and water increased: difference by place of residence, household composition, and income level. The Journal of nutrition, 147(8), 1552-1557."
  },
  {
    "objectID": "econometria-ii/lecturas.html#semana-6",
    "href": "econometria-ii/lecturas.html#semana-6",
    "title": "Lecturas",
    "section": "Semana 6",
    "text": "Semana 6\n\nModelos de selección\n\nCT, Capítulo 16 (secciones 16.1 – 16.6)\nTobit: Zou, B., & Luo, B. (2019). Rural Household Energy Consumption Characteristics and Determinants in China. Energy.\n* Heckman: Parey, M., Ruhose, J., Waldinger, F., & Netz, N. (2017). The selection of high-skilled emigrants. Review of Economics and Statistics, 99(5), 776-792.\n* Ordenado + selección: Alemi, F., Circella, G., Mokhtarian, P., & Handy, S. (2019). What drives the use of ridehailing in California? Ordered probit models of the usage frequency of Uber and Lyft. Transportation Research Part C: Emerging Technologies, 102, 233-248."
  },
  {
    "objectID": "econometria-ii/lecturas.html#semana-7",
    "href": "econometria-ii/lecturas.html#semana-7",
    "title": "Lecturas",
    "section": "Semana 7",
    "text": "Semana 7\n\nVariables instrumentales\n\nW, Capítulo 5.\nCT, Capítulo 4 (secciones 4.8 y 4.9)"
  },
  {
    "objectID": "econometria-ii/lecturas.html#semana-8",
    "href": "econometria-ii/lecturas.html#semana-8",
    "title": "Lecturas",
    "section": "Semana 8",
    "text": "Semana 8\n\nMétodo generalizado de momentos\n\nCT, Capítulo 6 (secciones 6.1 - 6.4)"
  },
  {
    "objectID": "econometria-ii/lecturas.html#semana-9",
    "href": "econometria-ii/lecturas.html#semana-9",
    "title": "Lecturas",
    "section": "Semana 9",
    "text": "Semana 9\n\nVariables instrumentales en la práctica\n\nVI: Hackett, L., & Marquez-Padilla, F. (2019). Working for Change: the Effect of Female Labor Force Participation on Fertility. SSRN Working Paper 3354753.\nVI: López-Feldman, A., & Chávez, E. (2017). Remittances and natural resource extraction: Evidence from Mexico. Ecological Economics, 132, 69-79.\n\nOtras aplicaciones de VI\n\n* VI: Campos-Vazquez, R. M., & Nuñez, R. (2019). Obesity and labor market outcomes in Mexico/Obesidad y el mercado de trabajo en México. Estudios Económicos, 34(2), 159-196.\n* MC2E2M: Mocetti, S. (2007). Intergenerational earnings mobility in Italy. The BE Journal of Economic Analysis & Policy, 7(2).\n\n* Poisson + VI: Hirvonen, K., & Hoddinott, J. (2017). Agricultural production and children’s diets: Evidence from rural Ethiopia. Agricultural Economics, 48(4), 469-480."
  },
  {
    "objectID": "econometria-ii/lecturas.html#semana-10",
    "href": "econometria-ii/lecturas.html#semana-10",
    "title": "Lecturas",
    "section": "Semana 10",
    "text": "Semana 10\n\nModelos y estimadores de panel\n\nCT, Capítulo 21\nPanel: Amare, M., Abay, K. A., Tiberti, L., & Chamberlin, J. (2021). COVID-19 and food security: Panel data evidence from Nigeria. Food policy, 101, 102099.\nPanel: Kagin, J., Taylor, J. E., & Yúnez-Naude, A. (2016). Inverse productivity or inverse efficiency? Evidence from Mexico. The Journal of Development Studies, 52(3), 396-411.\n* Panel: Bwalya, S. M. (2006). Foreign direct investment and technology spillovers: Evidence from panel data analysis of manufacturing firms in Zambia. Journal of development economics, 81(2), 514-526.\n* Panel + DID: Estrada, R. (2019). Rules versus discretion in public service: Teacher hiring in Mexico. Journal of Labor Economics, 37(2), 545-579."
  },
  {
    "objectID": "econometria-ii/lecturas.html#semana-11",
    "href": "econometria-ii/lecturas.html#semana-11",
    "title": "Lecturas",
    "section": "Semana 11",
    "text": "Semana 11\n\nTemas de errores estándar\n\nMHE, Capítulo 8"
  },
  {
    "objectID": "econometria-ii/lecturas.html#semana-12",
    "href": "econometria-ii/lecturas.html#semana-12",
    "title": "Lecturas",
    "section": "Semana 12",
    "text": "Semana 12\n\nBootstrap\n\nCT, Capítulo 11\nBootstrap: Li, H., & Maddala, G. S. (1999). Bootstrap variance estimation of nonlinear functions of parameters: an application to long-run elasticities of energy demand. Review of Economics and Statistics, 81(4), 728-733.\n\nRegresión cuantil\n\nCT, Capítulo 4 (sección 4.6)\nCuantil: Engelhardt, G. V., & Kumar, A. (2011). Pensions and household wealth accumulation. Journal of Human Resources, 46(1), 203-236."
  },
  {
    "objectID": "econometria-ii/lecturas.html#semana-13",
    "href": "econometria-ii/lecturas.html#semana-13",
    "title": "Lecturas",
    "section": "Semana 13",
    "text": "Semana 13\n\nMétodos semiparamétricos\n\nCT, Capítulo 9\nSemiparamétrico: Hussinger, K. (2008). R&D and subsidies at the firm level: An application of parametric and semiparametric two‐step selection models. Journal of applied econometrics, 23(6), 729-747."
  },
  {
    "objectID": "econometria-ii/lecturas.html#extensiones",
    "href": "econometria-ii/lecturas.html#extensiones",
    "title": "Lecturas",
    "section": "Extensiones",
    "text": "Extensiones\n\nPanel no lineal\n\nCT, Capítulo 23\n* Panel Poisson: Castillo, J. C., Mejía, D., & Restrepo, P. (2020). Scarcity without leviathan: The violent effects of cocaine supply shortages in the mexican drug war. Review of Economics and Statistics, 102(2), 269-286.\n\nPanel con endogeneidad\n\nCT, Capítulo 22 (secciones 22.1 - 22.5)\n* Panel + VI: Antman, F. M. (2011). The intergenerational effects of paternal migration on schooling and work: What can we learn from children’s time allocations?. Journal of Development Economics, 96(2), 200-208.\n* Wooldridge, J. (2012). Panel data models with heterogeneity and endogeneity. Institute for Fiscal Studies.\n* Semykina, A., & Wooldridge, J. M. (2010). Estimating panel data models in the presence of endogeneity and selection. Journal of Econometrics, 157(2), 375-380.\n\nModelos de riesgo y sobrevivencia\n\nCT, Capítulo 17 (secciones 17.1 – 17.4 y 17.6-17.11)\n* Riesgo: De Uña-Alvarez, J., Otero-Giráldez, M. S., & Alvarez-Llorente, G. (2003). Estimation under length-bias and right-censoring: an application to unemployment duration analysis for married women. Journal of Applied Statistics, 30(3), 283-291."
  },
  {
    "objectID": "econometria-ii/presentaciones.html",
    "href": "econometria-ii/presentaciones.html",
    "title": "Presentaciones",
    "section": "",
    "text": "Por favor, seleccione una de las lecturas marcadas con una “+” de la lista de lecturas y envíe un correo al profesor para que se le asigne una fecha de presentación.\n\n\n\n\n\n\n\n\n\nAutores\nTema\nPresentador o presentadora\nFecha de exposición\n\n\n\n\nAvila-Foucat & Pérez-Campuzano (2015)\nBinaria\n\nMiércoles 2 de octubre\n\n\nKveder & Flahaux (2013)\nMultinomial\n\nMiércoles 2 de octubre\n\n\nZou & Luo (2019)\nTobit\n\nMiércoles 2 de octubre\n\n\nHackett & Marquez-Padilla (2019)\nVI\nMoisés Barranco\nJueves 17 de octubre\n\n\nLópez-Feldman & Chávez (2017)\nVI\n\nJueves 17 de octubre\n\n\nAmare t al. (2021)\nPanel\n\nJueves 31 de octubre\n\n\nKagin et al. (2016)\nPanel\nMarcial Castillo\nJueves 31 de octubre\n\n\nLi & Maddala (1999)\nBootstrap\n\nJueves 21 de noviembre\n\n\nEngelhardt & Kumar (2011)\nCuantil\n\nJueves 21 de noviembre"
  },
  {
    "objectID": "econometria-ii/reglas.html",
    "href": "econometria-ii/reglas.html",
    "title": "Reglas",
    "section": "",
    "text": "No se tolerarán actos de discriminación. Se procura un ambiente de respeto entre todos los miembros de la clase.\nToda la comunicación relativa al curso se dará por medio del correo institucional del CIDE.\nLas tareas y exámenes se entregarán a través de Teams.\nLos participantes en la sesión deberán procurar que haya un ambiente silencioso para el desarrollo de la clase.\nSe aplicarán estrictamente los lineamientos generales contenidos en el código de ética del CIDE en términos de plagio y fraude en tareas y exámenes."
  },
  {
    "objectID": "econometria-ii/tareas/index.html",
    "href": "econometria-ii/tareas/index.html",
    "title": "Tareas",
    "section": "",
    "text": "Tarea 1\n\nFecha de entrega: viernes 13 de septiembre a las 20:00 en Teams\nPreguntas\n\n\n\n\nTarea 2\n\nFecha de entrega: viernes 4 de octubre a las 20:00 en Teams\n\n\n\n\nTarea 3\n\nFecha de entrega: viernes 8 de noviembre a las 20:00 en Teams\n\n\n\n\nTarea 4\n\nFecha de entrega: viernes 29 de noviembre a las 20:00 en Teams"
  }
]