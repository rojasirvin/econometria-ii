[
  {
    "objectID": "presentaciones.html",
    "href": "presentaciones.html",
    "title": "Presentaciones",
    "section": "",
    "text": "Por favor, seleccione una de las lecturas marcadas con una “+” de la lista de lecturas y envíe un correo al profesor para que se le asigne una fecha de presentación.\n\n\n\n\n\n\n\n\n\nAutores\nTema\nPresentador o presentadora\nFecha de exposición\n\n\n\n\nAvila-Foucat & Pérez-Campuzano (2015)\nBinaria\nLuis Ángel Ruiz\nMiércoles 2 de octubre\n\n\nKveder & Flahaux (2013)\nMultinomial\nAlejandro Altair\nMiércoles 2 de octubre\n\n\nZou & Luo (2019)\nTobit\nDavid Eugenio\nMiércoles 2 de octubre\n\n\nHackett & Marquez-Padilla (2019)\nVI\nMoisés Barranco\nJueves 17 de octubre\n\n\nLópez-Feldman & Chávez (2017)\nVI\nDante Rito\nJueves 17 de octubre\n\n\nAmare t al. (2021)\nPanel\nEmiliano Alejo\nJueves 31 de octubre\n\n\nKagin et al. (2016)\nPanel\nMarcial Castillo\nJueves 31 de octubre\n\n\nLi & Maddala (1999)\nBootstrap\nVictor Rosas\nJueves 21 de noviembre\n\n\nEngelhardt & Kumar (2011)\nCuantil\nMoisés Pelayo\nJueves 21 de noviembre",
    "crumbs": [
      "Presentaciones"
    ]
  },
  {
    "objectID": "tareas/tarea-2.html",
    "href": "tareas/tarea-2.html",
    "title": "Tarea 2",
    "section": "",
    "text": "Fecha de entrega: viernes 4 de octubre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los lenguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-2.html#preguntas",
    "href": "tareas/tarea-2.html#preguntas",
    "title": "Tarea 2",
    "section": "",
    "text": "Fecha de entrega: viernes 4 de octubre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los lenguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-2.html#datos",
    "href": "tareas/tarea-2.html#datos",
    "title": "Tarea 2",
    "section": "Datos",
    "text": "Datos\nmotral2012.csv\nphd_articulos.csv"
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-1",
    "href": "tareas/tarea-2.html#pregunta-1",
    "title": "Tarea 2",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nUse los datos en el archivo motral2012.csv, que incluye una muestra de individuos con sus características socioeconómicas. Nos interesa conocer los factores que afectan la probabilidad de que los individuos tengan ahorros formales. Considere lo siguiente sobre las opciones de ahorro de los entrevistados, contenida en la variable p14:\n\np14 igual a 1 significa cuentas de ahorro bancarias\np14 igual a 2 significa cuenta de inversión bancaria\np14 igual a 3 significa inversiones en bienes raíces\np14 igual a 4 significa caja de ahorro en su trabajo\np14 igual a 5 significa caja de ahorro con sus amigos\np14 igual a 6 significa tandas\np14 igual a 7 significa que ahorra en su casa o alcancías\np14 igual a 8 significa otro lugar\np14 NA significa que no ahorra\n\n\n[2 puntos] Comience generando una variable binaria ahorra_inf que tome el valor de 1 para las personas que ahorran en instrumentos informales y 0 en otro caso. Se consideran instrumentos informales las cajas de ahorro en el trabajo o amigos, las tandas y el ahorro en casa o alcancías . Construya también la variable mujer que tome el valor de 1 cuando sex toma el valor de 2 y 0 en otro caso. Luego, estime un modelo de probabilidad lineal que relacione ahorra_inf como variable dependiente con eda (edad), anios_esc (años de escolaridad) y mujer. Reporte los errores que asumen homocedasticidad y los errores robustos a heteroscedasticidad. ¿Qué observa respecto a los errores y por qué sucede?\n[3 puntos] ¿Cuál es el efecto en la probabilidad de ahorrar informalmente si los años de educación se incrementan en una unidad, pasando de 4 a 5 años de educación?\n[2 puntos] Realice una prueba de significancia conjunta de eda y anios_esc. ¿Qué concluye?\n[3 puntos] Estime un modelo logit relacionando las mismas variables. Use la función avg_slopes del paquete marginaleffects para obtener los efectos marginales promedio de un cambio en cada uno de los regresores. ¿Por qué difiere la magnitud de este efecto marginal con respecto a la parte b.?\n[2 puntos] Ahora estime el efecto marginal en la media para eda y anios_esc y para los hombres, usando la función slopes. ¿Por qué difiere la magnitud de este efecto marginal respecto a la parte b. y la d.?\n[3 puntos] Provea una expresión para la maginitud de:\n\n\\[\\frac{\\frac{\\partial P(y=1)}{\\partial \\; anios\\_esc}}{\\frac{\\partial P(y=1)}{\\partial \\; eda}}\\]"
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-2",
    "href": "tareas/tarea-2.html#pregunta-2",
    "title": "Tarea 2",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nAhora estimará un modelo multinomial empleando los mismos datos en motral2012.csv. El propósito será ahora estudiar los factores relevantes para predecir la forma de ahorro que tienen las personas que ahorran.\n\n[2 punto] Genere una variable categórica llamada ahorro que sea igual a 1 cuando p14 sea igual a 1 o 2, igual a 2 cuando p14 sea igual a 7, e igual a 3 cuando p14 sea igual a 3, 4, 5, 6 u 8. Haga que esa variable sea missing cuando p14 sea missing. Posteriormente, convierta esta nueva variable en una de factores de forma que el valor 1 tenga la etiqueta “Banco”, el valor 2 tenga la etiqueta “Casa” y el valor 3 tenga la etiqueta “Otro”.\n[4 puntos] Estime un modelo logit multinomial (regresores invariantes a la alternativa) con la opción de ahorro como variable dependiente y los mismos regresores de la pregunta 1. Hay varios paquetes para hacer esto, pero recomiendo usar la función multinom del paquete nnet. ¿Qué puede decir sobre el coeficiente de años de educación en la alternativa “Casa”?\n[4 puntos] Calcule los efectos marginales promedio sobre la probabilidad de ahorrar en el banco. Al considerar el cambio en la probabilidad para el caso de las mujeres (cuando la variable mujer pasa de 0 a 1), ¿de qué tamaño es el efecto predicho en la probabilidad de ahorrar en el banco?\n[3 puntos] Calcule los cocientes de riesgo relativo (relative risk ratios o RRR). ¿Qué significa el hecho de que el RRR asociado a ser mujer sea mayor que 1 en la alternativa “Casa”?\n[2 puntos] Estime nuevamente el modelo, pero ahora, especifique que la alternativa “Casa” sea la alternativa base. ¿Cómo es el RRR de la edad en la alternativa “Banco”? ¿Es esto congruente con lo que obtuvo en la parte d. de esta pregunta?"
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-3-modelo-poisson-inflado-en-cero",
    "href": "tareas/tarea-2.html#pregunta-3-modelo-poisson-inflado-en-cero",
    "title": "Tarea 2",
    "section": "Pregunta 3: modelo Poisson inflado en cero",
    "text": "Pregunta 3: modelo Poisson inflado en cero\nOtra manera de resolver el problema del exceso de ceros que a veces nos molesta en los modelos Poisson es usar un modelo Poisson inflado en cero (CT, p. 681). La idea es introducir un proceso binario con densidad \\(f_1(\\cdot)\\) para modelar la probabilidad de que \\(y=0\\) y luego una densidad de conteo \\(f_2(\\cdot)\\). Si el proceso binario toma el valor de 0, con probabilidad \\(f_1(0)\\), entonces \\(y=0\\), pero si el proceso binario toma el valor de 1, entonces \\(y={0,1,2,\\ldots}\\). Note que podemos entonces observar ceros por dos razones, por el proceso binomial o por el conteo.\nUn modelo inflado en cero tendrá como densidad:\n\\[\ng(y)=\n\\begin{cases}\nf_1(0)+(1-f_1(0))f_2(0) & \\text{si }y=0 \\\\\n(1-f_1(0))f_2(y)& \\text{si }y\\geq 1\n\\end{cases}\n\\] Considere la variable aleatoria \\(Y\\) con observaciones iid que sigue una distribución Poisson con parámetro \\(\\lambda\\). Y considere una variable un proceso binomial tal que \\(\\pi\\) es la probabilidad de que el conteo no se realice. Entonces:\n\\[\ng(y)=\n\\begin{cases}\n\\pi+(1-\\pi)f_2(0) & \\text{si }y=0 \\\\\n(1-\\pi)f_2(y)& \\text{si }y\\geq 1\n\\end{cases}\n\\]\n\n[4 puntos] Termine de especializar la expresión anterior unsando la distribución Poisson para \\(f_2(\\cdot)\\) para obtener la función de masa de probabilidad del modelo Poisson inflado en cero \\(g(y|\\lambda, \\pi)\\).\n[5 puntos] Provea una expresión para la función de verosimilitud \\(L(\\lambda,\\pi)=\\prod_{i=1}^N g(y_i|\\lambda, \\pi)\\). Una sugerencia para simplificar sus cálculos es definir una variable \\(X\\) igual al numero de veces que \\(Y_i\\) que toma el valor de cero.\n[3 puntos] Provea una expresión para la log verosimilitud del problema, \\(\\mathcal{L}(\\lambda,\\pi)\\).\n[3 puntos] Obtenga las condiciones de primer orden que caracterizan la solución del problema de máxima verosimilitud, derivando la log verosimilitud con respecto a \\(\\lambda\\) y a \\(\\pi\\)."
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-4",
    "href": "tareas/tarea-2.html#pregunta-4",
    "title": "Tarea 2",
    "section": "Pregunta 4",
    "text": "Pregunta 4\nUse los datos phd_articulos.csv, los cuales contienen información sobre el número de artículos publicados para una muestra de entonces estudiantes de doctorado. Nuestra variable de interés será el número de artículos art.\n\n[4 puntos] Estime un modelo Poisson que incluya variables dicotómicas para estudiantes mujeres (female) y para estudiantes casadas o casados (married), el número de hijos mejores de cinco años (kid5), el ranking de prestigio del doctorado (phd) y el número de artículos publicados por su mentor (**mentor*). Realice la estimación de la matriz de varianzas primero a partir de la varianza teórica que resulta de la igualdad de la matriz de información y luego usando una matriz de sándwich. Interprete los coeficientes estimados.\n[3 puntos] Obtenga la razón de tasas de incidencia (IRR) para los coeficientes e interprete los resultados.\n[2 puntos] Considere ahora que las mujeres han tenido carreras profesionales más cortas que los hombres, es decir, han estado menos expuestas a la ocurrencia de los eventos publicar. Incorpore esto al análisis y reinterprete los resultados. Pista: explore la opción offeset en glm de R. La columna profage mide la duración efectiva de las carreras profesionales de cada individuo.\n[2 puntos] Implemente la prueba de dispersión de Cameron y Trivedi (1990) usando una regresión auxiliar y los coeficientes estimados en la parte a. ¿Qué concluye?\n[4 puntos] Emplee ahora un modelo negativo binomial con sobredispersión cuadrática en la media para estimar la relación entre el número de artículos publicados y las variables explicativas antes enumeradas. Interprete el coeficiente asociado al número de hijos y a la variable dicotómica para estudiantes mujeres. ¿Qué puede decir sobre la significancia del \\(\\alpha\\) estimado?"
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-5",
    "href": "tareas/tarea-2.html#pregunta-5",
    "title": "Tarea 2",
    "section": "Pregunta 5",
    "text": "Pregunta 5\nRetome los datos del archivo motral2012.csv. Estimará un modelo Tobit para explicar los factores que afectan la oferta laboral femenina. En este archivo de datos la variable hrsocup registra las horas trabajadas a la semana.\n\n[2 punto] ¿Qué proporción de la muestra femenina reporta horas trabajadas iguales a cero?\n[3 puntos] Se desea estimar el efecto de los años de educación (anios_esc) sobre la oferta laboral femenina controlando por el estado marital (casada), la edad (eda) y el número de hijos (n_hij) como una variable continua. En la base, e_con toma el valor de 5 para las personas casadas. Genere la variable dummy casada que tome el valor de 1 para las mujeres casadas y cero en otro caso. Estime un modelo de MCO para hrsocup mayor que cero, usando solo la población femenina. Reporte errores robustos. ¿Cuál es la interpretación sobre el coeficiente de los años de escolaridad?\n[3 puntos] ¿Qué problema existe con el modelo planteado en el punto anterior en términos de la selección? ¿Explique si se trata de un caso de censura o de truncamiento?\n[8 puntos] Estime un modelo Tobit de datos censurados. ¿Qué resuelve el modelo Tobit en este caso? Interprete nuevamente el coeficiente sobre los años de escolaridad.\n[4 puntos] ¿Cuál es el efecto marginal de un incremento de un año de educación en la oferta laboral? ¿Cómo cambia su respuesta si, en lugar de considerar la variable latente, considera la variable censurada?"
  },
  {
    "objectID": "tareas/tarea-2.html#pregunta-6",
    "href": "tareas/tarea-2.html#pregunta-6",
    "title": "Tarea 2",
    "section": "Pregunta 6",
    "text": "Pregunta 6\nUsando los mismos datos del archivo motral2012.csv implementará un ejercicio en el mismo espíritu del famoso estudio de Mroz (1987)1 sobre la oferta laboral femenina. El propósito es estimar la relación entre el salario y el número de horas trabajadas, concentrándonos en la muestra de mujeres.\n\n[5 puntos] El primer problema al que nos enfrentamos es que el salario no se observa para las mujeres que no trabajan. Estime un modelo lineal para el log del salario por hora, ing_x_hrs, usando las variables anios_esc, eda, n_hij, el cuadrado de n_hij, busqueda y casada, usando la submuestra de mujeres con salario por hora positivo. Dichas variables representan los años de escolaridad, la edad, el número de hijos, el cuadrado del número de hijos, si la persona buscó trabajo recientemente y si la persona es casada, respectivamente. Use los coeficientes estimados para imputar el ingreso por hora, faltante para las mujeres que reportan 0 en las horas trabajadas.\n[5 puntos] Use heckit de la librería sampleSelection para estimar por máxima verosimilitud un heckit para las horas trabajadas hrsocup. En la ecuación de selección (si la persona trabaja o no) incluya como variable explicativa el salario por hora (imputado para las mujeres que no trabajan), además de anios_esc, eda, n_hij, el cuadrado de n_hij, casada y busqueda (esta última es un indicador de si se buscó trabajo en la última semana). En la ecuación de horas, incluya los mismos regresores, excepto n_hij, su cuadrado y busqueda.\n[10 puntos] Estime ahora el heckit en dos pasos, a mano. Es decir, siga los siguientes pasos: i) estime un probit para la ecuación de selección y obtenga el índice \\(x_i'\\hat{\\beta}\\); ii) calcule el inverso de la razón de Mills \\(\\lambda_i(x_i'\\hat{\\beta})\\); y iii) estime por MCO la ecuación para las horas trabajadas con la submuestra que tiene horas trabajadas positivas, incluyendo como regresor el inverso de la razón de Mills estimado y el resto de los regresores. Compare los coeficientes y los errores estándar obtenidos en esta parte con los de la parte b. ¿Por qué son iguales o por qué difieren?"
  },
  {
    "objectID": "tareas/tarea-2.html#footnotes",
    "href": "tareas/tarea-2.html#footnotes",
    "title": "Tarea 2",
    "section": "Notas",
    "text": "Notas\n\n\nMroz, T. A. (1987). The sensitivity of an empirical model of married women’s hours of work to economic and statistical assumptions. Econometrica: Journal of the econometric society, 765-799.↩︎"
  },
  {
    "objectID": "tareas/tarea-1.html",
    "href": "tareas/tarea-1.html",
    "title": "Tarea 1",
    "section": "",
    "text": "Fecha de entrega: viernes 13 de septiembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los lenguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-1.html#preguntas",
    "href": "tareas/tarea-1.html#preguntas",
    "title": "Tarea 1",
    "section": "",
    "text": "Fecha de entrega: viernes 13 de septiembre a las 20:00 en Teams\nLa tarea deberá entregarse en Teams. Deberá incluir dos documentos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los lenguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad."
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-1",
    "href": "tareas/tarea-1.html#pregunta-1",
    "title": "Tarea 1",
    "section": "Pregunta 1",
    "text": "Pregunta 1\nConsidere el problema de regresión no lineal en el que la variable dependiente escalar \\(y\\) tiene una media condicional \\(E(y_i)=g(x_i,\\beta)\\), siendo \\(g(\\cdot)\\) una función no lineal. Suponga que:\n\nEl proceso generador de datos es \\(y_i=g(x_i,\\beta_0)+u_i\\).\nEn el proceso generador de datos \\(E(u_i|x_i)=0\\) y \\(E(uu'|X)=\\Omega\\), donde \\(\\Omega_{0,ij}=\\sigma_{ij}\\).\nLa función \\(g(\\cdot)\\) satisface \\(g(x, \\beta^{(1)})=g(x, \\beta^{(2)})\\) si y solo si \\(\\beta^{(1)}=\\beta^{(2)}\\).\nLa matriz \\(A_0\\) existe y es finita y no singular y donde \\(A_0=p\\lim\\frac{1}{N}\\sum_{i=1}^{N}\\left.\\frac{\\partial g_i}{\\partial \\beta}\\right|_{\\beta_0}\\left.\\frac{\\partial g_i}{\\partial \\beta'}\\right|_{\\beta_0}=p\\lim\\frac{1}{N}\\left.\\frac{\\partial g'}{\\partial \\beta}\\frac{\\partial g'}{\\partial \\beta'}\\right|_{\\beta_0}\\)\n\\(N^{-1/2}\\sum_{i=1}^N \\left.\\frac{\\partial g_i}{\\partial \\beta}u_i \\right|_{\\beta_0}\\xrightarrow{d}\\mathcal{N}(0,B_0)\\), donde \\(B_0=p\\lim \\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\sigma_{ij}\\left.\\frac{\\partial g_i}{\\partial \\beta}\\frac{\\partial g_i}{\\partial \\beta'}\\right|_{\\beta_0}=p\\lim\\frac{1}{N}\\left.\\frac{\\partial g'}{\\partial \\beta}\\Omega_0 \\frac{\\partial g}{\\partial \\beta'}\\right|_{\\beta_0}\\).\n\n\n[5 puntos] Plantee el problema de optimización para la minimización de la suma de los errores cuadráticos y obtenga las condiciones de primer orden.\n[10 puntos] Pruebe que \\(\\hat{\\beta}_{MCNL}\\), el estimador de mínimos cuadrados no lineales (MCNL) y definido como una raíz de las condiciones de primer orden, es consistente para \\(\\beta_0\\).\n[10 puntos] Derive una expresión para \\(\\sqrt{N}(\\hat{\\beta}_{MCNL}-\\beta_0)\\) y pruebe que \\(\\sqrt{N}(\\hat{\\beta}_{MCNL}-\\beta_0)\\xrightarrow{d}\\mathcal{N}(0,A_0^{-1}B_0A_0^{-1})\\). Tip: utilice una expansión de Taylor exacta de primer orden.\n[5 puntos] ¿Cómo estimaría \\(V(\\hat{\\beta}_{MCNL})\\)?"
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-2",
    "href": "tareas/tarea-1.html#pregunta-2",
    "title": "Tarea 1",
    "section": "Pregunta 2",
    "text": "Pregunta 2\nSuponga que está interesado en una variable aleatoria que tiene una distribución Bernoulli con parámetro \\(p\\). La función de densidad está definida como:\n\\[f(x_;p)=\\left\\{\\begin{array} .1 & \\text{con probabilidad } p \\\\ 0 & \\text{con probabilidad } 1-p \\end{array} \\right.\\] Suponga que tiene una muestra de \\(N\\) observaciones independientes e idénticamente distribuidas.\n\n[4 puntos] Plantee la función de log verosimilitud del problema.\n[4 puntos] Obtenga las condiciones de primer orden y resuelva para \\(\\hat{p}\\).\n[2 puntos] ¿Cuál es la media y la varianza del estimador de máxima verosimilitud que ha encontrado?"
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-3",
    "href": "tareas/tarea-1.html#pregunta-3",
    "title": "Tarea 1",
    "section": "Pregunta 3",
    "text": "Pregunta 3\nConsidere el modelo logit:\n\\[f(y_i|x_i;\\theta_0)=\\left\\{ \\begin{array} .1 & \\frac{\\exp\\{x_i'\\theta_0\\}}{1+\\exp\\{x_i'\\theta_0\\}}  \\\\ 0 &  \\frac{1}{1+\\exp\\{x_i'\\theta_0\\}} \\end{array} \\right.\\] donde \\(x_i\\) es un vector de variables explicativas, \\(\\theta_0\\) y es el vector de parámetros poblacional. Asuma que dispone de observaciones \\((y_i,x_i)\\) que son iid.\n\n[5 puntos] Escriba la función de log verosimilitud condicional para la observación \\(i\\).\n[5 puntos] Encuentre el vector score para la observación \\(i\\).\n[5 puntos] Encuentre la hesiana de la función de log verosimilitud con respecto a \\(\\mathbf{\\theta}\\).\n[5 puntos] Obtenga la matriz de información para la observación \\(i\\)."
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-4",
    "href": "tareas/tarea-1.html#pregunta-4",
    "title": "Tarea 1",
    "section": "Pregunta 4",
    "text": "Pregunta 4\nSuponga una variable aleatoria \\(X_i\\) con distribución desconocida. Sin embargo, sí conocemos que \\(E(X)=\\mu=54\\) y que \\(\\sqrt{V(X)}=\\sigma=6\\). Suponga que se recolecta una muestra de 50 observaciones.\n\n[2 punto] ¿Cuál es la distribución asintótica de la media muestral \\(\\bar{X}\\)?\n[4 punto] ¿Cuál es la probabilidad de que \\(\\bar{X}&gt;58\\)?\n[2 punto] ¿Cuál es la probabilidad de que una observación elegida al azar sea tal que \\(X_i&gt;58\\)?\n[2 punto] Provea un intervalo de confianza de 99% para la media muestral."
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-5",
    "href": "tareas/tarea-1.html#pregunta-5",
    "title": "Tarea 1",
    "section": "Pregunta 5",
    "text": "Pregunta 5\nEn esta pregunta mostraremos los alcances de los teoremas del límite central. Para esto, generaremos muchas muestras de tamaño \\(N\\) con una distribución \\(Bernoulli\\) con probabilidad de éxito \\(p=0.7\\). Recuerde que cuando realice simulaciones, siempre debe fijar una semilla al inicio para poder replicar su trabajo.\n\n[2 puntos] ¿Cuál es la media y la varianza de una variable aleatoria \\(y_i \\sim Bernoulli(0.7)\\)?\n[2 puntos] Si \\(y_i\\) son iid y podemos aplicar un teorema de límite central, ¿cuál es la distribución teórica de \\(\\bar{y}\\) cuando \\(N\\to\\infty\\)?\n[5 puntos] Realice el siguiente procedimiento \\(J=1,000\\) veces. Obtenga una muestra de tamaño \\(N=3\\) a partir de la distribución \\(Bernoulli(0.7)\\) y calcule la media muestral \\(\\bar{y}\\). Coleccione las \\(J\\) medias muestrales y luego grafique un histograma de las medias muestrales obtenidas junto con una curva teórica normal con la media y varianza obtenida en la parte b. Comente sobre lo que observa.\n[3 puntos] Repita lo realizado en la parte b., ahora con \\(N=15\\). Comente sobre lo que observa.\n[3 puntos] Repita lo realizado en la parte b., ahora con \\(N=1,500\\). Comente sobre lo que observa.\n[5 puntos] ¿Cómo usaría este ejercicio con palabras simples para explicar a una persona que no sabe mucho de estadística sobre la importancia de los teoremas de límite central?"
  },
  {
    "objectID": "tareas/tarea-1.html#pregunta-6",
    "href": "tareas/tarea-1.html#pregunta-6",
    "title": "Tarea 1",
    "section": "Pregunta 6",
    "text": "Pregunta 6\nSea \\(x_1\\) un vector de variables continuas, \\(x_2\\) una variable continua y \\(d_1\\) una variable dicotómica. Considere el siguiente modelo probit: \\[P(y=1│x_1,x_2 )=\\Phi(x_1'\\alpha+\\beta x_2+\\gamma x_2^2 )\\]\n\n[5 punto] Provea una expresión para el efecto marginal de \\(x_2\\) en la probabilidad. ¿Cómo estimaría este efecto marginal?\n[3 punto] Considere ahora el modelo: \\[P(y=1│x_1  ,x_2 ,d_1)=\\Phi(x_1 '\\delta+\\pi x_2+\\rho d_1+\\nu x_2 d_1 )\\] Provea la nueva expresión para el efecto marginal de \\(x_2\\).\n[2 punto] En el modelo de la parte b., ¿cómo evaluaría el efecto de un cambio en \\(d_1\\) en la probabilidad? Provea una expresión para este efecto."
  },
  {
    "objectID": "tareas/index.html",
    "href": "tareas/index.html",
    "title": "Tareas",
    "section": "",
    "text": "Tarea 1\n\nFecha de entrega: viernes 13 de septiembre a las 20:00 en Teams\nPreguntas\nRespuestas\n\n\n\n\nTarea 2\n\nFecha de entrega: viernes 4 de octubre a las 20:00 en Teams\nPreguntas\nRespuestas\n\n\n\n\nTarea 3\n\nFecha de entrega: viernes 8 de noviembre a las 20:00 en Teams\n\n\n\n\nTarea 4\n\nFecha de entrega: viernes 29 de noviembre a las 20:00 en Teams",
    "crumbs": [
      "Tareas"
    ]
  },
  {
    "objectID": "reglas.html",
    "href": "reglas.html",
    "title": "Reglas",
    "section": "",
    "text": "No se tolerarán actos de discriminación. Se procura un ambiente de respeto entre todos los miembros de la clase.\nToda la comunicación relativa al curso se dará por medio del correo institucional del CIDE.\nLas tareas y exámenes se entregarán a través de Teams.\nLos participantes en la sesión deberán procurar que haya un ambiente silencioso para el desarrollo de la clase.\nSe aplicarán estrictamente los lineamientos generales contenidos en el código de ética del CIDE en términos de plagio y fraude en tareas y exámenes.",
    "crumbs": [
      "Reglas"
    ]
  },
  {
    "objectID": "materials.html",
    "href": "materials.html",
    "title": "Course Materials",
    "section": "",
    "text": "Datasets\nSlides"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html",
    "href": "diapositivas/variables-instrumentales.html",
    "title": "Variables instrumentales",
    "section": "",
    "text": "Supongamos que el el proceso de salarios verdadero está dado por\n\\[\\ln(w_i)=\\beta_0+\\beta_1 educ_i+\\beta_2 habilidad_i+e_i\\]\nY asumamos que la habilidad es no observada y decidimos estimar\n\\[\\ln(w_i)=\\beta_0+\\beta_1 educ_i+u_i\\]\n¿Dónde queda la habilidad?\nEl \\(\\hat{\\beta}_1\\) estimado con esta regresión corta es inconsistente porque \\(u_i\\) incluye la habilidad, que afecta tanto el desempeño en el mercado laboral como el desempeño en la escuela"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#qué-sucede-si-se-violan-los-supuestos-de-mco",
    "href": "diapositivas/variables-instrumentales.html#qué-sucede-si-se-violan-los-supuestos-de-mco",
    "title": "Variables instrumentales",
    "section": "",
    "text": "Supongamos que el el proceso de salarios verdadero está dado por\n\\[\\ln(w_i)=\\beta_0+\\beta_1 educ_i+\\beta_2 habilidad_i+e_i\\]\nY asumamos que la habilidad es no observada y decidimos estimar\n\\[\\ln(w_i)=\\beta_0+\\beta_1 educ_i+u_i\\]\n¿Dónde queda la habilidad?\nEl \\(\\hat{\\beta}_1\\) estimado con esta regresión corta es inconsistente porque \\(u_i\\) incluye la habilidad, que afecta tanto el desempeño en el mercado laboral como el desempeño en la escuela"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#instrumentos",
    "href": "diapositivas/variables-instrumentales.html#instrumentos",
    "title": "Variables instrumentales",
    "section": "Instrumentos",
    "text": "Instrumentos\nConsideremos el siguiente modelo\n\\[y=\\beta_0+\\beta_1 x+u\\]\ndonde \\(cov(x,u)\\neq 0\\)\nSuponga que existe una varible \\(z\\) que cumple con:\n\nExogeneidad: \\(z\\) no está correlacionada con \\(u\\)\n\n\\[cov(z,u)=0\\]\n\nRelevancia: \\(z\\) está correlacionado con \\(x\\)\n\n\\[cov(z,x)\\neq 0\\]\nEntonces \\(z\\) es un instrumento de \\(x\\)\nLa exogeneidad implica que \\(z\\) no debe estar correlacionado con factores omitidos (por ejemplo, la habilidad)"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#estimador-de-vi",
    "href": "diapositivas/variables-instrumentales.html#estimador-de-vi",
    "title": "Variables instrumentales",
    "section": "Estimador de VI",
    "text": "Estimador de VI\nCalculando la covarianza con \\(z\\) de \\(y=\\beta_0+\\beta_1 x+u\\) obtenemos:\n\\[cov(y,z)=\\beta_1 cov(x,z)+cov(u,z)\\]\nY, si \\(cov(u,z)\\), resolviendo para \\(\\hat{\\beta}_1\\)\n\\[\\hat{\\beta}_1=\\frac{cov(y,z)}{cov(x,z)}\\]\nsiempre y cuando \\(cov(x,z)\\neq 0\\)\nPor una LGN se puede mostrar que \\(\\hat{\\beta}_1\\) es consistente\nSin embargo, como profundizaremos más adelante, \\(\\hat{\\beta}_1\\) siempre es sesgagado\nEl sesgo puede ser sustancial en muestras pequeñas, por lo que se recomienda tener precaución con el tamaño de la muestra"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#ejemplo-rendimientos-a-la-educación",
    "href": "diapositivas/variables-instrumentales.html#ejemplo-rendimientos-a-la-educación",
    "title": "Variables instrumentales",
    "section": "Ejemplo: rendimientos a la educación",
    "text": "Ejemplo: rendimientos a la educación\nCard (1995) estudia el problema de retornos a la educación\nTenemos una muestra de 5,525 hombres de entre 14 y 24 años\nNos interesa la relación entre educación e ingreso, pero sabemos que no observamos la habilidad\nSabemos que si estimamos \\(\\ln(w_i)=\\beta_0+\\beta_1 educ_i+u_i\\), el coeficiente \\(\\beta_1\\) estará sesgado\nCard emplea como instrumento una variable \\(z_i\\) que indica si en el municipio de la persona \\(i\\) hay una universidad\nLa intución es que la presencia de la universidad baja el costo de ir a la universidad, pero esto no afecta directamente el ingreso\nEncontrar un instrumento casi nunca es tarea sencilla: se trata de enteder cómo los mecanismos, las instituciones y los contextos"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#lenguaje-de-vi",
    "href": "diapositivas/variables-instrumentales.html#lenguaje-de-vi",
    "title": "Variables instrumentales",
    "section": "Lenguaje de VI",
    "text": "Lenguaje de VI\nDe forma más general, partimos del la siguiente ecuación estructural para \\(y_i\\):\n\\[y_i=\\beta_0+\\beta_1 x_{1i}+\\beta_2 x_{2i}+u_i\\]\ndonde \\(cov(x_{1i},u_i)\\neq 0\\)\nA \\(x_{1i}\\) se le llama la variable endógena\nSe incluye también una o más variables exógenas como \\(x_{2i}\\) que no están correlacionadas con \\(u_i\\)\nA una regresión de la variable de interés en función del instrumento y las variables exógenas se le conoce como forma reducida\n\\[y_i=\\beta_0+\\beta_1 z_{1i}+\\beta_2 x_{2i}+u_i\\]"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#primera-etapa",
    "href": "diapositivas/variables-instrumentales.html#primera-etapa",
    "title": "Variables instrumentales",
    "section": "Primera etapa",
    "text": "Primera etapa\nLa primera etapa especifica la relación entre la variable endógena y el instrumento:\n\\[x_{1i}=\\pi_0+\\pi_1 z_i+\\pi_2x_{2i}+\\nu_i\\]\nDonde se cumple que \\(cov(z_i,\\nu_i=0)\\) y \\(cov(x_{2i},\\nu_i)=0\\)\nEntonces, la condición de relevancia puede escribirse también como \\(\\pi_1\\neq 0\\)\nNoten que la primera etapa también implica que, descontando el efecto de \\(z_i\\), todavía \\(x_{1i}\\) y \\(x_{2i}\\) están correlacionadas\nLa primera etapa puede y debe probarse empíricamente\nEn cambio, no es posible probar la restricción de exclusión, que debe estar respaldada sobre todo por la teoría económica, el conocimiento de las instituciones, la exogeneidad de experimentos naturales, etc."
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#más-de-un-instrumento",
    "href": "diapositivas/variables-instrumentales.html#más-de-un-instrumento",
    "title": "Variables instrumentales",
    "section": "Más de un instrumento",
    "text": "Más de un instrumento\nEs posible que haya \\(J\\) variables \\(z_{ij}\\) que puedan funcionar como instrumento\nSe debe cumplir que \\(cov(u_i,z_{ij})=0\\) y que cada una se correlacione con \\(x_{i1}\\)\nCon dos instrumentos, podemos escribir la primera etapa como\n\\[x_{1i}=\\pi_0+\\pi_1 z_{1i}+ \\pi_2 z_{2i} +\\pi_3x_{2i}+\\nu_i\\]\nAhora, debe cumplirse que \\(cov(z_{1i},\\nu_i)=cov(z_{2i},\\nu_i)=cov(x_{2i},\\nu_i)=0\\)\nPara lograr identificación, se requiere que \\(\\pi_1\\neq 0\\) o \\(\\pi_2\\neq 0\\)\nPodemos usar una prueba \\(F\\) para probar que \\(\\pi_1=\\pi_2=0\\)"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#mínimos-cuadrados-en-dos-etapas",
    "href": "diapositivas/variables-instrumentales.html#mínimos-cuadrados-en-dos-etapas",
    "title": "Variables instrumentales",
    "section": "Mínimos cuadrados en dos etapas",
    "text": "Mínimos cuadrados en dos etapas\nEl modelo presentado anteriormente sugiere que podemos estimar \\(\\beta_1\\) con un procedimiento de dos etapas\n\nRegresión de \\(x_{1i}\\) sobre los instrumentos y las variables exógenas para obtener \\(\\hat{x}_{1i}\\)\nRegresión de \\(y_i\\) sobre las variables exógenas y \\(\\hat{x}_{1i}\\)\n\nEs como si purgáramos a \\(x_{1i}\\) de su correlación con \\(u_i\\)\nNunca hacemos esto a mano\n\nCuando tenemos tantos instrumentos como endógenas, usamos el estimador de variables instrumentales\nCuando tenemos más instrumentos que endógenas, recurrimos al método generalizado de momentos"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#más-sobre-rendimientos-a-la-educación",
    "href": "diapositivas/variables-instrumentales.html#más-sobre-rendimientos-a-la-educación",
    "title": "Variables instrumentales",
    "section": "Más sobre rendimientos a la educación",
    "text": "Más sobre rendimientos a la educación\nEn el problema de Card (1995), la primera etapa es\n\\[esc_i=\\pi_0+\\pi_1 X_i+ \\phi unicerca_i +\\nu_i\\] donde \\(unicerca_i= \\begin{cases} 1 \\quad\\text{había una universidad en el municipio} \\\\ 0 \\quad\\text{otro caso}\\\\ \\end{cases}\\)\nY la forma reducida es\n\\[\\ln(w_i)=\\gamma_0+\\gamma_1 X_i+  \\delta unicerca_i+\\varepsilon_i\\]\nSabemos que el salario estará correlacionado con la presencia de la universidad, pero estas diferencias ocurren por la vía de la escolaridad"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#ejemplo-card-1995",
    "href": "diapositivas/variables-instrumentales.html#ejemplo-card-1995",
    "title": "Variables instrumentales",
    "section": "Ejemplo: Card (1995)",
    "text": "Ejemplo: Card (1995)\nUsamos los datos en ingresos_iv.csv, del estudio de Card que hemos mencionado como ejemplo\nLa librería AER, que ya hemos usado, tiene la función ivreg\nTambién usaremos una nueva librería, gmm\nEstimemos la relación entre el log del salario y la educación\n\ndata.ingresos &lt;- read_csv(\"../files/ingresos_iv.csv\",\n                          locale = locale(encoding = \"latin1\"))\n#MCO\nmco &lt;- lm(lwage ~ educ + exper + black + south + married + smsa,\n          data = data.ingresos)\n\n#Variables instrumentales (asume homocedasticidad)\nvi &lt;- ivreg(lwage ~  educ + exper + black + south + married + smsa |\n               . - educ + nearc4, data = data.ingresos)"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#ejemplo-card-1995-1",
    "href": "diapositivas/variables-instrumentales.html#ejemplo-card-1995-1",
    "title": "Variables instrumentales",
    "section": "Ejemplo: Card (1995)",
    "text": "Ejemplo: Card (1995)\nSabemos que \\(\\beta_1\\) estimado por MCO es inconsistente\n\nmodelsummary(list(\"MCO\"=mco, \"VI\"=vi),\n             coef_map = c(\"educ\", \"exper\"),\n             gof_map = c(\"nobs\", \"F\"))\n\n \n\n  \n    \n    \n    tinytable_elbvu1tt0pxpg5lx0ywk\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                MCO\n                VI\n              \n        \n        \n        \n                \n                  educ    \n                  0.071  \n                  0.124  \n                \n                \n                          \n                  (0.003)\n                  (0.050)\n                \n                \n                  exper   \n                  0.034  \n                  0.056  \n                \n                \n                          \n                  (0.002)\n                  (0.020)\n                \n                \n                  Num.Obs.\n                  3003   \n                  3003   \n                \n                \n                  F       \n                  219.153"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#ejemplo-card-1995-2",
    "href": "diapositivas/variables-instrumentales.html#ejemplo-card-1995-2",
    "title": "Variables instrumentales",
    "section": "Ejemplo: Card (1995)",
    "text": "Ejemplo: Card (1995)\nLa primera etapa de este ejercicio es\n\n# Primera etapa\npe_vi &lt;- lm(educ ~  nearc4 + exper + black + south + married + smsa,\n            data = data.ingresos)\n\n\nmodelsummary(list(\"MCO\"=mco, \"VI\"=vi, \"Primera etapa\"=pe_vi),\n             coef_map = c(\"educ\", \"exper\", \"nearc4\"),\n             gof_map = c(\"nobs\", \"F\"))\n\n \n\n  \n    \n    \n    tinytable_rrum14qygerdj5zc3oae\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n        \n              \n                 \n                MCO\n                VI\n                Primera etapa\n              \n        \n        \n        \n                \n                  educ    \n                  0.071  \n                  0.124  \n                         \n                \n                \n                          \n                  (0.003)\n                  (0.050)\n                         \n                \n                \n                  exper   \n                  0.034  \n                  0.056  \n                  -0.404 \n                \n                \n                          \n                  (0.002)\n                  (0.020)\n                  (0.009)\n                \n                \n                  nearc4  \n                         \n                         \n                  0.327  \n                \n                \n                          \n                         \n                         \n                  (0.082)\n                \n                \n                  Num.Obs.\n                  3003   \n                  3003   \n                  3003   \n                \n                \n                  F       \n                  219.153\n                         \n                  456.140"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#ejemplo-con-oferta-y-demanda",
    "href": "diapositivas/variables-instrumentales.html#ejemplo-con-oferta-y-demanda",
    "title": "Variables instrumentales",
    "section": "Ejemplo con oferta y demanda",
    "text": "Ejemplo con oferta y demanda\nSupongamos que nos interesa estimar la elasticidad del consumo de mantequilla\n\\[\\ln(q_{_i})=\\alpha + \\beta \\ln(p_i) + \\varepsilon_i\\] Supongamos que tenemos datos del precio y el consumo en una muestra grande de localidades \\(i\\)\nSi estimamos la ecuación anterior por MCO, el coeficiente estimado \\(\\hat{\\beta}\\) será inconsistente por un problema de simulateneidad\nEl precio y la cantidad se determinan en equilibrio por la interacción de la oferta y la demanda\nUn choque a la oferta o la demanda afectará tanto la cantidad como el precio de equilibrio"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#ejemplo-con-oferta-y-demanda-1",
    "href": "diapositivas/variables-instrumentales.html#ejemplo-con-oferta-y-demanda-1",
    "title": "Variables instrumentales",
    "section": "Ejemplo con oferta y demanda",
    "text": "Ejemplo con oferta y demanda\nPodemos usar variables instrumentales para estimar la elasticidad de la demanda\nNecesitamos una variable \\(z\\) que afecte solo la oferta, pero que no afecte directamente la demanda\n\\(z\\) puede ser precipitación o temperatura\nAl desplazar la oferta, manteniendo la demanda fija, se revela la forma de la curva de demanda\nPodemos estimar la elasticidad de la demanda"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#ejemplo-con-oferta-y-demanda-2",
    "href": "diapositivas/variables-instrumentales.html#ejemplo-con-oferta-y-demanda-2",
    "title": "Variables instrumentales",
    "section": "Ejemplo con oferta y demanda",
    "text": "Ejemplo con oferta y demanda\n\n# Add custom curves\ndemand1 &lt;- data.frame(Hmisc::bezier(c(1, 3, 9),\n                                    c(9, 3, 1))) \n\nsupply1 &lt;- data.frame(Hmisc::bezier(c(1, 8, 9),\n                                    c(1, 5, 9))) \n\nsupply2 &lt;- data.frame(Hmisc::bezier(c(1, 8, 9),\n                                    c(3, 8, 12))) \n\nsupply3 &lt;- data.frame(Hmisc::bezier(c(1, 8, 9),\n                                    c(5, 10, 14)))"
  },
  {
    "objectID": "diapositivas/variables-instrumentales.html#ejemplo-con-oferta-y-demanda-3",
    "href": "diapositivas/variables-instrumentales.html#ejemplo-con-oferta-y-demanda-3",
    "title": "Variables instrumentales",
    "section": "Ejemplo con oferta y demanda",
    "text": "Ejemplo con oferta y demanda\n\neconocharts::sdcurve(supply1, demand1, supply2, demand1, supply3, demand1,\n        names = c(\"S[1]\", \"D[1]\",\"S[2]\", \"D[1]\", \"S[3]\", \"D[1]\"),\n        xmax = 15, ymax=10)\n\n# A tibble: 3 × 2\n      x     y\n  &lt;dbl&gt; &lt;dbl&gt;\n1  4.65  3.40\n2  3.31  4.76\n3  2.39  6.03"
  },
  {
    "objectID": "lecturas.html",
    "href": "lecturas.html",
    "title": "Lecturas",
    "section": "",
    "text": "Todas las lecturas de capítulos de libro son obligatorias pues permiten una discusión informada en la clase. Las lecturas marcadas con “*” no serán cubiertas en clase, pero son ampliamente recomendables. En las sesiones de exposiciones cada alumno presentará uno de los artículos enlistados con negritas, por lo que se espera que el resto de la clase tenga el conocimiento suficiente para participar en la discusión.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#prerrequisitos",
    "href": "lecturas.html#prerrequisitos",
    "title": "Lecturas",
    "section": "Prerrequisitos",
    "text": "Prerrequisitos\n\nModelos lineales\n\nW, Capítulos 1-4",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-1",
    "href": "lecturas.html#semana-1",
    "title": "Lecturas",
    "section": "Semana 1",
    "text": "Semana 1\n\nIntroducción\n\nAngrist, J. D., & Pischke, J. S. (2017). Undergraduate Econometrics Instruction: Through Our Classes, Darkly. Journal of Economic Perspectives,31(2), 125-44.\n* Nakamura, E., & Steinsson, J. (2018). Identification in macroeconomics. Journal of Economic Perspectives, 32(3), 59-86.\n\nMCO\n\nCT, Capítulo 4 (secciones 4.1 a 4.3)",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-2",
    "href": "lecturas.html#semana-2",
    "title": "Lecturas",
    "section": "Semana 2",
    "text": "Semana 2\n\nTeoría asintótica\n\nCT, Capítulo 4, (sección 4.4)\n\nEstimadores extremos\n\nCT, Capítulo 5",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-3",
    "href": "lecturas.html#semana-3",
    "title": "Lecturas",
    "section": "Semana 3",
    "text": "Semana 3\n\nPrueba de hipótesis\n\nCT, Capítulo 7",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-4",
    "href": "lecturas.html#semana-4",
    "title": "Lecturas",
    "section": "Semana 4",
    "text": "Semana 4\n\nVariable dependiente binaria\n\nCT, Capítulo 14 (secciones 14.1 - 14.4)\nBinaria: Avila-Foucat, V. S., & Pérez-Campuzano, E. (2015). Municipality socioeconomic characteristics and the probability of occurrence of Wildlife Management Units in Mexico. Environmental Science & Policy, 45, 146-153.\n* Ordenados: Conigliani, C., Manca, A., & Tancredi, A. (2015). Prediction of patient-reported outcome measures via multivariate ordered probit models. Journal of the Royal Statistical Society. Series A (Statistics in Society), 567-591.\n\nVariable dependiente categórica\n\nCT, Capítulo 15 (secciones 15.1 - 15.4)\nMultinomial: Kveder, C. L. M., & Flahaux, M. L. (2013). Returning to Dakar: A mixed methods analysis of the role of migration experience for occupational status. World Development, 45, 223-238.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-5",
    "href": "lecturas.html#semana-5",
    "title": "Lecturas",
    "section": "Semana 5",
    "text": "Semana 5\n\nModelos de conteo\n\nCT, Capítulo 20 (secciones 20.1 - 20.4).\n* Poisson: White, K., & Buckley, C. J. (2011). Exposure to international migration and its effect on childbearing in Turkey. International Migration Review, 45(1), 123-147.\n* Negativo binomial: Antón, J. I., & De Bustillo, R. M. (2010). Health care utilisation and immigration in Spain. The European Journal of Health Economics, 11(5), 487-498.\n* Inflado en cero: Young, J. D., Anderson, N. M., Naughton, H. T., & Mullan, K. (2018). Economic and policy factors driving adoption of institutional woody biomass heating systems in the US. Energy Economics, 69, 456-470.\n* Dos partes: Colchero, M. A., Molina, M., & Guerrero-López, C. M. (2017). After Mexico implemented a tax, purchases of sugar-sweetened beverages decreased and water increased: difference by place of residence, household composition, and income level. The Journal of nutrition, 147(8), 1552-1557.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-6",
    "href": "lecturas.html#semana-6",
    "title": "Lecturas",
    "section": "Semana 6",
    "text": "Semana 6\n\nModelos de selección\n\nCT, Capítulo 16 (secciones 16.1 – 16.6)\nTobit: Zou, B., & Luo, B. (2019). Rural Household Energy Consumption Characteristics and Determinants in China. Energy.\n* Heckman: Parey, M., Ruhose, J., Waldinger, F., & Netz, N. (2017). The selection of high-skilled emigrants. Review of Economics and Statistics, 99(5), 776-792.\n* Ordenado + selección: Alemi, F., Circella, G., Mokhtarian, P., & Handy, S. (2019). What drives the use of ridehailing in California? Ordered probit models of the usage frequency of Uber and Lyft. Transportation Research Part C: Emerging Technologies, 102, 233-248.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-7",
    "href": "lecturas.html#semana-7",
    "title": "Lecturas",
    "section": "Semana 7",
    "text": "Semana 7\n\nVariables instrumentales\n\nW, Capítulo 5.\nCT, Capítulo 4 (secciones 4.8 y 4.9)",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-8",
    "href": "lecturas.html#semana-8",
    "title": "Lecturas",
    "section": "Semana 8",
    "text": "Semana 8\n\nMétodo generalizado de momentos\n\nCT, Capítulo 6 (secciones 6.1 - 6.4)",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-9",
    "href": "lecturas.html#semana-9",
    "title": "Lecturas",
    "section": "Semana 9",
    "text": "Semana 9\n\nVariables instrumentales en la práctica\n\nVI: Hackett, L., & Marquez-Padilla, F. (2019). Working for Change: the Effect of Female Labor Force Participation on Fertility. SSRN Working Paper 3354753.\nVI: López-Feldman, A., & Chávez, E. (2017). Remittances and natural resource extraction: Evidence from Mexico. Ecological Economics, 132, 69-79.\n\nOtras aplicaciones de VI\n\n* VI: Campos-Vazquez, R. M., & Nuñez, R. (2019). Obesity and labor market outcomes in Mexico/Obesidad y el mercado de trabajo en México. Estudios Económicos, 34(2), 159-196.\n* MC2E2M: Mocetti, S. (2007). Intergenerational earnings mobility in Italy. The BE Journal of Economic Analysis & Policy, 7(2).\n\n* Poisson + VI: Hirvonen, K., & Hoddinott, J. (2017). Agricultural production and children’s diets: Evidence from rural Ethiopia. Agricultural Economics, 48(4), 469-480.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-10",
    "href": "lecturas.html#semana-10",
    "title": "Lecturas",
    "section": "Semana 10",
    "text": "Semana 10\n\nModelos y estimadores de panel\n\nCT, Capítulo 21\nPanel: Amare, M., Abay, K. A., Tiberti, L., & Chamberlin, J. (2021). COVID-19 and food security: Panel data evidence from Nigeria. Food policy, 101, 102099.\nPanel: Kagin, J., Taylor, J. E., & Yúnez-Naude, A. (2016). Inverse productivity or inverse efficiency? Evidence from Mexico. The Journal of Development Studies, 52(3), 396-411.\n* Panel: Bwalya, S. M. (2006). Foreign direct investment and technology spillovers: Evidence from panel data analysis of manufacturing firms in Zambia. Journal of development economics, 81(2), 514-526.\n* Panel + DID: Estrada, R. (2019). Rules versus discretion in public service: Teacher hiring in Mexico. Journal of Labor Economics, 37(2), 545-579.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-11",
    "href": "lecturas.html#semana-11",
    "title": "Lecturas",
    "section": "Semana 11",
    "text": "Semana 11\n\nTemas de errores estándar\n\nMHE, Capítulo 8",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-12",
    "href": "lecturas.html#semana-12",
    "title": "Lecturas",
    "section": "Semana 12",
    "text": "Semana 12\n\nBootstrap\n\nCT, Capítulo 11\nBootstrap: Li, H., & Maddala, G. S. (1999). Bootstrap variance estimation of nonlinear functions of parameters: an application to long-run elasticities of energy demand. Review of Economics and Statistics, 81(4), 728-733.\n\nRegresión cuantil\n\nCT, Capítulo 4 (sección 4.6)\nCuantil: Engelhardt, G. V., & Kumar, A. (2011). Pensions and household wealth accumulation. Journal of Human Resources, 46(1), 203-236.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#semana-13",
    "href": "lecturas.html#semana-13",
    "title": "Lecturas",
    "section": "Semana 13",
    "text": "Semana 13\n\nMétodos semiparamétricos\n\nCT, Capítulo 9\nSemiparamétrico: Hussinger, K. (2008). R&D and subsidies at the firm level: An application of parametric and semiparametric two‐step selection models. Journal of applied econometrics, 23(6), 729-747.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "lecturas.html#extensiones",
    "href": "lecturas.html#extensiones",
    "title": "Lecturas",
    "section": "Extensiones",
    "text": "Extensiones\n\nPanel no lineal\n\nCT, Capítulo 23\n* Panel Poisson: Castillo, J. C., Mejía, D., & Restrepo, P. (2020). Scarcity without leviathan: The violent effects of cocaine supply shortages in the mexican drug war. Review of Economics and Statistics, 102(2), 269-286.\n\nPanel con endogeneidad\n\nCT, Capítulo 22 (secciones 22.1 - 22.5)\n* Panel + VI: Antman, F. M. (2011). The intergenerational effects of paternal migration on schooling and work: What can we learn from children’s time allocations?. Journal of Development Economics, 96(2), 200-208.\n* Wooldridge, J. (2012). Panel data models with heterogeneity and endogeneity. Institute for Fiscal Studies.\n* Semykina, A., & Wooldridge, J. M. (2010). Estimating panel data models in the presence of endogeneity and selection. Journal of Econometrics, 157(2), 375-380.\n\nModelos de riesgo y sobrevivencia\n\nCT, Capítulo 17 (secciones 17.1 – 17.4 y 17.6-17.11)\n* Riesgo: De Uña-Alvarez, J., Otero-Giráldez, M. S., & Alvarez-Llorente, G. (2003). Estimation under length-bias and right-censoring: an application to unemployment duration analysis for married women. Journal of Applied Statistics, 30(3), 283-291.",
    "crumbs": [
      "Lecturas"
    ]
  },
  {
    "objectID": "programa.html",
    "href": "programa.html",
    "title": "Programa",
    "section": "",
    "text": "Conocer la teoría sobre la que se fundamentan los métodos para la estimación de relaciones empíricas y la inferencia usando datos de sección cruzada y de panel.\nDiseñar estrategias econométricas usando los modelos adecuados de acuerdo con la pregunta de investigación.\nEmplear software para estimar los modelos econométricos apropiados de acuerdo con la naturaleza de los datos disponibles.\nConocer e implementar buenas prácticas en el uso de software, orientadas a la transparencia y la replicabilidad en la investigación.\nConocer los métodos que se emplean en la investigación económica actual.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#objetivos",
    "href": "programa.html#objetivos",
    "title": "Programa",
    "section": "",
    "text": "Conocer la teoría sobre la que se fundamentan los métodos para la estimación de relaciones empíricas y la inferencia usando datos de sección cruzada y de panel.\nDiseñar estrategias econométricas usando los modelos adecuados de acuerdo con la pregunta de investigación.\nEmplear software para estimar los modelos econométricos apropiados de acuerdo con la naturaleza de los datos disponibles.\nConocer e implementar buenas prácticas en el uso de software, orientadas a la transparencia y la replicabilidad en la investigación.\nConocer los métodos que se emplean en la investigación económica actual.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#referencias",
    "href": "programa.html#referencias",
    "title": "Programa",
    "section": "Referencias",
    "text": "Referencias\nEl curso se basa en los siguientes textos:\n\n(MHE) Angrist, J.D. y Pischke, J.S. (2013). Mostly Harmless Econometrics: An Empiricists Companion. Princeton University Press.\n* (CT) Cameron, A.C. y Trivedi, P.K. (2005). Microeconometrics: Methods and applications. Oxford University Press.\nHansen, B. (2022). Econometrics. Princeton University Press.\nHayashi, F. (2000). Econometrics. Princeton University Press.\n* (W) Wooldridge, J.M. (2010). Econometric analysis of cross section and panel data. Segunda edición, MIT Press.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#contenido-temático",
    "href": "programa.html#contenido-temático",
    "title": "Programa",
    "section": "Contenido temático",
    "text": "Contenido temático\nUnidad 1. Introducción\n\nRevisión de fundamentos de estadística y regresión lineal\nTeoría asintótica\nEstimadores extremos\nMáxima verosimilitud\nMínimos cuadrados no lineales\nInferencia estadística\n\nUnidad 2. Modelos de variable dependiente no continua\n\nModelos de variable dependiente binaria\n\nModelos de conteo\n\nUnidad 3. Modelos de selección\n\nModelo de Tobit\nModelo de Heckman\n\nUnidad 4. Endogeneidad\n\nVariables instrumentales\nMétodo generalizado de momentos\nEstimación con instrumentos débiles\n\nUnidad 5. Datos de panel\n\nModelos de efectos fijos y de efectos aleatorios\nEstimadores between y within\nEstimadores de primeras diferencias y de efectos aleatorios\nErrores estándar agrupados\n\nUnidad 6. Extensiones\n\nBootstrap\nRegresión por cuantiles\nMétodos semi paramétricos y no paramétricos\nModelos de panel no lineales\nModelos de panel con endogeneidad\nModelos de riesgo y de sobrevivencia",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#evaluación-del-curso",
    "href": "programa.html#evaluación-del-curso",
    "title": "Programa",
    "section": "Evaluación del curso",
    "text": "Evaluación del curso\n\nExamen parcial: 30%.\nExamen final acumulativo: 45%\nTareas (4): 20% (5% cada una)\nExposición: 5%",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#tareas",
    "href": "programa.html#tareas",
    "title": "Programa",
    "section": "Tareas",
    "text": "Tareas\nCuatro tareas teórico-prácticas. Las tareas deben entregarse de manera individual, pero se recomienda ampliamente colaborar en grupos de estudio. Las tareas deberán entregarse en Teams antes de la fecha y hora señalada. No se aceptarán tareas fuera de tiempo. Por favor, no comprima los archivos en carpetas comprimidas. Las tareas deberán contener dos archivos:\nUn primer documento de respuestas donde se incluyan las respuestas a las preguntas teóricas y conceptuales. Este documento debe estar en formato pdf y debe ser generado usando un software de procesamiento de textos científicos, por ejemplo, usando los leguajes LaTeX o Markdown. En este documento también se deben incluir las respuestas a preguntas sobre conclusiones que se desprenden de las secciones prácticas. Por ejemplo, si una pregunta pide obtener la media de la variable x en cierta base de datos, entonces el documento de respuestas debe incluir la pregunta y respuesta correspondiente: “la media de la variable x es 32.6”. En este documento también deberán incluirse las tablas y gráficas que se soliciten.\nUn segundo archivo deberá contener el código replicable usado para generar los resultados de la sección práctica. El código debe también crear las tablas y gráficas solicitadas. Los archivos de código se verificarán para comprobar su replicabilidad de manera aleatoria.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#software",
    "href": "programa.html#software",
    "title": "Programa",
    "section": "Software",
    "text": "Software\nR será el paquete standard usado en las sesiones prácticas. Más aún, el uso de cualquier software es aceptado siempre que se cumplan con los requisitos de replicabilidad y reportes de las tareas y exámenes. Habrá una sesión especial para introducir el uso de Quarto para la generación de reportes científicos.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#exámenes",
    "href": "programa.html#exámenes",
    "title": "Programa",
    "section": "Exámenes",
    "text": "Exámenes\n\nExamen parcial: miércoles 9 de octubre en el horario de clase.\nExamen final: por definir.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#exposición",
    "href": "programa.html#exposición",
    "title": "Programa",
    "section": "Exposición",
    "text": "Exposición\nCada alumno realizará una presentación de uno de los artículos aplicados marcados con negritas en la lista de lecturas. Cada presentación deberá ser de máximo 15 minutos y deberá incluir el contenido que el presentador considere más relevante. La presentación deberá abordar, mínimamente: 1) el problema a investigar, 2) la metodología empleada, 3) la relación entre la metodología y la teoría vista en el curso, 4) los datos empleados, 5) los principales resultados, y 6) una crítica sobre la validez y las conclusiones del estudio.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "programa.html#lista-de-lecturas",
    "href": "programa.html#lista-de-lecturas",
    "title": "Programa",
    "section": "Lista de lecturas",
    "text": "Lista de lecturas\nTodas las lecturas de capítulos de libro son obligatorias pues permiten una discusión informada en la clase. Las lecturas marcadas con “*” no serán cubiertas en clase, pero son ampliamente recomendables. En las sesiones de exposiciones cada alumno presentará uno de los artículos enlistados con negritas, por lo que se espera que el resto de la clase tenga el conocimiento suficiente para participar en la discusión.\nLa lista de lecturas está disponible aquí.",
    "crumbs": [
      "Programa"
    ]
  },
  {
    "objectID": "schedule.html",
    "href": "schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Example schedule:\n\n\n\n\n\n\n\n\n\nMorning\nAfternoon\n\n\n\n\nL\nIntro + Data manipulation\ngit / GitHub\n\n\nM\nGeneralised Linear Models\nData visualisation\n\n\nX\nMixed models / GAM / Bayes\nFunctional programming + Students work\n\n\nJ\nMultivariate analyses\nReproducible workflows\n\n\nV\nUsing R as GIS + Students work\nProject presentations"
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html",
    "href": "tareas/tarea-1-respuestas.html",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Considere el problema de regresión no lineal en el que la variable dependiente escalar \\(y\\) tiene una media condicional \\(E(y_i)=g(x_i,\\beta)\\), siendo \\(g(\\cdot)\\) una función no lineal. Suponga que:\n\nEl proceso generador de datos es \\(y_i=g(x_i,\\beta_0)+u_i\\).\nEn el proceso generador de datos \\(E(u_i|x_i)=0\\) y \\(E(uu'|X)=\\Omega\\), donde \\(\\Omega_{0,ij}=\\sigma_{ij}\\).\nLa función \\(g(\\cdot)\\) satisface \\(g(x, \\beta^{(1)})=g(x, \\beta^{(2)})\\) si y solo si \\(\\beta^{(1)}=\\beta^{(2)}\\).\nLa matriz \\(A_0\\) existe y es finita y no singular y donde \\(A_0=p\\lim\\frac{1}{N}\\sum_{i=1}^{N}\\left.\\frac{\\partial g_i}{\\partial \\beta}\\right|_{\\beta_0}\\left.\\frac{\\partial g_i}{\\partial \\beta'}\\right|_{\\beta_0}=p\\lim\\frac{1}{N}\\left.\\frac{\\partial g'}{\\partial \\beta}\\frac{\\partial g'}{\\partial \\beta'}\\right|_{\\beta_0}\\)\n\\(N^{-1/2}\\sum_{i=1}^N \\left.\\frac{\\partial g_i}{\\partial \\beta}u_i \\right|_{\\beta_0}\\xrightarrow{d}\\mathcal{N}(0,B_0)\\), donde \\(B_0=p\\lim \\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\sigma_{ij}\\left.\\frac{\\partial g_i}{\\partial \\beta}\\frac{\\partial g_i}{\\partial \\beta'}\\right|_{\\beta_0}=p\\lim\\frac{1}{N}\\left.\\frac{\\partial g'}{\\partial \\beta}\\Omega_0 \\frac{\\partial g}{\\partial \\beta'}\\right|_{\\beta_0}\\).\nRespuestas: ver proposición 5.6 en CT.\n\n\n[5 puntos] Plantee el problema de optimización para la minimización de la suma de los errores cuadráticos y obtenga las condiciones de primer orden.\n[10 puntos] Pruebe que \\(\\hat{\\beta}_{MCNL}\\), el estimador de mínimos cuadrados no lineales (MCNL) y definido como una raíz de las condiciones de primer orden, es consistente para \\(\\beta_0\\).\n[10 puntos] Derive una expresión para \\(\\sqrt{N}(\\hat{\\beta}_{MCNL}-\\beta_0)\\) y pruebe que \\(\\sqrt{N}(\\hat{\\beta}_{MCNL}-\\beta_0)\\xrightarrow{d}\\mathcal{N}(0,A_0^{-1}B_0A_0^{-1})\\). Tip: utilice una expansión de Taylor exacta de primer orden.\n[5 puntos] ¿Cómo estimaría \\(V(\\hat{\\beta}_{MCNL})\\)?}\n\n\n\n\nSuponga que está interesado en una variable aleatoria que tiene una distribución Bernoulli con parámetro \\(p\\). La función de densidad está definida como:\n\\[f(x_;p)=\\left\\{\\begin{array} .1 & \\text{con probabilidad } p \\\\ 0 & \\text{con probabilidad } 1-p \\end{array} \\right.\\] Suponga que tiene una muestra de \\(N\\) observaciones independientes e idénticamente distribuidas.\n\n[4 puntos] Plantee la función de log verosimilitud del problema.\nPodemos escribir la función de densidad para la \\(i\\)-ésima observación como\n\\[f(x_i;p)=p^{x_i}(1-p)^{(1-x_i)}\\]\nPor tanto, la función de verosimilitud es\n\\[L_N(p)=\\prod_{i=1}^N f(x;p)=\\prod_{i=1}^N p^{x_i}(1-p)^{(1-x_i)} = p^{\\sum_{i=1}^N x_i}(1-p)^{N-\\sum_{i=1}^N x_i}\\]\nY la función de log verosimilitud será\n\\[\\mathcal{L_N(p)}=\\ln{L_N(p)}=\\sum x_i \\ln(p)-(N-\\sum x_i)\\ln(1-p)\\]\n[4 puntos] Obtenga las condiciones de primer orden y resuelva para \\(\\hat{p}\\).\nDerivando \\(\\mathcal{L}_N\\) con respecto a \\(p\\) obtenemos la condición de primer orden:\n\\[\\frac{d\\mathcal{L}_N(p)}{d p}=\\frac{\\sum x_i}{p}-\\frac{N-\\sum x_i}{1-p}=0\\]\nY resolviendo, obtenemos el estimador de máxima verosimilitud \\[\\hat{p}_{MV}=\\bar{x}\\] es decir, la media muestral.\n[2 puntos] ¿Cuál es la media y la varianza del estimador de máxima verosimilitud que ha encontrado?\nObtenemos directamente la media \\[E(\\hat{p}_{MV})=E(\\bar{x})=\\frac{1}{N}E\\left(\\sum x_i\\right)=\\frac{1}{N}N p=p\\]\nMientras que la varianza es \\[V(\\hat{p}_{MV})=\\frac{1}{N^2}V\\left(\\sum x_i\\right)=\\frac{p(1-p)}{N}\\]\n\n\n\n\nConsidere el modelo logit:\n\\[f(y_i|x_i;\\theta_0)=\\left\\{ \\begin{array} .1 & \\frac{\\exp\\{x_i'\\theta_0\\}}{1+\\exp\\{x_i'\\theta_0\\}}  \\\\ 0 &  \\frac{1}{1+\\exp\\{x_i'\\theta_0\\}} \\end{array} \\right.\\] donde \\(x_i\\) es un vector de variables explicativas, \\(\\theta_0\\) y es el vector de parámetros poblacional. Asuma que dispone de observaciones \\((y_i,x_i)\\) que son iid.\n\n[5 puntos] Escriba la función de log verosimilitud condicional para la observación \\(i\\).\nEs conveniente escribir el problema en término de \\(\\Lambda (x_i'\\theta_0) \\equiv \\frac{\\exp\\{x_i'\\theta_0\\}}{1+\\exp\\{x_i'\\theta_0\\}}\\). Así, la función de verosimilitud para la observación \\(i\\) es:\n\\[f(y_i|x_i;\\theta_0)=\\Lambda (x_i'\\theta_0)^{y_i}(1-\\Lambda (x_i'\\theta_0))^{(1-y_i)}\\]\nTomando logs, la función de log verosimilitud es:\n\\[\\mathcal{l}(y_i|x_i,\\theta)=\\ln f(y_i|x_i;\\theta)=y_i\\ln \\Lambda (x_i'\\theta)+(1-y_i)(1-\\Lambda (x_i'\\theta))\\]\n[5 puntos] Encuentre el vector score para la observación \\(i\\).\nEl vector score es el vector de primeras derivadas parciales de la log verosimilitud. Un pequeño truco facilita las cosas. Se puede mostrar que \\(\\Lambda (\\cdot)'=\\Lambda (\\cdot)(1-\\Lambda (\\cdot))\\). Entonces:\n\\[\\frac{\\partial \\mathcal{l}_i}{\\partial\\theta}=y_i \\frac{1}{\\Lambda (x_i'\\theta)}\\Lambda (x_i'\\theta)(1-\\Lambda (x_i'\\theta))x_i+(1-y_i)\\frac{1}{1-\\Lambda (x_i'\\theta)}\\Lambda (x_i'\\theta)(1-\\Lambda (x_i'\\theta))x_i\\]\nSimplificando:\n\\[\\frac{\\partial \\mathcal{l}_i}{\\partial\\theta}=(y_i-\\Lambda (x_i'\\theta))x_i \\equiv s(y_i,x_i;\\theta)\\]\n[5 puntos] Encuentre la hesiana de la función de log verosimilitud con respecto a \\(\\mathbf{\\theta}\\).\nProcedemos a derivar el score con respecto a \\(\\theta'\\):\n\\[H(y_i,x_i;\\theta)\\equiv \\frac{\\partial s(y_i,x_i;\\theta)}{\\partial \\theta'}= -\\Lambda(x_i'\\theta)(1-\\Lambda(x_i'\\theta))x_ix_i'\\]\n[5 puntos] Obtenga la matriz de información para la observación \\(i\\).\nLa matriz de información es \\(E(s(y_i,x_i;\\theta_0)s(y_i,x_i;\\theta_0)'|x_i)\\)\n\\[I(\\theta_0)=E((y_i-\\Lambda(x_i'\\theta_0))^2x_ix_i')\\]\n\n\n\n\nSuponga una variable aleatoria \\(X_i\\) con distribución desconocida. Sin embargo, sí conocemos que \\(E(X)=\\mu=54\\) y que \\(\\sqrt{V(X)}=\\sigma=6\\). Suponga que se recolecta una muestra de 50 observaciones.\n\n[2 punto] ¿Cuál es la distribución asintótica de la media muestral \\(\\bar{X}\\)?\nSi se puede aplicar un teorema de límite central a la media muestral, sabemos que la nueva variable hereda la media de \\(X_i\\) y la desviación estándar es la desviación estándar de \\(X_i\\) dividida por la raíz del tamaño de la muestra. Es decir:\n\\[\\bar{X}\\sim \\mathcal{N}(54, 6^2/50)\\]\n[4 punto] ¿Cuál es la probabilidad de que \\(\\bar{X}&gt;58\\)?\nSabemos que \\(\\frac{\\bar{X}-54}{6/\\sqrt{50}}\\sim\\mathcal{N}(0,1)\\), por tanto:\n\\[P(\\bar{X}&gt;58)=P\\left(z&gt;\\frac{58-54}{6/\\sqrt{50}}\\right)=P(z&gt;4.714045)=1-\\Phi(4.714045)\\]\nCalculamos la probabilidad usando pnorm, que nos da la función de distribución. La probabilidad es un número muy pequeño:\n\n1-pnorm((58-54)/(6/sqrt(50)), mean = 0, sd = 1)\n\n[1] 1.214234e-06\n\n\n[2 punto] ¿Cuál es la probabilidad de que una observación elegida al azar sea tal que \\(X_i&gt;58\\)?\nEs imposible de determinar porque no sabemos la distribución de \\(X_i\\). Esto es algo muy conveniente de los TLC, pues nos permiten hacer afirmaciones sobre la media muestral sin saber la distribución de la que provienen las observaciones. Solo necesitamos que se cumplan las condiciones sobre las \\(X_i\\) para aplicar los TLC.\n[2 punto] Provea un intervalo de confianza de 99% para la media muestral.\nPor un lado, sabemos que la variable aleatoria \\(Z=\\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{N}}\\) tendrá una distribución \\(\\mathcal{N}(0,1)\\). Por otro lado, queremos obtener \\(P(-z_{\\alpha/2}&lt;Z&lt;z_{\\alpha/2})=0.99\\). Manipulando, obtenemos una expresión para el intervalo de confianza:\n\\[\\left(\\bar{X}-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{N}},\\bar{X}+z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{N}}\\right)\\]\nEn nuestro caso, el intervalo es:\n\\[P\\left(\\bar{X}\\pm 2.5758\\times(6/\\sqrt{50})\\right)=0.99\\]\ndonde obtenemos el 2.5758 como:\n\nqnorm(0.995)\n\n[1] 2.575829\n\n\nqnorm es la función cuantil y está definida como la función inversa de la función de distribución. La función cuantil da el valor de \\(x\\) tal que \\(F(x)=P(X \\leq x)=p\\).\nEntonces, el intervalo de confianza es: \\[P(\\bar{X}\\pm 2.185664)=0.99\\]\n\n\n\n\nEn esta pregunta mostraremos los alcances de los teoremas del límite central. Para esto, generaremos muchas muestras de tamaño \\(N\\) con una distribución \\(Bernoulli\\) con probabilidad de éxito \\(p=0.7\\). Recuerde que cuando realice simulaciones, siempre debe fijar una semilla al inicio para poder replicar su trabajo.\n\n[2 puntos] ¿Cuál es la media y la varianza de una variable aleatoria \\(y_i \\sim Bernoulli(0.3)\\)?\nPara una variable que se distribuye \\(Bernoulli(p)\\), la media es \\(p\\) y la varianza es \\(p(1-p)\\). Para este caso, \\(E(y_i)=0.7\\) y \\(V(y_i)=0.7*0.3=0.21\\).\n[2 puntos] Si \\(y_i\\) son iid y podemos aplicar un teorema de límite central, ¿cuál es la distribución teórica de \\(\\bar{y}\\) cuando \\(N\\to\\infty\\)?\nObtenemos el valor esperado y la varianza de \\(\\bar{y}\\):\n\\[E(\\bar{y})=\\frac{1}{N}E(\\sum_i y_i)  = E(y_i)=p\\]\n\\[V(\\bar{y})=\\frac{1}{N^2}V(\\sum_i y_i) = \\frac{1}{N}V(y_i)=\\frac{p(1-p)}{N}\\]\nEntonces, un TLC nos daría las condiciones para que:\n\\[\\frac{\\bar{y}-0.7}{\\sqrt{0.21/N}}\\sim\\mathcal{N}(0, 1)\\]\n[5 puntos] Realice el siguiente procedimiento \\(J=1,000\\) veces. Obtenga una muestra de tamaño \\(N=3\\) a partir de la distribución \\(Bernoulli(0.7)\\) y calcule la media muestral \\(\\bar{y}\\). Coleccione las \\(J\\) medias muestrales y luego grafique un histograma de las medias muestrales obtenidas junto con una curva teórica normal con la media y varianza obtenida en la parte b. Comente sobre lo que observa.\n\nset.seed(921)\nreps &lt;- 1000\nn &lt;- 3\np &lt;- 0.7\nv &lt;- p*(1-p)/n\n\nymedias3 &lt;- numeric(reps)\nfor (i in 1:reps){\n sample &lt;- rbinom(n, 1, p)\n ymedias3[i]&lt;-mean(sample)\n}\n\nGraficamos junto con una densidad \\(N(0.7, \\sqrt{0.21/3})\\):\n\nhist(ymedias3, breaks=20, prob=TRUE, \n     xlab=\"Medias\")\ncurve(dnorm(x, mean=p, sd=sqrt(v)), \n      col=\"darkblue\", lwd=2, add=TRUE, yaxt=\"n\")\n\n\n\n\n\n\n\n\nEl histograma no se parece nada a la curva normal.\n[3 puntos] Repita lo realizado en la parte b., ahora con \\(N=15\\). Comente sobre lo que observa.\n\nreps &lt;- 1000\nn &lt;- 15\np &lt;- 0.7\nv &lt;- p*(1-p)/n\n\nymedias15 &lt;- numeric(reps)\nfor (i in 1:reps){\n sample &lt;- rbinom(n, 1, p)\n ymedias15[i]&lt;-mean(sample)\n}\n\nGraficamos junto con una densidad \\(N(0.7, \\sqrtt{0.21/15})\\):\n\nhist(ymedias15, breaks=20, prob=TRUE)\ncurve(dnorm(x, mean=p, sd=sqrt(v)), \n      col=\"darkblue\", lwd=2, add=TRUE, yaxt=\"n\")\n\n\n\n\n\n\n\n\nEl histograma comienza a tener una forma normal.\n[3 puntos] Repita lo realizado en la parte b., ahora con \\(N=1,500\\). Comente sobre lo que observa.\n\n#|echo: true\n\nreps &lt;- 1000\nn &lt;- 1500\np &lt;- 0.7\nv &lt;- p*(1-p)/n\n\nymedias1500 &lt;- numeric(reps)\nfor (i in 1:reps){\n sample &lt;- rbinom(n, 1, p)\n ymedias1500[i]&lt;-mean(sample)\n}\n\nGraficamos junto con una densidad \\(N(0.7, \\sqrt{0.21/1500})\\):\n\nhist(ymedias1500, breaks=20, prob=TRUE, \n     xlab=\"Medias\")\ncurve(dnorm(x, mean=p, sd=sqrt(v)), \n      col=\"darkblue\", lwd=2, add=TRUE, yaxt=\"n\")\n\n\n\n\n\n\n\n\nEl histograma se parece ya a la curva normal. Podrían repetir este ejercicio con un tamaño de muestra más grande incluso y ver qué sucede.\n[5 puntos] ¿Cómo usaría este ejercicio con palabras simples para explicar a una persona que no sabe mucho de estadística sobre la importancia de los teoremas de límite central?\nUn TLC nos permite hacer afirmaciones sobre la distribución de un estadístico. Un estadístico es un resumen de los datos, por lo que nos interesa usar dichos estadísticos para describir características de los fenómenos que estudiamos usando datos. Queremos saber cosas como lo que esperamos en promedio que suceda con una variable, o qué tanta variabilidad dicha variable tendrá en la población. Con un TLC podemos hacer afirmaciones sobre cómo lucen promedios muestrales de la variable que estudiamos cuando tenemos suficientes observaciones. Nos dice en particular que va a tener una distribución normal.\n\n\n\n\nSea \\(x_1\\) un vector de variables continuas, \\(x_2\\) una variable continua y \\(d_1\\) una variable dicotómica. Considere el siguiente modelo probit: \\[P(y=1│x_1,x_2 )=\\Phi(x_1'\\alpha+\\beta x_2+\\gamma x_2^2 )\\]\n\n[5 punto] Provea una expresión para el efecto marginal de \\(x_2\\) en la probabilidad. ¿Cómo estimaría este efecto marginal?\nEl efecto marginal de interés es:\n\\[\\frac{\\partial P(y=1|x_1,x_2)}{\\partial x_2}=\\phi(x_1\\alpha+\\beta x_2+\\gamma x_2^2)(\\beta+2\\gamma x_2)\\]\nPara estimarlo, usamos máxima verosimilitud para obtener estimadores consistentes de \\(\\alpha\\), \\(\\beta\\) y \\(\\gamma\\) y empleamos software para obener los valores de las probabilidad usando las características individuales \\(x_1\\) y \\(x_2\\). Luego podemos obtener el efecto marginal promedio como el promedio de los efectos marginales individuales. Alternativamente, se podría calcular el efecto marginal en valores específicos de \\(x_1\\) y \\(x_2\\), como \\(\\bar{x}_1\\) y \\(\\bar{x}_2\\).\n[3 punto] Considere ahora el modelo: \\[P(y=1│x_1  ,x_2 ,d_1)=\\Phi(x_1 '\\delta+\\pi x_2+\\rho d_1+\\nu x_2 d_1 )\\] Provea la nueva expresión para el efecto marginal de \\(x_2\\).\nEl efecto marginal es: \\[\\frac{\\partial P(y=1|x_1,x_2)}{\\partial x_2}=\\phi(x_1\\delta+\\pi x_2+\\rho d_1+  \\nu x_2d_1)(\\pi+\\nu d_1)\\]\n[2 punto] En el modelo de la parte b., ¿cómo evaluaría el efecto de un cambio en \\(d_1\\) en la probabilidad? Provea una expresión para este efecto.\nDado que \\(d_1\\) es una variable dicotómica, el efecto de \\(d_1\\) se mide como la diferencia en probabilidad cuando \\(d_1=1\\) y cuando \\(d_1=0\\):\n\\[P(y=1|x_1,x_2,d_1=1)-P(y=1|x_1,x_2,d_1=0)=\\phi(x_1\\delta+(\\pi+\\nu)x_2+\\rho)-\\phi(x_1\\delta+\\pi x_2)\\]\nPodemos estimar este cambio en probabilidad para cada individuo de la muestra y luego obtener un promedio de los cambios en probabilidad. Por ejemplo, supongamos que estudiamos la probabilidad de estar empleado y que \\(d_1\\) es la pertenencia o no a un sindicato. Para cada individuo en la muestra obtemeos el cambio en probabilidad que resulta de que \\(d_1\\) pase de 1 a 0."
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-1",
    "href": "tareas/tarea-1-respuestas.html#pregunta-1",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Considere el problema de regresión no lineal en el que la variable dependiente escalar \\(y\\) tiene una media condicional \\(E(y_i)=g(x_i,\\beta)\\), siendo \\(g(\\cdot)\\) una función no lineal. Suponga que:\n\nEl proceso generador de datos es \\(y_i=g(x_i,\\beta_0)+u_i\\).\nEn el proceso generador de datos \\(E(u_i|x_i)=0\\) y \\(E(uu'|X)=\\Omega\\), donde \\(\\Omega_{0,ij}=\\sigma_{ij}\\).\nLa función \\(g(\\cdot)\\) satisface \\(g(x, \\beta^{(1)})=g(x, \\beta^{(2)})\\) si y solo si \\(\\beta^{(1)}=\\beta^{(2)}\\).\nLa matriz \\(A_0\\) existe y es finita y no singular y donde \\(A_0=p\\lim\\frac{1}{N}\\sum_{i=1}^{N}\\left.\\frac{\\partial g_i}{\\partial \\beta}\\right|_{\\beta_0}\\left.\\frac{\\partial g_i}{\\partial \\beta'}\\right|_{\\beta_0}=p\\lim\\frac{1}{N}\\left.\\frac{\\partial g'}{\\partial \\beta}\\frac{\\partial g'}{\\partial \\beta'}\\right|_{\\beta_0}\\)\n\\(N^{-1/2}\\sum_{i=1}^N \\left.\\frac{\\partial g_i}{\\partial \\beta}u_i \\right|_{\\beta_0}\\xrightarrow{d}\\mathcal{N}(0,B_0)\\), donde \\(B_0=p\\lim \\frac{1}{N}\\sum_{i=1}^{N}\\sum_{j=1}^{N}\\sigma_{ij}\\left.\\frac{\\partial g_i}{\\partial \\beta}\\frac{\\partial g_i}{\\partial \\beta'}\\right|_{\\beta_0}=p\\lim\\frac{1}{N}\\left.\\frac{\\partial g'}{\\partial \\beta}\\Omega_0 \\frac{\\partial g}{\\partial \\beta'}\\right|_{\\beta_0}\\).\nRespuestas: ver proposición 5.6 en CT.\n\n\n[5 puntos] Plantee el problema de optimización para la minimización de la suma de los errores cuadráticos y obtenga las condiciones de primer orden.\n[10 puntos] Pruebe que \\(\\hat{\\beta}_{MCNL}\\), el estimador de mínimos cuadrados no lineales (MCNL) y definido como una raíz de las condiciones de primer orden, es consistente para \\(\\beta_0\\).\n[10 puntos] Derive una expresión para \\(\\sqrt{N}(\\hat{\\beta}_{MCNL}-\\beta_0)\\) y pruebe que \\(\\sqrt{N}(\\hat{\\beta}_{MCNL}-\\beta_0)\\xrightarrow{d}\\mathcal{N}(0,A_0^{-1}B_0A_0^{-1})\\). Tip: utilice una expansión de Taylor exacta de primer orden.\n[5 puntos] ¿Cómo estimaría \\(V(\\hat{\\beta}_{MCNL})\\)?}"
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-2",
    "href": "tareas/tarea-1-respuestas.html#pregunta-2",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Suponga que está interesado en una variable aleatoria que tiene una distribución Bernoulli con parámetro \\(p\\). La función de densidad está definida como:\n\\[f(x_;p)=\\left\\{\\begin{array} .1 & \\text{con probabilidad } p \\\\ 0 & \\text{con probabilidad } 1-p \\end{array} \\right.\\] Suponga que tiene una muestra de \\(N\\) observaciones independientes e idénticamente distribuidas.\n\n[4 puntos] Plantee la función de log verosimilitud del problema.\nPodemos escribir la función de densidad para la \\(i\\)-ésima observación como\n\\[f(x_i;p)=p^{x_i}(1-p)^{(1-x_i)}\\]\nPor tanto, la función de verosimilitud es\n\\[L_N(p)=\\prod_{i=1}^N f(x;p)=\\prod_{i=1}^N p^{x_i}(1-p)^{(1-x_i)} = p^{\\sum_{i=1}^N x_i}(1-p)^{N-\\sum_{i=1}^N x_i}\\]\nY la función de log verosimilitud será\n\\[\\mathcal{L_N(p)}=\\ln{L_N(p)}=\\sum x_i \\ln(p)-(N-\\sum x_i)\\ln(1-p)\\]\n[4 puntos] Obtenga las condiciones de primer orden y resuelva para \\(\\hat{p}\\).\nDerivando \\(\\mathcal{L}_N\\) con respecto a \\(p\\) obtenemos la condición de primer orden:\n\\[\\frac{d\\mathcal{L}_N(p)}{d p}=\\frac{\\sum x_i}{p}-\\frac{N-\\sum x_i}{1-p}=0\\]\nY resolviendo, obtenemos el estimador de máxima verosimilitud \\[\\hat{p}_{MV}=\\bar{x}\\] es decir, la media muestral.\n[2 puntos] ¿Cuál es la media y la varianza del estimador de máxima verosimilitud que ha encontrado?\nObtenemos directamente la media \\[E(\\hat{p}_{MV})=E(\\bar{x})=\\frac{1}{N}E\\left(\\sum x_i\\right)=\\frac{1}{N}N p=p\\]\nMientras que la varianza es \\[V(\\hat{p}_{MV})=\\frac{1}{N^2}V\\left(\\sum x_i\\right)=\\frac{p(1-p)}{N}\\]"
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-3",
    "href": "tareas/tarea-1-respuestas.html#pregunta-3",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Considere el modelo logit:\n\\[f(y_i|x_i;\\theta_0)=\\left\\{ \\begin{array} .1 & \\frac{\\exp\\{x_i'\\theta_0\\}}{1+\\exp\\{x_i'\\theta_0\\}}  \\\\ 0 &  \\frac{1}{1+\\exp\\{x_i'\\theta_0\\}} \\end{array} \\right.\\] donde \\(x_i\\) es un vector de variables explicativas, \\(\\theta_0\\) y es el vector de parámetros poblacional. Asuma que dispone de observaciones \\((y_i,x_i)\\) que son iid.\n\n[5 puntos] Escriba la función de log verosimilitud condicional para la observación \\(i\\).\nEs conveniente escribir el problema en término de \\(\\Lambda (x_i'\\theta_0) \\equiv \\frac{\\exp\\{x_i'\\theta_0\\}}{1+\\exp\\{x_i'\\theta_0\\}}\\). Así, la función de verosimilitud para la observación \\(i\\) es:\n\\[f(y_i|x_i;\\theta_0)=\\Lambda (x_i'\\theta_0)^{y_i}(1-\\Lambda (x_i'\\theta_0))^{(1-y_i)}\\]\nTomando logs, la función de log verosimilitud es:\n\\[\\mathcal{l}(y_i|x_i,\\theta)=\\ln f(y_i|x_i;\\theta)=y_i\\ln \\Lambda (x_i'\\theta)+(1-y_i)(1-\\Lambda (x_i'\\theta))\\]\n[5 puntos] Encuentre el vector score para la observación \\(i\\).\nEl vector score es el vector de primeras derivadas parciales de la log verosimilitud. Un pequeño truco facilita las cosas. Se puede mostrar que \\(\\Lambda (\\cdot)'=\\Lambda (\\cdot)(1-\\Lambda (\\cdot))\\). Entonces:\n\\[\\frac{\\partial \\mathcal{l}_i}{\\partial\\theta}=y_i \\frac{1}{\\Lambda (x_i'\\theta)}\\Lambda (x_i'\\theta)(1-\\Lambda (x_i'\\theta))x_i+(1-y_i)\\frac{1}{1-\\Lambda (x_i'\\theta)}\\Lambda (x_i'\\theta)(1-\\Lambda (x_i'\\theta))x_i\\]\nSimplificando:\n\\[\\frac{\\partial \\mathcal{l}_i}{\\partial\\theta}=(y_i-\\Lambda (x_i'\\theta))x_i \\equiv s(y_i,x_i;\\theta)\\]\n[5 puntos] Encuentre la hesiana de la función de log verosimilitud con respecto a \\(\\mathbf{\\theta}\\).\nProcedemos a derivar el score con respecto a \\(\\theta'\\):\n\\[H(y_i,x_i;\\theta)\\equiv \\frac{\\partial s(y_i,x_i;\\theta)}{\\partial \\theta'}= -\\Lambda(x_i'\\theta)(1-\\Lambda(x_i'\\theta))x_ix_i'\\]\n[5 puntos] Obtenga la matriz de información para la observación \\(i\\).\nLa matriz de información es \\(E(s(y_i,x_i;\\theta_0)s(y_i,x_i;\\theta_0)'|x_i)\\)\n\\[I(\\theta_0)=E((y_i-\\Lambda(x_i'\\theta_0))^2x_ix_i')\\]"
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-4",
    "href": "tareas/tarea-1-respuestas.html#pregunta-4",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Suponga una variable aleatoria \\(X_i\\) con distribución desconocida. Sin embargo, sí conocemos que \\(E(X)=\\mu=54\\) y que \\(\\sqrt{V(X)}=\\sigma=6\\). Suponga que se recolecta una muestra de 50 observaciones.\n\n[2 punto] ¿Cuál es la distribución asintótica de la media muestral \\(\\bar{X}\\)?\nSi se puede aplicar un teorema de límite central a la media muestral, sabemos que la nueva variable hereda la media de \\(X_i\\) y la desviación estándar es la desviación estándar de \\(X_i\\) dividida por la raíz del tamaño de la muestra. Es decir:\n\\[\\bar{X}\\sim \\mathcal{N}(54, 6^2/50)\\]\n[4 punto] ¿Cuál es la probabilidad de que \\(\\bar{X}&gt;58\\)?\nSabemos que \\(\\frac{\\bar{X}-54}{6/\\sqrt{50}}\\sim\\mathcal{N}(0,1)\\), por tanto:\n\\[P(\\bar{X}&gt;58)=P\\left(z&gt;\\frac{58-54}{6/\\sqrt{50}}\\right)=P(z&gt;4.714045)=1-\\Phi(4.714045)\\]\nCalculamos la probabilidad usando pnorm, que nos da la función de distribución. La probabilidad es un número muy pequeño:\n\n1-pnorm((58-54)/(6/sqrt(50)), mean = 0, sd = 1)\n\n[1] 1.214234e-06\n\n\n[2 punto] ¿Cuál es la probabilidad de que una observación elegida al azar sea tal que \\(X_i&gt;58\\)?\nEs imposible de determinar porque no sabemos la distribución de \\(X_i\\). Esto es algo muy conveniente de los TLC, pues nos permiten hacer afirmaciones sobre la media muestral sin saber la distribución de la que provienen las observaciones. Solo necesitamos que se cumplan las condiciones sobre las \\(X_i\\) para aplicar los TLC.\n[2 punto] Provea un intervalo de confianza de 99% para la media muestral.\nPor un lado, sabemos que la variable aleatoria \\(Z=\\frac{\\bar{X}-\\mu}{\\sigma/\\sqrt{N}}\\) tendrá una distribución \\(\\mathcal{N}(0,1)\\). Por otro lado, queremos obtener \\(P(-z_{\\alpha/2}&lt;Z&lt;z_{\\alpha/2})=0.99\\). Manipulando, obtenemos una expresión para el intervalo de confianza:\n\\[\\left(\\bar{X}-z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{N}},\\bar{X}+z_{\\alpha/2}\\frac{\\sigma}{\\sqrt{N}}\\right)\\]\nEn nuestro caso, el intervalo es:\n\\[P\\left(\\bar{X}\\pm 2.5758\\times(6/\\sqrt{50})\\right)=0.99\\]\ndonde obtenemos el 2.5758 como:\n\nqnorm(0.995)\n\n[1] 2.575829\n\n\nqnorm es la función cuantil y está definida como la función inversa de la función de distribución. La función cuantil da el valor de \\(x\\) tal que \\(F(x)=P(X \\leq x)=p\\).\nEntonces, el intervalo de confianza es: \\[P(\\bar{X}\\pm 2.185664)=0.99\\]"
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-5",
    "href": "tareas/tarea-1-respuestas.html#pregunta-5",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "En esta pregunta mostraremos los alcances de los teoremas del límite central. Para esto, generaremos muchas muestras de tamaño \\(N\\) con una distribución \\(Bernoulli\\) con probabilidad de éxito \\(p=0.7\\). Recuerde que cuando realice simulaciones, siempre debe fijar una semilla al inicio para poder replicar su trabajo.\n\n[2 puntos] ¿Cuál es la media y la varianza de una variable aleatoria \\(y_i \\sim Bernoulli(0.3)\\)?\nPara una variable que se distribuye \\(Bernoulli(p)\\), la media es \\(p\\) y la varianza es \\(p(1-p)\\). Para este caso, \\(E(y_i)=0.7\\) y \\(V(y_i)=0.7*0.3=0.21\\).\n[2 puntos] Si \\(y_i\\) son iid y podemos aplicar un teorema de límite central, ¿cuál es la distribución teórica de \\(\\bar{y}\\) cuando \\(N\\to\\infty\\)?\nObtenemos el valor esperado y la varianza de \\(\\bar{y}\\):\n\\[E(\\bar{y})=\\frac{1}{N}E(\\sum_i y_i)  = E(y_i)=p\\]\n\\[V(\\bar{y})=\\frac{1}{N^2}V(\\sum_i y_i) = \\frac{1}{N}V(y_i)=\\frac{p(1-p)}{N}\\]\nEntonces, un TLC nos daría las condiciones para que:\n\\[\\frac{\\bar{y}-0.7}{\\sqrt{0.21/N}}\\sim\\mathcal{N}(0, 1)\\]\n[5 puntos] Realice el siguiente procedimiento \\(J=1,000\\) veces. Obtenga una muestra de tamaño \\(N=3\\) a partir de la distribución \\(Bernoulli(0.7)\\) y calcule la media muestral \\(\\bar{y}\\). Coleccione las \\(J\\) medias muestrales y luego grafique un histograma de las medias muestrales obtenidas junto con una curva teórica normal con la media y varianza obtenida en la parte b. Comente sobre lo que observa.\n\nset.seed(921)\nreps &lt;- 1000\nn &lt;- 3\np &lt;- 0.7\nv &lt;- p*(1-p)/n\n\nymedias3 &lt;- numeric(reps)\nfor (i in 1:reps){\n sample &lt;- rbinom(n, 1, p)\n ymedias3[i]&lt;-mean(sample)\n}\n\nGraficamos junto con una densidad \\(N(0.7, \\sqrt{0.21/3})\\):\n\nhist(ymedias3, breaks=20, prob=TRUE, \n     xlab=\"Medias\")\ncurve(dnorm(x, mean=p, sd=sqrt(v)), \n      col=\"darkblue\", lwd=2, add=TRUE, yaxt=\"n\")\n\n\n\n\n\n\n\n\nEl histograma no se parece nada a la curva normal.\n[3 puntos] Repita lo realizado en la parte b., ahora con \\(N=15\\). Comente sobre lo que observa.\n\nreps &lt;- 1000\nn &lt;- 15\np &lt;- 0.7\nv &lt;- p*(1-p)/n\n\nymedias15 &lt;- numeric(reps)\nfor (i in 1:reps){\n sample &lt;- rbinom(n, 1, p)\n ymedias15[i]&lt;-mean(sample)\n}\n\nGraficamos junto con una densidad \\(N(0.7, \\sqrtt{0.21/15})\\):\n\nhist(ymedias15, breaks=20, prob=TRUE)\ncurve(dnorm(x, mean=p, sd=sqrt(v)), \n      col=\"darkblue\", lwd=2, add=TRUE, yaxt=\"n\")\n\n\n\n\n\n\n\n\nEl histograma comienza a tener una forma normal.\n[3 puntos] Repita lo realizado en la parte b., ahora con \\(N=1,500\\). Comente sobre lo que observa.\n\n#|echo: true\n\nreps &lt;- 1000\nn &lt;- 1500\np &lt;- 0.7\nv &lt;- p*(1-p)/n\n\nymedias1500 &lt;- numeric(reps)\nfor (i in 1:reps){\n sample &lt;- rbinom(n, 1, p)\n ymedias1500[i]&lt;-mean(sample)\n}\n\nGraficamos junto con una densidad \\(N(0.7, \\sqrt{0.21/1500})\\):\n\nhist(ymedias1500, breaks=20, prob=TRUE, \n     xlab=\"Medias\")\ncurve(dnorm(x, mean=p, sd=sqrt(v)), \n      col=\"darkblue\", lwd=2, add=TRUE, yaxt=\"n\")\n\n\n\n\n\n\n\n\nEl histograma se parece ya a la curva normal. Podrían repetir este ejercicio con un tamaño de muestra más grande incluso y ver qué sucede.\n[5 puntos] ¿Cómo usaría este ejercicio con palabras simples para explicar a una persona que no sabe mucho de estadística sobre la importancia de los teoremas de límite central?\nUn TLC nos permite hacer afirmaciones sobre la distribución de un estadístico. Un estadístico es un resumen de los datos, por lo que nos interesa usar dichos estadísticos para describir características de los fenómenos que estudiamos usando datos. Queremos saber cosas como lo que esperamos en promedio que suceda con una variable, o qué tanta variabilidad dicha variable tendrá en la población. Con un TLC podemos hacer afirmaciones sobre cómo lucen promedios muestrales de la variable que estudiamos cuando tenemos suficientes observaciones. Nos dice en particular que va a tener una distribución normal."
  },
  {
    "objectID": "tareas/tarea-1-respuestas.html#pregunta-6",
    "href": "tareas/tarea-1-respuestas.html#pregunta-6",
    "title": "Respuestas a la tarea 1",
    "section": "",
    "text": "Sea \\(x_1\\) un vector de variables continuas, \\(x_2\\) una variable continua y \\(d_1\\) una variable dicotómica. Considere el siguiente modelo probit: \\[P(y=1│x_1,x_2 )=\\Phi(x_1'\\alpha+\\beta x_2+\\gamma x_2^2 )\\]\n\n[5 punto] Provea una expresión para el efecto marginal de \\(x_2\\) en la probabilidad. ¿Cómo estimaría este efecto marginal?\nEl efecto marginal de interés es:\n\\[\\frac{\\partial P(y=1|x_1,x_2)}{\\partial x_2}=\\phi(x_1\\alpha+\\beta x_2+\\gamma x_2^2)(\\beta+2\\gamma x_2)\\]\nPara estimarlo, usamos máxima verosimilitud para obtener estimadores consistentes de \\(\\alpha\\), \\(\\beta\\) y \\(\\gamma\\) y empleamos software para obener los valores de las probabilidad usando las características individuales \\(x_1\\) y \\(x_2\\). Luego podemos obtener el efecto marginal promedio como el promedio de los efectos marginales individuales. Alternativamente, se podría calcular el efecto marginal en valores específicos de \\(x_1\\) y \\(x_2\\), como \\(\\bar{x}_1\\) y \\(\\bar{x}_2\\).\n[3 punto] Considere ahora el modelo: \\[P(y=1│x_1  ,x_2 ,d_1)=\\Phi(x_1 '\\delta+\\pi x_2+\\rho d_1+\\nu x_2 d_1 )\\] Provea la nueva expresión para el efecto marginal de \\(x_2\\).\nEl efecto marginal es: \\[\\frac{\\partial P(y=1|x_1,x_2)}{\\partial x_2}=\\phi(x_1\\delta+\\pi x_2+\\rho d_1+  \\nu x_2d_1)(\\pi+\\nu d_1)\\]\n[2 punto] En el modelo de la parte b., ¿cómo evaluaría el efecto de un cambio en \\(d_1\\) en la probabilidad? Provea una expresión para este efecto.\nDado que \\(d_1\\) es una variable dicotómica, el efecto de \\(d_1\\) se mide como la diferencia en probabilidad cuando \\(d_1=1\\) y cuando \\(d_1=0\\):\n\\[P(y=1|x_1,x_2,d_1=1)-P(y=1|x_1,x_2,d_1=0)=\\phi(x_1\\delta+(\\pi+\\nu)x_2+\\rho)-\\phi(x_1\\delta+\\pi x_2)\\]\nPodemos estimar este cambio en probabilidad para cada individuo de la muestra y luego obtener un promedio de los cambios en probabilidad. Por ejemplo, supongamos que estudiamos la probabilidad de estar empleado y que \\(d_1\\) es la pertenencia o no a un sindicato. Para cada individuo en la muestra obtemeos el cambio en probabilidad que resulta de que \\(d_1\\) pase de 1 a 0."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html",
    "href": "tareas/tarea-2-respuestas.html",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "Use los datos en el archivo motral2012.csv, que incluye una muestra de individuos con sus características socioeconómicas. Nos interesa conocer los factores que afectan la probabilidad de que los individuos tengan ahorros formales. Considere lo siguiente sobre las opciones de ahorro de los entrevistados, contenida en la variable p14:\n\np14 igual a 1 significa cuentas de ahorro bancarias\np14 igual a 2 significa cuenta de inversión bancaria\np14 igual a 3 significa inversiones en bienes raíces\np14 igual a 4 significa caja de ahorro en su trabajo\np14 igual a 5 significa caja de ahorro con sus amigos\np14 igual a 6 significa tandas\np14 igual a 7 significa que ahorra en su casa o alcancías\np14 igual a 8 significa otro lugar\np14 NA significa que no ahorra\n\n\n[2 puntos] Comience generando una variable binaria ahorra_inf que tome el valor de 1 para las personas que ahorran en instrumentos informales y 0 en otro caso. Se consideran instrumentos informales las cajas de ahorro en el trabajo o amigos, las tandas y el ahorro en casa o alcancías . Construya también la variable mujer que tome el valor de 1 cuando sex toma el valor de 2 y 0 en otro caso. Luego, estime un modelo de probabilidad lineal que relacione ahorra_inf como variable dependiente con eda (edad), anios_esc (años de escolaridad) y mujer. Reporte los errores que asumen homocedasticidad y los errores robustos a heteroscedasticidad. ¿Qué observa respecto a los errores y por qué sucede?\nGeneramos variables:\n\ndata.financiero &lt;- read_csv(\"../files/motral2012.csv\",\n                          locale = locale(encoding = \"latin1\")) %&gt;%\n  clean_names() %&gt;% \n  mutate(ahorra_inf = case_when(p14 %in% c(4,5,6,7) ~ 1,\n                                .default = 0),\n         mujer=ifelse(sex==2,1,0))\n\nEstimamos el modelo lineal y obtenemos la matriz de varianzas robusta usando vcovHC:\n\nsummary(reg.lineal &lt;- lm(ahorra_inf ~ eda + anios_esc + mujer,\n                         data = data.financiero))\n\n\nCall:\nlm(formula = ahorra_inf ~ eda + anios_esc + mujer, data = data.financiero)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.3365 -0.2580 -0.1844 -0.1092  0.9467 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.4519266  0.0254686  17.744   &lt;2e-16 ***\neda         -0.0063753  0.0005491 -11.610   &lt;2e-16 ***\nanios_esc   -0.0006780  0.0012186  -0.556    0.578    \nmujer       -0.0006674  0.0113305  -0.059    0.953    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4107 on 5260 degrees of freedom\nMultiple R-squared:  0.02507,    Adjusted R-squared:  0.02452 \nF-statistic: 45.09 on 3 and 5260 DF,  p-value: &lt; 2.2e-16\n\n#Matriz robusta\nv_rob &lt;- vcovHC(reg.lineal, type = \"HC0\")\nse_rob    &lt;- sqrt(diag(v_rob))\n\nPresentamos usando modelsummary.\nmodelsummary(list(reg.lineal, reg.lineal),\n             vcov = c(\"iid\", \"HC0\"),\n             stars = c('*'=.1, '**'=.05, '***'=.01))\n \n\n  \n    \n    \n    tinytable_je4k9ncycm5363q2aswf\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n                (2)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)\n                  0.452*** \n                  0.452*** \n                \n                \n                             \n                  (0.025)  \n                  (0.029)  \n                \n                \n                  eda        \n                  -0.006***\n                  -0.006***\n                \n                \n                             \n                  (0.001)  \n                  (0.001)  \n                \n                \n                  anios_esc  \n                  -0.001   \n                  -0.001   \n                \n                \n                             \n                  (0.001)  \n                  (0.002)  \n                \n                \n                  mujer      \n                  -0.001   \n                  -0.001   \n                \n                \n                             \n                  (0.011)  \n                  (0.011)  \n                \n                \n                  Num.Obs.   \n                  5264     \n                  5264     \n                \n                \n                  R2         \n                  0.025    \n                  0.025    \n                \n                \n                  R2 Adj.    \n                  0.025    \n                  0.025    \n                \n                \n                  AIC        \n                  5575.3   \n                  5575.3   \n                \n                \n                  BIC        \n                  5608.1   \n                  5608.1   \n                \n                \n                  Log.Lik.   \n                  -2782.626\n                  -2782.626\n                \n                \n                  F          \n                  45.091   \n                  46.854   \n                \n                \n                  RMSE       \n                  0.41     \n                  0.41     \n                \n                \n                  Std.Errors \n                  IID      \n                  HC0      \n                \n        \n      \n    \n\n    \n\n  \n\n\nEn en problema binario, la media condicional está bien planteada. Y dado que la densidad pertenece a la familia lineal exponencial, basta con que la media condicional esté bien planteada para la consistencia de \\(\\beta\\). Sin embargo, en el caso de los modelos binarios, la varianza condicional también está siempre bien planteada, pues \\(V(y)=p(1-p)\\). Esto implica que no hay ninguna ganancia en usar la matriz de varianzas robustas. Ver CT, p. 469 para una discusión.\n[3 puntos] ¿Cuál es el efecto en la probabilidad de ahorrar informalmente si los años de educación se incrementan en una unidad, pasando de 4 a 5 años de educación?\nUna reducción de 0.1 puntos porcentuales (0.001/100), estadísticamente no significativa.\n[2 puntos] Realice una prueba de significancia conjunta de eda y anios_esc. ¿Qué concluye?\nPodemos usar la función linearHypothesis:\n\ncar::linearHypothesis(reg.lineal, c(\"eda=0\", \"anios_esc=0\"))\n\nLinear hypothesis test\n\nHypothesis:\neda = 0\nanios_esc = 0\n\nModel 1: restricted model\nModel 2: ahorra_inf ~ eda + anios_esc + mujer\n\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1   5262 909.91                                  \n2   5260 887.14  2    22.773 67.512 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nConcluimos que no hay evidencia para afirmar que \\(\\beta_{eda}=\\beta_{anios\\_esc}=0\\).\n[3 puntos] Estime un modelo logit relacionando las mismas variables. Use la función avg_slopes del paquete marginaleffects para obtener los efectos marginales promedio de un cambio en cada uno de los regresores. ¿Por qué difiere la magnitud de este efecto marginal con respecto a la parte b.?\nEstimamos el modelo probit:\n\nreg.logit &lt;- glm(ahorra_inf ~ eda + anios_esc + mujer,\n                  family = binomial(link = \"logit\"),\n                  data = data.financiero)\n\nsummary(reg.logit)$coef\n\n                Estimate  Std. Error      z value     Pr(&gt;|z|)\n(Intercept)  0.081021587 0.150793629   0.53730113 5.910596e-01\neda         -0.038339619 0.003385824 -11.32357193 1.003001e-29\nanios_esc   -0.003787198 0.007627194  -0.49653889 6.195143e-01\nmujer       -0.001539617 0.067250054  -0.02289392 9.817349e-01\n\n\nNoten que el signo de los coeficientes coinciden con el promedio de los efectos marginales:\n\navg_slopes(reg.logit)\n\n\n      Term Contrast  Estimate Std. Error        z Pr(&gt;|z|)     S    2.5 %\n anios_esc    dY/dX -0.000638   0.001285  -0.4966    0.619   0.7 -0.00316\n eda          dY/dX -0.006459   0.000554 -11.6533   &lt;0.001 101.8 -0.00755\n mujer        1 - 0 -0.000259   0.011331  -0.0229    0.982   0.0 -0.02247\n   97.5 %\n  0.00188\n -0.00537\n  0.02195\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nEl promedio del efecto marginal de un cambio en los años de educación es de una reducción de 0.06 puntos porcentuales.\n[2 puntos] Ahora estime el efecto marginal en la media para eda y anios_esc y para los hombres, usando la función slopes. ¿Por qué difiere la magnitud de este efecto marginal respecto a la parte b. y la d.?\nPara obtener los efectos marginales evaluados en algún valor \\(X_i\\) de los covariables, debemos especificar estos valores usando datagrid:\n\navg_slopes(reg.logit,\n           newdata = datagrid(eda = mean(data.financiero$eda),\n                              anios_esc = mean(data.financiero$anios_esc),\n                              mujer = 1))\n\n\n      Term Contrast  Estimate Std. Error        z Pr(&gt;|z|)    S    2.5 %\n anios_esc    dY/dX -0.000639   0.001287  -0.4963    0.620  0.7 -0.00316\n eda          dY/dX -0.006465   0.000575 -11.2472   &lt;0.001 95.1 -0.00759\n mujer        1 - 0 -0.000260   0.011346  -0.0229    0.982  0.0 -0.02250\n   97.5 %\n  0.00188\n -0.00534\n  0.02198\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nEl efecto marginal de un cambio en los años de escolaridad evaluados en la media de los años de educación y edad, para las mujeres, es de -0.06 puntos. Esto difiere del modelo lineal porque en el modelo lineal los efectos marginales son constantes, mientras que los efectos marginal del modelo no lineal dependen del punto de evaluación. También difiere de los efectos marginales promedio pues aquí solo hemos calculado el efecto marginal una sola vez, para un valor \\(X_i\\), mientras que el promedio de efectos marginales implica calcular el efecto marginal para cada individuo y luego obtener el promedio.\nEn clase les pregunté cómo estimarían el error estándar de los cambios marginales y brevemente mencioné que una forma muy usada es el Método Delta, el cual se basa en que los efectos marginales son funciones no lineales de los parámetros. Esto es lo que efectivamente se usa en la función avg_slopes para obtener los errores estándar y los intervalos de confianza. Aquí pueden leer al respecto.\n[3 puntos] Provea una expresión para la maginitud de:\n\n\\[\\frac{\\frac{\\partial P(y=1)}{\\partial \\; anios\\_esc}}{\\frac{\\partial P(y=1)}{\\partial \\; eda}}\\]\nLa razón de efectos marginales es la razón de coeficientes:\n\\[\\frac{\\frac{\\partial P(y=1)}{\\partial \\; anios\\_esc}}{\\frac{\\partial P(y=1)}{\\partial \\; eda}}=\\frac{\\beta_{anios\\_esc}}{\\beta_{eda}}=\\frac{0.0038 }{0.0383}\\]\n\n\n\nAhora estimará un modelo multinomial empleando los mismos datos en motral2012.csv. El propósito será ahora estudiar los factores relevantes para predecir la forma de ahorro que tienen las personas que ahorran.\n\n[2 puntos] Genere una variable categórica llamada ahorro que sea igual a 1 cuando p14 sea igual a 1 o 2, igual a 2 cuando p14 sea igual a 7, e igual a 3 cuando p14 sea igual a 3, 4, 5, 6 u 8. Haga que esa variable sea missing cuando p14 sea missing. Posteriormente, convierta esta nueva variable en una de factores de forma que el valor 1 tenga la etiqueta “Banco”, el valor 2 tenga la etiqueta “Casa” y el valor 3 tenga la etiqueta “Otro”.\nConstruimos la variable dependiente:\n\ndata.financiero &lt;- read_csv(\"../files/motral2012.csv\",\n                            locale = locale(encoding = \"latin1\")) %&gt;%\n  clean_names() %&gt;% \n  mutate(ahorro=NA) %&gt;% \n  mutate(ahorro=ifelse(p14%in%c(1,2),1,ahorro)) %&gt;%\n  mutate(ahorro=ifelse(p14==7,2,ahorro)) %&gt;% \n  mutate(ahorro=ifelse(p14%in%c(3,4,5,6,8),3,ahorro)) %&gt;% \n  mutate(ahorro=factor(ahorro,\n                   levels=c(1,2,3), labels=c(\"Banco\",\"Casa\",\"Otro\"))) %&gt;%\n  mutate(mujer=ifelse(sex==2,1,0))\n\n[4 puntos] Estime un modelo logit multinomial (regresores invariantes a la alternativa) con la opción de ahorro como variable dependiente y los mismos regresores de la pregunta 1. Hay varios paquetes para hacer esto, pero recomiendo usar la función multinom del paquete nnet. ¿Qué puede decir sobre el coeficiente de años de educación en la alternativa “Casa”?\nUsamos multinom para estimar el modelo logit multinomial:\n\nmultilogit &lt;- nnet::multinom(ahorro~ eda + anios_esc + mujer,\n                              data=data.financiero)\n\n# weights:  15 (8 variable)\ninitial  value 2727.854313 \niter  10 value 2546.085070\nfinal  value 2545.712541 \nconverged\n\nsummary(multilogit)\n\nCall:\nnnet::multinom(formula = ahorro ~ eda + anios_esc + mujer, data = data.financiero)\n\nCoefficients:\n     (Intercept)          eda   anios_esc       mujer\nCasa    3.026880 -0.052310196 -0.14829719  0.09265405\nOtro    0.206704 -0.003501367 -0.04628175 -0.06459305\n\nStd. Errors:\n     (Intercept)         eda  anios_esc      mujer\nCasa   0.2487107 0.005207439 0.01355319 0.09956544\nOtro   0.2476498 0.004964123 0.01285100 0.09995715\n\nResidual Deviance: 5091.425 \nAIC: 5107.425 \n\n\nEn el logit multinominal (regresores invariantes) el coeficiente se interpreta con respecto a una categoría base. En este caso, la categoría base es Banco. El modelo implica que la probabilidad de ahorrar en casa disminuye con un año más de educación, en comparación con la probabilidad de ahorrar en el banco. En particular, sabemos que podemos escribir el log del cociente de la probabilidad de las categorías \\(j\\) y \\(k\\) sean escogidas, normalizando \\(k\\) a ser la base, como:\n\\[\\ln\\left(\\frac{P(y=Casa)}{P(y=Banco)}\\right)=x'\\beta=\\beta_0+\\beta_1 edad + \\beta_2 educación + \\beta_3 mujer \\]\nEs decir, un año más de educación se asocia con una reducción en el log de la razón de momios de 0.15.\n[4 puntos] Calcule los efectos marginales promedio sobre la probabilidad de ahorrar en el banco. Al considerar el cambio en la probabilidad para el caso de las mujeres (cuando la variable mujer pasa de 0 a 1), ¿de qué tamaño es el efecto predicho en la probabilidad de ahorrar en el banco?\nUsamos avg_slopes:\n\navg_slopes(multilogit)\n\n\n Group      Term Contrast Estimate Std. Error       z Pr(&gt;|z|)    S    2.5 %\n Banco anios_esc    dY/dX  0.02285   0.002381   9.595   &lt;0.001 70.0  0.01818\n Banco eda          dY/dX  0.00657   0.000935   7.027   &lt;0.001 38.8  0.00474\n Banco mujer        1 - 0 -0.00343   0.019432  -0.177    0.860  0.2 -0.04152\n Casa  anios_esc    dY/dX -0.02512   0.002231 -11.262   &lt;0.001 95.3 -0.02949\n Casa  eda          dY/dX -0.00982   0.000860 -11.422   &lt;0.001 98.0 -0.01151\n Casa  mujer        1 - 0  0.02271   0.017662   1.286    0.199  2.3 -0.01191\n Otro  anios_esc    dY/dX  0.00228   0.002174   1.046    0.295  1.8 -0.00199\n Otro  eda          dY/dX  0.00325   0.000842   3.863   &lt;0.001 13.1  0.00160\n Otro  mujer        1 - 0 -0.01927   0.017549  -1.098    0.272  1.9 -0.05367\n   97.5 %\n  0.02751\n  0.00840\n  0.03465\n -0.02075\n -0.00814\n  0.05732\n  0.00654\n  0.00490\n  0.01512\n\nColumns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  probs \n\n\nEl efecto de ser mujer es de una reducción de 0.3 puntos en la probabilidad de ahorrar en el banco al estimar el promedio de los efectos marginales.\n[3 puntos] Calcule los cocientes de riesgo relativo (relative risk ratios o RRR). ¿Qué significa el hecho de que el RRR asociado a ser mujer sea mayor que 1 en la alternativa “Casa”?\n\n(multilogit_rrr = exp(coef(multilogit)))\n\n     (Intercept)       eda anios_esc     mujer\nCasa   20.632752 0.9490344 0.8621748 1.0970821\nOtro    1.229619 0.9965048 0.9547729 0.9374489\n\n\nLos coeficientes en forma de RRR tienen la interpretación del cambio en el riesgo relativo que una categoría sea elegida con relación al riesgo de escoger la categoría base. En este caso, el ser mujer está asociado con una probabilidad de ahorrar en “Casa” 1.097 veces mayor de que la de ahorrar en “Banco”.\n[2 puntos] Estime nuevamente el modelo, pero ahora, especifique que la alternativa “Casa” sea la alternativa base. ¿Cómo es el RRR de la edad en la alternativa “Banco”? ¿Es esto congruente con lo que obtuvo en la parte d. de esta pregunta?\nPrimero tenemos que cambiar la base. Para esto hacemos uso de que ahorro es una variable de factores. Luego estimamos:\n\ndata.financiero &lt;- data.financiero %&gt;% \n  mutate(ahorro = relevel(ahorro, ref = \"Casa\"))\n\nmultilogit2 &lt;- nnet::multinom(ahorro ~ eda + anios_esc + mujer,\n                              data=data.financiero)\n\n# weights:  15 (8 variable)\ninitial  value 2727.854313 \niter  10 value 2552.696634\nfinal  value 2545.712541 \nconverged\n\n\nObtenemos el RRR:\n\n(multilogit2_rrr = exp(coef(multilogit2)))\n\n      (Intercept)      eda anios_esc     mujer\nBanco  0.04846638 1.053703  1.159857 0.9115111\nOtro   0.05959489 1.050020  1.107401 0.8544952\n\n\nAl cambiar la categoría base a Casa solo se modifica la interpretación relativa. En la parte d. el RRR de la edad para la opción de Casa era 0.949, es decir, si la edad se incrementa en una unidad, la probabilidad de ahorrar en Casa es 0.949 veces la de ahorrar en Banco. Con la nueva categoría base, el RRR de la edad para ahorrar en Banco es 1.054, es decir, si la edad se incrementa en un año, la probabilidad de ahorrar en Banco es 1.054 veces más probable que la probabilidad de ahorrar en Casa. La parte d. implica que \\(P(Casa)=0.949(Banco)\\). Mientras que estimando el modelo con la nueva categoría, \\(P(Banco)=1.054(Casa)\\), o \\(P(Casa)=1/1.054(Banco)\\). Empleando todos los decimales en R se puede notar que 1/1.054≅0.949 Ambos resultados son consistentes.\n\n\n\n\nOtra manera de resolver el problema del exceso de ceros que a veces nos molesta en los modelos Poisson es usar un modelo Poisson inflado en cero (CT, p. 681). La idea es introducir un proceso binario con densidad \\(f_1(\\cdot)\\) para modelar la probabilidad de que \\(y=0\\) y luego una densidad de conteo \\(f_2(\\cdot)\\). Si el proceso binario toma el valor de 0, con probabilidad \\(f_1(0)\\), entonces \\(y=0\\), pero si el proceso binario toma el valor de 1, entonces \\(y={0,1,2,\\ldots}\\). Note que podemos entonces observar ceros por dos razones, por el proceso binomial o por el conteo.\nUn modelo inflado en cero tendrá como densidad:\n\\[\ng(y)=\n\\begin{cases}\nf_1(0)+(1-f_1(0))f_2(0) & \\text{si }y=0 \\\\\n(1-f_1(0))f_2(y)& \\text{si }y\\geq 1\n\\end{cases}\n\\]\nConsidere la variable aleatoria \\(Y\\) con observaciones iid que sigue una distribución Poisson con parámetro \\(\\lambda\\). Y considere una variable un proceso binomial tal que \\(\\pi\\) es la probabilidad de que el conteo no se realice. Entonces:\n\\[\ng(y)=\n\\begin{cases}\n\\pi+(1-\\pi)f_2(0) & \\text{si }y=0 \\\\\n(1-\\pi)f_2(y)& \\text{si }y\\geq 1\n\\end{cases}\n\\]\n\n[4 puntos] Termine de especializar la expresión anterior unsando la distribución Poisson para \\(f_2(\\cdot)\\) para obtener la función de masa de probabilidad del modelo Poisson inflado en cero \\(g(y|\\lambda, \\pi)\\).\nEn el caso particular de un modelo Poisson, sabemos que \\(f_2(0)=P(Y=0)=exp(-\\lambda)\\). Definiendo la probabilidad de observar un conteo cero como \\(\\pi\\), la función de masa de probabilidad del modelo inflado en cero es:\n\\[g(y)=\n\\begin{cases}\n\\pi+(1-\\pi)exp(-\\lambda) \\quad\\text{si }y=0 \\\\\n(1-\\pi)\\frac{\\lambda^y exp(-\\lambda)}{y!} \\quad\\text{si } y \\geq1 \\\\\n\\end{cases}\n\\]\n[5 puntos] Provea una expresión para la función de verosimilitud \\(L(\\lambda,\\pi)=\\prod_{i=1}^N g(y_i|\\lambda, \\pi)\\). Una sugerencia para simplificar sus cálculos es definir una variable \\(X\\) igual al numero de veces que \\(Y_i\\) que toma el valor de cero.\nLa función de verosimilitud del problema es:\n\\[L(\\pi,\\lambda,y_i)=\\prod_i P(Y_i=y_i)\\]\nCon las formas específicas para el modelo Poisson inflado en cero:\n\\[L(\\pi,\\lambda,y_i)=\\prod_{i\\in y_i=0}\\left(\\pi+(1-\\pi)exp(-\\lambda) \\right) \\prod_{i\\in y_i&gt;0}\\left((1-\\pi)\\frac{\\lambda^{y_i} exp(-\\lambda)}{y!}\\right)\\]\nHaciendo \\(X\\) el número de veces que \\(y_i\\) toma el valor de cero, el primer producto es \\(\\left(\\pi+(1-\\pi)exp(-\\lambda) \\right)\\) elevado a la potencia \\(X\\).\n¿Cuántos términos distintos de cero quedan? Quedan \\(n-X\\). El segundo producto en la verosimilitud es:\n\\[\\left((1-\\pi)exp(-\\lambda)\\right)^{n-X}\\frac{\\lambda^{\\sum_i y_i}}{\\prod_{i\\in y_i&gt;0} y!}\\]\nLa verosimilitud es por tanto:\n\\[L(\\pi,\\lambda,y_i)=\\left(\\pi+(1-\\pi)exp(-\\lambda) \\right)^X \\left((1-\\pi)exp(-\\lambda)\\right)^{n-X}\\frac{\\lambda^{\\sum_i y_i}}{\\prod_{i\\in y_i&gt;0} y!}\\]\n[3 puntos] Provea una expresión para la log verosimilitud del problema, \\(\\mathcal{L}(\\lambda,\\pi)\\).\nDada la verosimilitud planteada en la parte anterior, la log verosimilitud es:\n\\[\\mathcal{L}(\\pi,\\lambda,y_i)=X\\ln \\left(\\pi+(1-\\pi)exp(-\\lambda) \\right)+(n-X)\\ln(1-\\pi)-(n-X)\\lambda+n\\bar{Y}\\ln (\\lambda)- \\ln\\left(\\prod_{i\\in y_i&gt;0} y! \\right)\\]\n[3 puntos] Obtenga las condiciones de primer orden que caracterizan la solución del problema de máxima verosimilitud, derivando la log verosimilitud con respecto a \\(\\lambda\\) y a \\(\\pi\\).\nTenemos dos parámetros, así que tenemos dos condiciones de primer orden. Derivando la log verosimilitud con respecto a \\(\\pi\\) obtenemos:\n\\[\\frac{\\partial \\mathcal{L}}{\\partial \\pi}=\\frac{X}{\\pi+(1-\\pi)exp(-\\lambda)}(1-exp(-\\lambda))-\\frac{n-X}{1-\\pi}=0\\]\nLa primer condición (A) es:\n\\[\\frac{X(1-exp(-\\lambda))(1-\\pi)}{\\pi+(1-\\pi)exp(-\\lambda)}=n-X\\quad\\quad\\ldots(A)\\]\nAhora derivando la log verosimilitud con respecto a \\(\\lambda\\):\n\\[\\frac{\\partial \\mathcal{L}}{\\partial \\lambda}=-\\frac{X}{\\pi+(1-\\pi)exp(-\\lambda)}(1-\\pi)exp(-\\lambda)-(n-X)+\\frac{n\\bar{Y}}{\\lambda}=0\\]\nLa segunda condición (B) es:\n\\[\\frac{X(1-\\pi)exp(-\\lambda)}{\\pi+(1-\\pi)exp(-\\lambda)}+(n-X)=\\frac{n\\bar{Y}}{\\lambda}\\quad\\quad\\ldots(B)\\]\n\\((\\hat{\\pi}_{MV},\\hat{\\lambda}_{MV})\\) son los valores de los parámetros que resulven el sistema dado por (A) y (B).\n\n\n\n\nUse los datos phd_articulos.csv, los cuales contienen información sobre el número de artículos publicados para una muestra de entonces estudiantes de doctorado. Nuestra variable de interés será el número de artículos art.\n\n[4 puntos] Estime un modelo Poisson que incluya variables dicotómicas para estudiantes mujeres (female) y para estudiantes casadas o casados (married), el número de hijos mejores de cinco años (kid5), el ranking de prestigio del doctorado (phd) y el número de artículos publicados por su mentor (mentor). Realice la estimación de la matriz de varianzas primero a partir de la varianza teórica que resulta de la igualdad de la matriz de información y luego usando una matriz de sándwich. Interprete los coeficientes estimados.\n\ndata.phd&lt;-read_csv(\"../files/phd_articulos.csv\",\n                          locale = locale(encoding =                \"latin1\"))\n\ndata.phd &lt;- data.phd %&gt;% \n  mutate(female=factor(female,\n                       levels=c('Male','Female')))\n\nmpoisson &lt;- glm(art ~ factor(female) + factor(married) + kid5 + phd + mentor,\n                family=\"poisson\",\n                data=data.phd)\n\nsummary(mpoisson)\n\n\nCall:\nglm(formula = art ~ factor(female) + factor(married) + kid5 + \n    phd + mentor, family = \"poisson\", data = data.phd)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            0.459860   0.093335   4.927 8.35e-07 ***\nfactor(female)Female  -0.224594   0.054613  -4.112 3.92e-05 ***\nfactor(married)Single -0.155243   0.061374  -2.529   0.0114 *  \nkid5                  -0.184883   0.040127  -4.607 4.08e-06 ***\nphd                    0.012823   0.026397   0.486   0.6271    \nmentor                 0.025543   0.002006  12.733  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 1817.4  on 914  degrees of freedom\nResidual deviance: 1634.4  on 909  degrees of freedom\nAIC: 3314.1\n\nNumber of Fisher Scoring iterations: 5\n\n\nPresentamos errores heterocedásticos y robustos a la heterocedasticidad. Aquí les muestro otro paquete que puede servirles para presentar resultados en trabajos y tesinas, alterntivo a stargazer, modelsummary:\n\nmodelsummary(list(mpoisson, mpoisson),\n             vcov = list('classical', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n \n\n  \n    \n    \n    tinytable_c69u71kdxs6dya8b76p9\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n                (2)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)          \n                  0.460*** \n                  0.460*** \n                \n                \n                                       \n                  (0.093)  \n                  (0.151)  \n                \n                \n                  factor(female)Female \n                  -0.225***\n                  -0.225***\n                \n                \n                                       \n                  (0.055)  \n                  (0.072)  \n                \n                \n                  factor(married)Single\n                  -0.155** \n                  -0.155*  \n                \n                \n                                       \n                  (0.061)  \n                  (0.083)  \n                \n                \n                  kid5                 \n                  -0.185***\n                  -0.185***\n                \n                \n                                       \n                  (0.040)  \n                  (0.057)  \n                \n                \n                  phd                  \n                  0.013    \n                  0.013    \n                \n                \n                                       \n                  (0.026)  \n                  (0.044)  \n                \n                \n                  mentor               \n                  0.026*** \n                  0.026*** \n                \n                \n                                       \n                  (0.002)  \n                  (0.004)  \n                \n                \n                  Num.Obs.             \n                  915      \n                  915      \n                \n                \n                  AIC                  \n                  3314.1   \n                  3314.1   \n                \n                \n                  BIC                  \n                  3343.0   \n                  3343.0   \n                \n                \n                  Log.Lik.             \n                  -1651.056\n                  -1651.056\n                \n                \n                  F                    \n                  43.333   \n                  14.855   \n                \n                \n                  RMSE                 \n                  1.84     \n                  1.84     \n                \n                \n                  Std.Errors           \n                  IID      \n                  HC3      \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nPara las variables continuas, como el número de artículos publicados por el mentor, la interpretación es el cambio en el log conteo esperado. En este caso, un artículo más publicado por el mentor incrementa el log conteo esperado en 0.026. También sabemos que los coeficientes tienen una interpretación de semielasticidad; en este caso, la semielasticidad del conteo con respecto al número de artículos publicados es 0.026. Para las variables dicotómicas, por ejemplo female, la interpretación es la diferencia entre el log conteo esperado entre mujeres y la categoría base (hombres).\n[3 puntos] Obtenga la razón de tasas de incidencia (IRR) para los coeficientes e interprete los resultados.\n\nexp(summary(mpoisson)$coef)\n\n                       Estimate Std. Error      z value Pr(&gt;|z|)\n(Intercept)           1.5838526   1.097829 1.379638e+02 1.000001\nfactor(female)Female  0.7988403   1.056132 1.636793e-02 1.000039\nfactor(married)Single 0.8562068   1.063297 7.970295e-02 1.011490\nkid5                  0.8312018   1.040943 9.977222e-03 1.000004\nphd                   1.0129051   1.026749 1.625407e+00 1.872246\nmentor                1.0258718   1.002008 3.386456e+05 1.000000\n\n\nAunque esto también puede hacerse directamente en modelsummary:\n\nmodelsummary(list(mpoisson, mpoisson),\n             exponentiate = TRUE,\n             vcov = list('classical', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n \n\n  \n    \n    \n    tinytable_i0mpf849vz0u3zucc4t9\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n                (2)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)          \n                  1.584*** \n                  1.584*** \n                \n                \n                                       \n                  (0.148)  \n                  (0.240)  \n                \n                \n                  factor(female)Female \n                  0.799*** \n                  0.799*** \n                \n                \n                                       \n                  (0.044)  \n                  (0.058)  \n                \n                \n                  factor(married)Single\n                  0.856**  \n                  0.856*   \n                \n                \n                                       \n                  (0.053)  \n                  (0.071)  \n                \n                \n                  kid5                 \n                  0.831*** \n                  0.831*** \n                \n                \n                                       \n                  (0.033)  \n                  (0.047)  \n                \n                \n                  phd                  \n                  1.013    \n                  1.013    \n                \n                \n                                       \n                  (0.027)  \n                  (0.045)  \n                \n                \n                  mentor               \n                  1.026*** \n                  1.026*** \n                \n                \n                                       \n                  (0.002)  \n                  (0.004)  \n                \n                \n                  Num.Obs.             \n                  915      \n                  915      \n                \n                \n                  AIC                  \n                  3314.1   \n                  3314.1   \n                \n                \n                  BIC                  \n                  3343.0   \n                  3343.0   \n                \n                \n                  Log.Lik.             \n                  -1651.056\n                  -1651.056\n                \n                \n                  F                    \n                  43.333   \n                  14.855   \n                \n                \n                  RMSE                 \n                  1.84     \n                  1.84     \n                \n                \n                  Std.Errors           \n                  IID      \n                  HC3      \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nLa interpretación de los coeficientes se vuelve más sencilla usando irr. Para la variable continua mentor, un artículo más publicado por el mentor está asociado con 1.026 veces más artículos publicados por el estudiante, es decir, un 2.6% más artículos. En cambio, la variable dicotómica para mujeres indica que las mujeres publican 0.8 veces el número de artículos que los hombres.\n[2 puntos] Considere ahora que las mujeres han tenido carreras profesionales más cortas que los hombres, es decir, han estado menos expuestas a la ocurrencia de los eventos publicar. Incorpore esto al análisis y reinterprete los resultados. Pista: explore la opción offeset en glm de R. La columna profage mide la duración efectiva de las carreras profesionales de cada individuo.\nEl razonamiento es que ahora queremos conocer cuál es la tasa de publicación, es decir, \\(art/profage\\). Pero como nuestro podemos Poisson solo puede manejar conteos, podemos modificar el modelo para pasar la edad de la carrera del lado derecho:\n\\[\\begin{aligned}ln(art/profage)&=x'\\beta \\\\ ln(art)&=x'\\beta+\\ln(profage) \\end{aligned}\\]\n\nmpoisson_duracion &lt;- glm(art ~\n                  factor(female) + factor(married) + kid5 + phd + mentor,\n                  offset = log(profage),\n                  family=\"poisson\",\n                  data=data.phd)\n\nsummary(mpoisson_duracion)$coef\n\n                         Estimate  Std. Error     z value      Pr(&gt;|z|)\n(Intercept)           -2.95404558 0.093812104 -31.4889600 1.230266e-217\nfactor(female)Female   0.45874678 0.054721432   8.3833109  5.145931e-17\nfactor(married)Single -0.15598278 0.061347334  -2.5426171  1.100257e-02\nkid5                  -0.18643454 0.040135522  -4.6451256  3.398696e-06\nphd                    0.01801602 0.026428953   0.6816773  4.954430e-01\nmentor                 0.02573493 0.002001731  12.8563329  7.924799e-38\n\n\nHasta ahora hemos asumido que cada individuo ha estado “en riesgo” de publicar por el mismo periodo de tiempo, lo cual puede ser no cierto si, por ejemplo, algunos estudiantes se graduaron antes, o si otros han tenido pausas en sus carreras. Al controlar por el hecho de que las mujeres han tenido carreras más cortas, la variable female deja de ser negativa y se convierte en positiva. Las mujeres publican más que los hombres al tomar en cuenta la duración de las carreras.\nComparando los tres modelos:\n\nmodelsummary(list(mpoisson, mpoisson, mpoisson_duracion),\n             vcov = list('classical', 'robust', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n \n\n  \n    \n    \n    tinytable_7in89qhwdzqgpbrgu8d0\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n                (2)\n                (3)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)          \n                  0.460*** \n                  0.460*** \n                  -2.954***\n                \n                \n                                       \n                  (0.093)  \n                  (0.151)  \n                  (0.155)  \n                \n                \n                  factor(female)Female \n                  -0.225***\n                  -0.225***\n                  0.459*** \n                \n                \n                                       \n                  (0.055)  \n                  (0.072)  \n                  (0.073)  \n                \n                \n                  factor(married)Single\n                  -0.155** \n                  -0.155*  \n                  -0.156*  \n                \n                \n                                       \n                  (0.061)  \n                  (0.083)  \n                  (0.083)  \n                \n                \n                  kid5                 \n                  -0.185***\n                  -0.185***\n                  -0.186***\n                \n                \n                                       \n                  (0.040)  \n                  (0.057)  \n                  (0.057)  \n                \n                \n                  phd                  \n                  0.013    \n                  0.013    \n                  0.018    \n                \n                \n                                       \n                  (0.026)  \n                  (0.044)  \n                  (0.045)  \n                \n                \n                  mentor               \n                  0.026*** \n                  0.026*** \n                  0.026*** \n                \n                \n                                       \n                  (0.002)  \n                  (0.004)  \n                  (0.005)  \n                \n                \n                  Num.Obs.             \n                  915      \n                  915      \n                  915      \n                \n                \n                  AIC                  \n                  3314.1   \n                  3314.1   \n                  3322.8   \n                \n                \n                  BIC                  \n                  3343.0   \n                  3343.0   \n                  3351.7   \n                \n                \n                  Log.Lik.             \n                  -1651.056\n                  -1651.056\n                  -1655.393\n                \n                \n                  F                    \n                  43.333   \n                  14.855   \n                  20.311   \n                \n                \n                  RMSE                 \n                  1.84     \n                  1.84     \n                  1.85     \n                \n                \n                  Std.Errors           \n                  IID      \n                  HC3      \n                  HC3      \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n[2 puntos] Implemente la prueba de dispersión de Cameron y Trivedi (1990) usando una regresión auxiliar y los coeficientes estimados en la parte a. ¿Qué concluye?\nSeguimos a CT, p671 y construimos:\n\\[\\frac{(y_i-\\hat{\\mu}_i)^2}{\\hat{\\mu}_i}=\\alpha\\frac{ g(\\hat{\\mu}_i)}{\\hat{\\mu}_i}+u_i\\] Creamos el lado izquierdo:\n\ndata.phd &lt;- data.phd %&gt;% \n  mutate(xb_hat = predict(mpoisson),\n         mu_hat = exp(xb_hat),\n         lado_izq = (art-mu_hat)^2/mu_hat)\n\nNoten que si especificamos \\(g(\\hat{\\mu}_i)=\\hat{\\mu}^2_i\\), el lado derecho simplemente es \\(\\alpha \\hat{\\mu}_i+u_i\\). Estimamos entonces la regresión, sin constante:\nCorremos la regresión:\n\nsummary(lm(lado_izq ~ -1 + mu_hat,\n    data = data.phd))\n\n\nCall:\nlm(formula = lado_izq ~ -1 + mu_hat, data = data.phd)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-5.570 -1.431 -0.798 -0.027 69.967 \n\nCoefficients:\n       Estimate Std. Error t value Pr(&gt;|t|)    \nmu_hat  1.02020    0.08866   11.51   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.881 on 914 degrees of freedom\nMultiple R-squared:  0.1265, Adjusted R-squared:  0.1256 \nF-statistic: 132.4 on 1 and 914 DF,  p-value: &lt; 2.2e-16\n\n\nEl coeficiente sobre \\(\\alpha\\) es estadísticamente significativo, sugiriendo una relación entre la media y la varianza.\n[5 puntos] Emplee ahora un modelo negativo binomial con sobredispersión cuadrática en la media para estimar la relación entre el número de artículos publicados y las variables explicativas antes enumeradas. Interprete el coeficiente asociado al número de hijos y a la variable dicotómica para estudiantes mujeres. ¿Qué puede decir sobre la significancia del \\(\\alpha\\) estimado?\n\nmnb2 &lt;- MASS::glm.nb(art ~\n                 factor(female) + factor(married) + kid5 + phd + mentor,\n                 data = data.phd)\nsummary(mnb2)\n\n\nCall:\nMASS::glm.nb(formula = art ~ factor(female) + factor(married) + \n    kid5 + phd + mentor, data = data.phd, init.theta = 2.264387695, \n    link = log)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            0.406633   0.125778   3.233 0.001225 ** \nfactor(female)Female  -0.216418   0.072636  -2.979 0.002887 ** \nfactor(married)Single -0.150489   0.082097  -1.833 0.066791 .  \nkid5                  -0.176415   0.052813  -3.340 0.000837 ***\nphd                    0.015271   0.035873   0.426 0.670326    \nmentor                 0.029082   0.003214   9.048  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(2.2644) family taken to be 1)\n\n    Null deviance: 1109.0  on 914  degrees of freedom\nResidual deviance: 1004.3  on 909  degrees of freedom\nAIC: 3135.9\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  2.264 \n          Std. Err.:  0.271 \n\n 2 x log-likelihood:  -3121.917 \n\n\nPonemos todo junto:\n\nmodelsummary(list(mpoisson, mpoisson, mpoisson_duracion, mnb2),\n             vcov = list('classical', 'robust', 'robust', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n \n\n  \n    \n    \n    tinytable_nh2hlt04ma8cy8muhchn\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n                (2)\n                (3)\n                (4)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)          \n                  0.460*** \n                  0.460*** \n                  -2.954***\n                  0.407*** \n                \n                \n                                       \n                  (0.093)  \n                  (0.151)  \n                  (0.155)  \n                  (0.135)  \n                \n                \n                  factor(female)Female \n                  -0.225***\n                  -0.225***\n                  0.459*** \n                  -0.216***\n                \n                \n                                       \n                  (0.055)  \n                  (0.072)  \n                  (0.073)  \n                  (0.071)  \n                \n                \n                  factor(married)Single\n                  -0.155** \n                  -0.155*  \n                  -0.156*  \n                  -0.150*  \n                \n                \n                                       \n                  (0.061)  \n                  (0.083)  \n                  (0.083)  \n                  (0.081)  \n                \n                \n                  kid5                 \n                  -0.185***\n                  -0.185***\n                  -0.186***\n                  -0.176***\n                \n                \n                                       \n                  (0.040)  \n                  (0.057)  \n                  (0.057)  \n                  (0.053)  \n                \n                \n                  phd                  \n                  0.013    \n                  0.013    \n                  0.018    \n                  0.015    \n                \n                \n                                       \n                  (0.026)  \n                  (0.044)  \n                  (0.045)  \n                  (0.038)  \n                \n                \n                  mentor               \n                  0.026*** \n                  0.026*** \n                  0.026*** \n                  0.029*** \n                \n                \n                                       \n                  (0.002)  \n                  (0.004)  \n                  (0.005)  \n                  (0.003)  \n                \n                \n                  Num.Obs.             \n                  915      \n                  915      \n                  915      \n                  915      \n                \n                \n                  AIC                  \n                  3314.1   \n                  3314.1   \n                  3322.8   \n                  3135.9   \n                \n                \n                  BIC                  \n                  3343.0   \n                  3343.0   \n                  3351.7   \n                  3169.6   \n                \n                \n                  Log.Lik.             \n                  -1651.056\n                  -1651.056\n                  -1655.393\n                  -1560.958\n                \n                \n                  F                    \n                  43.333   \n                  14.855   \n                  20.311   \n                  20.935   \n                \n                \n                  RMSE                 \n                  1.84     \n                  1.84     \n                  1.85     \n                  1.86     \n                \n                \n                  Std.Errors           \n                  IID      \n                  HC3      \n                  HC3      \n                  HC3      \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nA diferencia de otros paquetes, glm.nb reporta \\(\\theta=1/\\alpha\\):\n\n(alpha &lt;- 1/summary(mnb2)$theta)        \n\n[1] 0.4416205\n\n\nEste es el modelo NB2 visto en clase y la forma más usada para implementar un modelo negativo binomial. Se asume una sobredispersión cuadrática en la media, con la varianza parametrizada usando \\(\\alpha\\). La interpretación de los coeficientes se mantiene con respecto al modelo Poisson. Los coeficientes tienen magnitudes similares, pero se prefiere el modelo NB2 si el propósito es pronóstico pues toma en cuenta la sobredispersión y le da suficiente flexibilidad a la varianza para depender de manera cuadrática de la media.\nUn poco más cuidado hay que poner en \\(\\alpha\\). En este caso, \\(\\hat{\\alpha}=0.44\\). Pero noten que lo que se reporta es el error estándar de \\(\\theta\\). Como platicamos en clase, con un estadístico podemos hacer un test y obtener un valor \\(p\\), pero una función no lineal del mismo puede que no tenga el mismo valor \\(p\\). Esto ocurre aquí, deberíamos recurrir al método delta para calcular el error estándar de \\(\\alpha\\).\n\n\n\n\nRetome los datos del archivo motral2012.csv usado en la Tarea 1. Estimará un modelo Tobit para explicar los factores que afectan la oferta laboral femenina. En este archivo de datos la variable hrsocup registra las horas trabajadas a la semana.\n\n[2 punto] ¿Qué proporción de la muestra femenina reporta horas trabajadas iguales a cero?\nSi hacemos una dummy de horas positivas, al sacarle la media obtenemos la proporción.\n\ndata.salarios&lt;-read_csv(\"../files/motral2012.csv\",\n                          locale = locale(encoding = \"latin1\")) \n\ndata.salarios &lt;- data.salarios %&gt;% \n  filter(sex==2) %&gt;% \n  mutate(zerohrs=ifelse(hrsocup==0,1,0))\n\nsummary(data.salarios$zerohrs)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.3528  1.0000  1.0000 \n\n\nEl 35% de las observaciones tienen cero horas trabajadas.\n[3 puntos] Se desea estimar el efecto de los años de educación (anios_esc) sobre la oferta laboral femenina controlando por el estado marital (casada), la edad (eda) y el número de hijos (n_hij) como una variable continua. En la base, e_con toma el valor de 5 para las personas casadas. Genere la variable dummy casada que tome el valor de 1 para las mujeres casadas y cero en otro caso. Estime un modelo de MCO para hrsocup mayor que cero, usando solo la población femenina. Reporte errores robustos. ¿Cuál es la interpretación sobre el coeficiente de los años de escolaridad?\nEl estimar por MCO, un año más de escolaridad se asocia con 0.17 horas trabajadas más a la semana. Sin embargo, este efecto no es estadísticamente significativo.\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(casada=ifelse(e_con==5,1,0))\n\nreg_mco &lt;- lm(hrsocup ~ anios_esc+casada+eda+n_hij,\n          data=filter(data.salarios,hrsocup&gt;0))\n\ncoeftest(reg_mco,\n         vcov = vcovHC(reg_mco, \"HC1\"))[1:4,]\n\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 36.70129720 1.99116828 18.432042 2.742336e-69\nanios_esc    0.17465627 0.10353350  1.686954 9.179628e-02\ncasada      -3.52571327 0.89724706 -3.929479 8.855253e-05\neda          0.06949593 0.04914655  1.414055 1.575295e-01\n\n\nCon modelsummary podemos hacer pedir la tabla de coeficientes. Podemos especificar qué tipo de errores robustos queremos en la opción vcov:\n\nmodelsummary(list(reg_mco, reg_mco),\n             vcov = list('classical', 'HC1'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n \n\n  \n    \n    \n    tinytable_fkg31zfvygblu6l68nv4\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n                (2)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)\n                  36.701***\n                  36.701***\n                \n                \n                             \n                  (1.959)  \n                  (1.991)  \n                \n                \n                  anios_esc  \n                  0.175*   \n                  0.175*   \n                \n                \n                             \n                  (0.104)  \n                  (0.104)  \n                \n                \n                  casada     \n                  -3.526***\n                  -3.526***\n                \n                \n                             \n                  (0.862)  \n                  (0.897)  \n                \n                \n                  eda        \n                  0.069    \n                  0.069    \n                \n                \n                             \n                  (0.047)  \n                  (0.049)  \n                \n                \n                  n_hij      \n                  -1.149***\n                  -1.149***\n                \n                \n                             \n                  (0.336)  \n                  (0.372)  \n                \n                \n                  Num.Obs.   \n                  1699     \n                  1699     \n                \n                \n                  R2         \n                  0.030    \n                  0.030    \n                \n                \n                  R2 Adj.    \n                  0.028    \n                  0.028    \n                \n                \n                  AIC        \n                  14234.8  \n                  14234.8  \n                \n                \n                  BIC        \n                  14267.4  \n                  14267.4  \n                \n                \n                  Log.Lik.   \n                  -7111.383\n                  -7111.383\n                \n                \n                  F          \n                  13.171   \n                  12.526   \n                \n                \n                  RMSE       \n                  15.91    \n                  15.91    \n                \n                \n                  Std.Errors \n                  IID      \n                  HC1      \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n[3 puntos] ¿Qué problema existe con el modelo planteado en el punto anterior en términos de la selección? ¿Considera que se trata de un caso de censura o de truncamiento?\nPodemos racionalizar las horas trabajadas en un modelo microeconómico de oferta laboral. Las horas trabajadas observadas son positivas cuando la solución óptima es una cantidad positiva de horas. Sin embargo, si la solución óptima implicara horas negativas, las horas observadas serían cero. En este caso tenemos datos censurados en cero. Si existe una relación positiva entre educación y horas trabajadas, al estimar un modelo por MCO usando solo los datos con horas positivas estamos sobreestimando la media condicional pues se habrán omitido del análisis aquellas mujeres cuya solución a su problema de optimización eran horas iguales a cero o negativas.\n[8 puntos] Estime un modelo Tobit de datos censurados. ¿Qué resuelve el modelo Tobit en este caso? Interprete nuevamente el coeficiente sobre los años de escolaridad.\nLa función tobit permite hacer esto muy fácilmente. Noten que left especifica dónde está la censura. La opción gaussian pone explícito uno de los supuestos críticos del modelo tobit visto en clase: errores normales. Además, se asume homocedasticidad.\n\nreg_tobit &lt;- tobit(hrsocup ~ anios_esc+casada+eda+n_hij,\n               left = 0,\n               right = Inf,\n               dist = \"gaussian\",\n               data = data.salarios)\n\nsummary(reg_tobit)\n\n\nCall:\ntobit(formula = hrsocup ~ anios_esc + casada + eda + n_hij, left = 0, \n    right = Inf, dist = \"gaussian\", data = data.salarios)\n\nObservations:\n         Total  Left-censored     Uncensored Right-censored \n          2625            926           1699              0 \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.88236    3.19905   0.276  0.78269    \nanios_esc     0.85530    0.17509   4.885 1.04e-06 ***\ncasada      -10.99515    1.43025  -7.688 1.50e-14 ***\neda           0.41621    0.07665   5.430 5.64e-08 ***\nn_hij        -1.73840    0.55887  -3.111  0.00187 ** \nLog(scale)    3.44512    0.01887 182.608  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nScale: 31.35 \n\nGaussian distribution\nNumber of Newton-Raphson Iterations: 3 \nLog-likelihood: -9086 on 6 Df\nWald-statistic: 127.9 on 4 Df, p-value: &lt; 2.22e-16 \n\n\nEl modelo tobit para datos censurados toma en cuenta que hay una masa de ceros en las horas trabajadas para individuos para los que disponemos de sus características en la base de datos. El modelo tobit ajusta la probabilidad de observar esta masa de ceros. El coeficiente estimado será ahora consistente si el modelo está bien especificado, es decir, si el proceso subyacente es lineal en los parámetros y con un error normal homoscedástico (los supuestos de tobit básico). En este caso, un año más de educación se asocia con 0.85 más horas semanales trabajadas, un efecto estadísticamente significativo. Usar MCO subestimaba el efecto de la escolaridad.\nmodelsummary acepta la salida de la función tobit:\n\nmodelsummary(list(reg_mco, reg_mco, reg_tobit),\n             vcov = list('classical', 'HC1', 'classical'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n \n\n  \n    \n    \n    tinytable_debf4qfj2125rxkkyzt5\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n                (2)\n                (3)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)\n                  36.701***\n                  36.701***\n                  0.882     \n                \n                \n                             \n                  (1.959)  \n                  (1.991)  \n                  (3.199)   \n                \n                \n                  anios_esc  \n                  0.175*   \n                  0.175*   \n                  0.855***  \n                \n                \n                             \n                  (0.104)  \n                  (0.104)  \n                  (0.175)   \n                \n                \n                  casada     \n                  -3.526***\n                  -3.526***\n                  -10.995***\n                \n                \n                             \n                  (0.862)  \n                  (0.897)  \n                  (1.430)   \n                \n                \n                  eda        \n                  0.069    \n                  0.069    \n                  0.416***  \n                \n                \n                             \n                  (0.047)  \n                  (0.049)  \n                  (0.077)   \n                \n                \n                  n_hij      \n                  -1.149***\n                  -1.149***\n                  -1.738*** \n                \n                \n                             \n                  (0.336)  \n                  (0.372)  \n                  (0.559)   \n                \n                \n                  Num.Obs.   \n                  1699     \n                  1699     \n                  2625      \n                \n                \n                  R2         \n                  0.030    \n                  0.030    \n                            \n                \n                \n                  R2 Adj.    \n                  0.028    \n                  0.028    \n                            \n                \n                \n                  AIC        \n                  14234.8  \n                  14234.8  \n                  18184.9   \n                \n                \n                  BIC        \n                  14267.4  \n                  14267.4  \n                  18220.1   \n                \n                \n                  Log.Lik.   \n                  -7111.383\n                  -7111.383\n                            \n                \n                \n                  F          \n                  13.171   \n                  12.526   \n                            \n                \n                \n                  RMSE       \n                  15.91    \n                  15.91    \n                  23.02     \n                \n                \n                  Std.Errors \n                  IID      \n                  HC1      \n                  IID       \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n[4 puntos] ¿Cuál es el efecto marginal de un incremento de un año de educación en la oferta laboral? ¿Cómo cambia su respuesta si, en lugar de considerar la variable latente, considera la variable censurada?\nEl efecto marginal en la variable latente es directamente el coficiente estimado en la parte d., es decir 0.855.\nEl efecto marginal en la media censurada está dado por:\n\\[\\frac{\\partial E(y|x)}{\\partial x_j}=\\beta_j\\Phi(x_i'\\beta)\\]\nLo que hice aquí fue calcular este efecto marginal para cada individuo y luego obtener el promedio de los efectos marginales en aquellos individuos con horas positivas.\n\ndata.salarios &lt;- data.salarios %&gt;%\n  mutate(index1=predict(reg_tobit,.)) %&gt;% \n  mutate(phi=pnorm(index1/reg_tobit$scale)) %&gt;% \n  mutate(mfx_anis_esc=reg_tobit$coefficients[2]*phi,\n         mfx_eda=reg_tobit$coefficients[4]*phi,\n         mfx_n_hij=reg_tobit$coefficients[5]*phi)\n\ndata.salarios %&gt;%\n  filter(hrsocup&gt;0) %&gt;% \n  summarise(mfx_anis_esc=mean(mfx_anis_esc)) \n\n# A tibble: 1 × 1\n  mfx_anis_esc\n         &lt;dbl&gt;\n1        0.612\n\n\n\n\n\n\nUsando los mismos datos del archivo motral2012.csv implementará un ejercicio en el mismo espíritu del famoso estudio de Mroz (1987)1 sobre la oferta laboral femenina. El propósito es estimar la relación entre el salario y el número de horas trabajadas, concentrándonos en la muestra de mujeres.\n\n[5 puntos] El primer problema al que nos enfrentamos es que el salario no se observa para las mujeres que no trabajan. Estime un modelo lineal para el log del salario por hora, ing_x_hrs, usando las variables anios_esc, eda, n_hij, el cuadrado de n_hij, busqueda y casada, usando la submuestra de mujeres con salario por hora positivo. Dichas variables representan los años de escolaridad, la edad, el número de hijos, el cuadrado del número de hijos, si la persona buscó trabajo recientemente y si la persona es casada, respectivamente. Use los coeficientes estimados para imputar el ingreso por hora, faltante para las mujeres que reportan 0 en las horas trabajadas.\nImputamos el salario faltante:\n\ndata.salarios&lt;-read_csv(\"../files/motral2012.csv\",\n                        locale = locale(encoding = \"latin1\")) %&gt;%\n  filter(sex==2) %&gt;% \n  mutate(casada=ifelse(e_con==5,1,0))\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(ly=ifelse(ing_x_hrs&gt;0,log(ing_x_hrs),NA)) \n\nreg_imput &lt;- lm(ly ~ anios_esc+casada+eda+n_hij+n_hij^2+busqueda,\n              data = data.salarios)\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(lyhat = predict(reg_imput, .)) %&gt;% \n  mutate(ly = ifelse(is.na(ly), lyhat, ly))\n\nAquí tomé en cuenta que hay personas con horas trabajadas positivas e ingreso cero. En ese caso puse un NA al log del salario. Luego, en la imputación, le asigné el valor ajustado a estas observaciones junto con todas las que tienen el log del salario faltante.\n[5 puntos] Use heckit de la librería sampleSelection para estimar por máxima verosimilitud un heckit para las horas trabajadas hrsocup. En la ecuación de selección (si la persona trabaja o no) incluya como variable explicativa el salario por hora (imputado para las mujeres que no trabajan), además de anios_esc, eda, n_hij, el cuadrado de n_hij, casada y busqueda (esta última es un indicador de si se buscó trabajo en la última semana). En la ecuación de horas, incluya los mismos regresores, excepto n_hij, su cuadrado y busqueda.\nLa función heckit permite estimar el modelo de Heckman por máxima verosimilitud de manera muy simple. Hay que especificar method=“ml” para que la estimación sea por máxima verosimilitud:\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(trabaja = ifelse(hrsocup&gt;0,1,0)) %&gt;% \n  mutate(trabaja = factor(trabaja,levels=c(0,1)))\n\nreg_heckit_mv &lt;- heckit(trabaja ~ anios_esc+casada+eda+ly+n_hij+n_hij^2+busqueda,\n                hrsocup ~ anios_esc+casada+eda+ly,\n                method=\"ml\",\n                data = data.salarios)\n\nsummary(reg_heckit_mv)\n\n--------------------------------------------\nTobit 2 model (sample selection model)\nMaximum Likelihood estimation\nNewton-Raphson maximisation, 3 iterations\nReturn code 8: successive function values within relative tolerance limit (reltol)\nLog-Likelihood: -7181.675 \n2625 observations (926 censored and 1699 observed)\n14 free parameters (df = 2611)\nProbit selection equation:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.583614   0.448320  -5.763 9.24e-09 ***\nanios_esc    0.005346   0.020341   0.263    0.793    \ncasada      -0.213125   0.145135  -1.468    0.142    \neda         -0.003391   0.008137  -0.417    0.677    \nly          -0.004236   0.133344  -0.032    0.975    \nn_hij        0.023985   0.058900   0.407    0.684    \nbusqueda     2.406669   0.104595  23.009  &lt; 2e-16 ***\nOutcome equation:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 55.62469    2.17656  25.556  &lt; 2e-16 ***\nanios_esc    1.04819    0.09995  10.487  &lt; 2e-16 ***\ncasada      -3.58856    0.77967  -4.603 4.37e-06 ***\neda          0.11614    0.03902   2.977  0.00294 ** \nly          -9.83418    0.60389 -16.285  &lt; 2e-16 ***\n   Error terms:\n      Estimate Std. Error t value Pr(&gt;|t|)    \nsigma  14.8579     0.2591  57.350   &lt;2e-16 ***\nrho    -0.1606     0.1964  -0.818    0.414    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n--------------------------------------------\n\n\nPodemos reportar con modelsummary, aunque realmente lo hace muy mal:\n\nmodelsummary(list(reg_heckit_mv),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n \n\n  \n    \n    \n    tinytable_f2bjcgh5lnpm3l91yxqa\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)\n                  -2.584***\n                \n                \n                             \n                  55.625***\n                \n                \n                             \n                  (0.448)  \n                \n                \n                             \n                  (2.177)  \n                \n                \n                  anios_esc  \n                  0.005    \n                \n                \n                             \n                  1.048*** \n                \n                \n                             \n                  (0.020)  \n                \n                \n                             \n                  (0.100)  \n                \n                \n                  casada     \n                  -0.213   \n                \n                \n                             \n                  -3.589***\n                \n                \n                             \n                  (0.145)  \n                \n                \n                             \n                  (0.780)  \n                \n                \n                  eda        \n                  -0.003   \n                \n                \n                             \n                  0.116*** \n                \n                \n                             \n                  (0.008)  \n                \n                \n                             \n                  (0.039)  \n                \n                \n                  ly         \n                  -0.004   \n                \n                \n                             \n                  -9.834***\n                \n                \n                             \n                  (0.133)  \n                \n                \n                             \n                  (0.604)  \n                \n                \n                  n_hij      \n                  0.024    \n                \n                \n                             \n                  (0.059)  \n                \n                \n                  busqueda   \n                  2.407*** \n                \n                \n                             \n                  (0.105)  \n                \n                \n                  sigma      \n                  14.858***\n                \n                \n                             \n                  (0.259)  \n                \n                \n                  rho        \n                  -0.161   \n                \n                \n                             \n                  (0.196)  \n                \n                \n                  Num.Obs.   \n                  2625     \n                \n                \n                  AIC        \n                  14391.4  \n                \n                \n                  BIC        \n                  14473.6  \n                \n                \n                  RMSE       \n                  14.84    \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n[10 puntos] Estime ahora el heckit en dos pasos, a mano. Es decir, siga los siguientes pasos: i) estime un probit para la ecuación de selección y obtenga el índice \\(x_i'\\hat{\\beta}\\); ii) calcule el inverso de la razón de Mills \\(\\lambda_i(x_i'\\hat{\\beta})\\); y iii) estime por MCO la ecuación para las horas trabajadas con la submuestra que tiene horas trabajadas positivas, incluyendo como regresor el inverso de la razón de Mills estimado y el resto de los regresores. Compare los coeficientes y los errores estándar obtenidos en esta parte con los de la parte b. ¿Por qué son iguales o por qué difieren?\nEstimamos ahora el heckit a mano. Estimamos el probit y obtenemos el valor ajustado del IMR:\n\nreg_heckit_pe &lt;- glm(trabaja ~ anios_esc+casada+eda+ly+n_hij+n_hij^2+busqueda,\n                  family = binomial(link = \"probit\"),\n                  data = data.salarios)\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(index = predict(reg_heckit_pe, .)) %&gt;% \n  mutate(imr = dnorm(index)/pnorm(index))\n\n\nreg_heckit_se &lt;- lm(hrsocup ~ anios_esc+casada+eda+ly+imr,\n            data=filter(data.salarios,trabaja==1))\n\nsummary(reg_heckit_se)\n\n\nCall:\nlm(formula = hrsocup ~ anios_esc + casada + eda + ly + imr, data = filter(data.salarios, \n    trabaja == 1))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-46.172 -10.085   1.915   9.253  57.689 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 55.68676    2.17948  25.550  &lt; 2e-16 ***\nanios_esc    1.04814    0.10000  10.481  &lt; 2e-16 ***\ncasada      -3.56927    0.78057  -4.573 5.17e-06 ***\neda          0.11621    0.03904   2.977  0.00296 ** \nly          -9.82971    0.60406 -16.273  &lt; 2e-16 ***\nimr         -3.94669    3.62684  -1.088  0.27667    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.86 on 1693 degrees of freedom\nMultiple R-squared:  0.1563, Adjusted R-squared:  0.1539 \nF-statistic: 62.75 on 5 and 1693 DF,  p-value: &lt; 2.2e-16\n\n\nComparamos coeficientes (aquí stargazer lo hace mejor):\nstargazer(reg_heckit_mv, reg_heckit_se,\n          type=\"html\", \n          df=FALSE,\n          digits=4)\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nhrsocup\n\n\n\n\n\n\nHeckman\n\n\nOLS\n\n\n\n\n\n\nselection\n\n\n\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nanios_esc\n\n\n1.0482***\n\n\n1.0481***\n\n\n\n\n\n\n(0.0999)\n\n\n(0.1000)\n\n\n\n\n\n\n\n\n\n\n\n\ncasada\n\n\n-3.5886***\n\n\n-3.5693***\n\n\n\n\n\n\n(0.7797)\n\n\n(0.7806)\n\n\n\n\n\n\n\n\n\n\n\n\neda\n\n\n0.1161***\n\n\n0.1162***\n\n\n\n\n\n\n(0.0390)\n\n\n(0.0390)\n\n\n\n\n\n\n\n\n\n\n\n\nly\n\n\n-9.8342***\n\n\n-9.8297***\n\n\n\n\n\n\n(0.6039)\n\n\n(0.6041)\n\n\n\n\n\n\n\n\n\n\n\n\nimr\n\n\n\n\n-3.9467\n\n\n\n\n\n\n\n\n(3.6268)\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n55.6247***\n\n\n55.6868***\n\n\n\n\n\n\n(2.1766)\n\n\n(2.1795)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n2,625\n\n\n1,699\n\n\n\n\nR2\n\n\n0.1563\n\n\n\n\n\n\nAdjusted R2\n\n\n0.1539\n\n\n\n\n\n\nResidual Std. Error\n\n\n\n\n14.8614\n\n\n\n\nF Statistic\n\n\n\n\n62.7490***\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\nLa magnitud de los coeficientes es práctiamente la misma entre el modelo estimado por máxima verosimilitud y con un procedimiento en dos etapas a mano. En este ejemplo las diferencias son sutiles, aunque recordemos que en general la estimación por MV es más eficiente si la verosimilitud está bien planteada."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-1",
    "href": "tareas/tarea-2-respuestas.html#pregunta-1",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "Use los datos en el archivo motral2012.csv, que incluye una muestra de individuos con sus características socioeconómicas. Nos interesa conocer los factores que afectan la probabilidad de que los individuos tengan ahorros formales. Considere lo siguiente sobre las opciones de ahorro de los entrevistados, contenida en la variable p14:\n\np14 igual a 1 significa cuentas de ahorro bancarias\np14 igual a 2 significa cuenta de inversión bancaria\np14 igual a 3 significa inversiones en bienes raíces\np14 igual a 4 significa caja de ahorro en su trabajo\np14 igual a 5 significa caja de ahorro con sus amigos\np14 igual a 6 significa tandas\np14 igual a 7 significa que ahorra en su casa o alcancías\np14 igual a 8 significa otro lugar\np14 NA significa que no ahorra\n\n\n[2 puntos] Comience generando una variable binaria ahorra_inf que tome el valor de 1 para las personas que ahorran en instrumentos informales y 0 en otro caso. Se consideran instrumentos informales las cajas de ahorro en el trabajo o amigos, las tandas y el ahorro en casa o alcancías . Construya también la variable mujer que tome el valor de 1 cuando sex toma el valor de 2 y 0 en otro caso. Luego, estime un modelo de probabilidad lineal que relacione ahorra_inf como variable dependiente con eda (edad), anios_esc (años de escolaridad) y mujer. Reporte los errores que asumen homocedasticidad y los errores robustos a heteroscedasticidad. ¿Qué observa respecto a los errores y por qué sucede?\nGeneramos variables:\n\ndata.financiero &lt;- read_csv(\"../files/motral2012.csv\",\n                          locale = locale(encoding = \"latin1\")) %&gt;%\n  clean_names() %&gt;% \n  mutate(ahorra_inf = case_when(p14 %in% c(4,5,6,7) ~ 1,\n                                .default = 0),\n         mujer=ifelse(sex==2,1,0))\n\nEstimamos el modelo lineal y obtenemos la matriz de varianzas robusta usando vcovHC:\n\nsummary(reg.lineal &lt;- lm(ahorra_inf ~ eda + anios_esc + mujer,\n                         data = data.financiero))\n\n\nCall:\nlm(formula = ahorra_inf ~ eda + anios_esc + mujer, data = data.financiero)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.3365 -0.2580 -0.1844 -0.1092  0.9467 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  0.4519266  0.0254686  17.744   &lt;2e-16 ***\neda         -0.0063753  0.0005491 -11.610   &lt;2e-16 ***\nanios_esc   -0.0006780  0.0012186  -0.556    0.578    \nmujer       -0.0006674  0.0113305  -0.059    0.953    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4107 on 5260 degrees of freedom\nMultiple R-squared:  0.02507,    Adjusted R-squared:  0.02452 \nF-statistic: 45.09 on 3 and 5260 DF,  p-value: &lt; 2.2e-16\n\n#Matriz robusta\nv_rob &lt;- vcovHC(reg.lineal, type = \"HC0\")\nse_rob    &lt;- sqrt(diag(v_rob))\n\nPresentamos usando modelsummary.\nmodelsummary(list(reg.lineal, reg.lineal),\n             vcov = c(\"iid\", \"HC0\"),\n             stars = c('*'=.1, '**'=.05, '***'=.01))\n \n\n  \n    \n    \n    tinytable_je4k9ncycm5363q2aswf\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n                (2)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)\n                  0.452*** \n                  0.452*** \n                \n                \n                             \n                  (0.025)  \n                  (0.029)  \n                \n                \n                  eda        \n                  -0.006***\n                  -0.006***\n                \n                \n                             \n                  (0.001)  \n                  (0.001)  \n                \n                \n                  anios_esc  \n                  -0.001   \n                  -0.001   \n                \n                \n                             \n                  (0.001)  \n                  (0.002)  \n                \n                \n                  mujer      \n                  -0.001   \n                  -0.001   \n                \n                \n                             \n                  (0.011)  \n                  (0.011)  \n                \n                \n                  Num.Obs.   \n                  5264     \n                  5264     \n                \n                \n                  R2         \n                  0.025    \n                  0.025    \n                \n                \n                  R2 Adj.    \n                  0.025    \n                  0.025    \n                \n                \n                  AIC        \n                  5575.3   \n                  5575.3   \n                \n                \n                  BIC        \n                  5608.1   \n                  5608.1   \n                \n                \n                  Log.Lik.   \n                  -2782.626\n                  -2782.626\n                \n                \n                  F          \n                  45.091   \n                  46.854   \n                \n                \n                  RMSE       \n                  0.41     \n                  0.41     \n                \n                \n                  Std.Errors \n                  IID      \n                  HC0      \n                \n        \n      \n    \n\n    \n\n  \n\n\nEn en problema binario, la media condicional está bien planteada. Y dado que la densidad pertenece a la familia lineal exponencial, basta con que la media condicional esté bien planteada para la consistencia de \\(\\beta\\). Sin embargo, en el caso de los modelos binarios, la varianza condicional también está siempre bien planteada, pues \\(V(y)=p(1-p)\\). Esto implica que no hay ninguna ganancia en usar la matriz de varianzas robustas. Ver CT, p. 469 para una discusión.\n[3 puntos] ¿Cuál es el efecto en la probabilidad de ahorrar informalmente si los años de educación se incrementan en una unidad, pasando de 4 a 5 años de educación?\nUna reducción de 0.1 puntos porcentuales (0.001/100), estadísticamente no significativa.\n[2 puntos] Realice una prueba de significancia conjunta de eda y anios_esc. ¿Qué concluye?\nPodemos usar la función linearHypothesis:\n\ncar::linearHypothesis(reg.lineal, c(\"eda=0\", \"anios_esc=0\"))\n\nLinear hypothesis test\n\nHypothesis:\neda = 0\nanios_esc = 0\n\nModel 1: restricted model\nModel 2: ahorra_inf ~ eda + anios_esc + mujer\n\n  Res.Df    RSS Df Sum of Sq      F    Pr(&gt;F)    \n1   5262 909.91                                  \n2   5260 887.14  2    22.773 67.512 &lt; 2.2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nConcluimos que no hay evidencia para afirmar que \\(\\beta_{eda}=\\beta_{anios\\_esc}=0\\).\n[3 puntos] Estime un modelo logit relacionando las mismas variables. Use la función avg_slopes del paquete marginaleffects para obtener los efectos marginales promedio de un cambio en cada uno de los regresores. ¿Por qué difiere la magnitud de este efecto marginal con respecto a la parte b.?\nEstimamos el modelo probit:\n\nreg.logit &lt;- glm(ahorra_inf ~ eda + anios_esc + mujer,\n                  family = binomial(link = \"logit\"),\n                  data = data.financiero)\n\nsummary(reg.logit)$coef\n\n                Estimate  Std. Error      z value     Pr(&gt;|z|)\n(Intercept)  0.081021587 0.150793629   0.53730113 5.910596e-01\neda         -0.038339619 0.003385824 -11.32357193 1.003001e-29\nanios_esc   -0.003787198 0.007627194  -0.49653889 6.195143e-01\nmujer       -0.001539617 0.067250054  -0.02289392 9.817349e-01\n\n\nNoten que el signo de los coeficientes coinciden con el promedio de los efectos marginales:\n\navg_slopes(reg.logit)\n\n\n      Term Contrast  Estimate Std. Error        z Pr(&gt;|z|)     S    2.5 %\n anios_esc    dY/dX -0.000638   0.001285  -0.4966    0.619   0.7 -0.00316\n eda          dY/dX -0.006459   0.000554 -11.6533   &lt;0.001 101.8 -0.00755\n mujer        1 - 0 -0.000259   0.011331  -0.0229    0.982   0.0 -0.02247\n   97.5 %\n  0.00188\n -0.00537\n  0.02195\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nEl promedio del efecto marginal de un cambio en los años de educación es de una reducción de 0.06 puntos porcentuales.\n[2 puntos] Ahora estime el efecto marginal en la media para eda y anios_esc y para los hombres, usando la función slopes. ¿Por qué difiere la magnitud de este efecto marginal respecto a la parte b. y la d.?\nPara obtener los efectos marginales evaluados en algún valor \\(X_i\\) de los covariables, debemos especificar estos valores usando datagrid:\n\navg_slopes(reg.logit,\n           newdata = datagrid(eda = mean(data.financiero$eda),\n                              anios_esc = mean(data.financiero$anios_esc),\n                              mujer = 1))\n\n\n      Term Contrast  Estimate Std. Error        z Pr(&gt;|z|)    S    2.5 %\n anios_esc    dY/dX -0.000639   0.001287  -0.4963    0.620  0.7 -0.00316\n eda          dY/dX -0.006465   0.000575 -11.2472   &lt;0.001 95.1 -0.00759\n mujer        1 - 0 -0.000260   0.011346  -0.0229    0.982  0.0 -0.02250\n   97.5 %\n  0.00188\n -0.00534\n  0.02198\n\nColumns: term, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  response \n\n\nEl efecto marginal de un cambio en los años de escolaridad evaluados en la media de los años de educación y edad, para las mujeres, es de -0.06 puntos. Esto difiere del modelo lineal porque en el modelo lineal los efectos marginales son constantes, mientras que los efectos marginal del modelo no lineal dependen del punto de evaluación. También difiere de los efectos marginales promedio pues aquí solo hemos calculado el efecto marginal una sola vez, para un valor \\(X_i\\), mientras que el promedio de efectos marginales implica calcular el efecto marginal para cada individuo y luego obtener el promedio.\nEn clase les pregunté cómo estimarían el error estándar de los cambios marginales y brevemente mencioné que una forma muy usada es el Método Delta, el cual se basa en que los efectos marginales son funciones no lineales de los parámetros. Esto es lo que efectivamente se usa en la función avg_slopes para obtener los errores estándar y los intervalos de confianza. Aquí pueden leer al respecto.\n[3 puntos] Provea una expresión para la maginitud de:\n\n\\[\\frac{\\frac{\\partial P(y=1)}{\\partial \\; anios\\_esc}}{\\frac{\\partial P(y=1)}{\\partial \\; eda}}\\]\nLa razón de efectos marginales es la razón de coeficientes:\n\\[\\frac{\\frac{\\partial P(y=1)}{\\partial \\; anios\\_esc}}{\\frac{\\partial P(y=1)}{\\partial \\; eda}}=\\frac{\\beta_{anios\\_esc}}{\\beta_{eda}}=\\frac{0.0038 }{0.0383}\\]"
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-2",
    "href": "tareas/tarea-2-respuestas.html#pregunta-2",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "Ahora estimará un modelo multinomial empleando los mismos datos en motral2012.csv. El propósito será ahora estudiar los factores relevantes para predecir la forma de ahorro que tienen las personas que ahorran.\n\n[2 puntos] Genere una variable categórica llamada ahorro que sea igual a 1 cuando p14 sea igual a 1 o 2, igual a 2 cuando p14 sea igual a 7, e igual a 3 cuando p14 sea igual a 3, 4, 5, 6 u 8. Haga que esa variable sea missing cuando p14 sea missing. Posteriormente, convierta esta nueva variable en una de factores de forma que el valor 1 tenga la etiqueta “Banco”, el valor 2 tenga la etiqueta “Casa” y el valor 3 tenga la etiqueta “Otro”.\nConstruimos la variable dependiente:\n\ndata.financiero &lt;- read_csv(\"../files/motral2012.csv\",\n                            locale = locale(encoding = \"latin1\")) %&gt;%\n  clean_names() %&gt;% \n  mutate(ahorro=NA) %&gt;% \n  mutate(ahorro=ifelse(p14%in%c(1,2),1,ahorro)) %&gt;%\n  mutate(ahorro=ifelse(p14==7,2,ahorro)) %&gt;% \n  mutate(ahorro=ifelse(p14%in%c(3,4,5,6,8),3,ahorro)) %&gt;% \n  mutate(ahorro=factor(ahorro,\n                   levels=c(1,2,3), labels=c(\"Banco\",\"Casa\",\"Otro\"))) %&gt;%\n  mutate(mujer=ifelse(sex==2,1,0))\n\n[4 puntos] Estime un modelo logit multinomial (regresores invariantes a la alternativa) con la opción de ahorro como variable dependiente y los mismos regresores de la pregunta 1. Hay varios paquetes para hacer esto, pero recomiendo usar la función multinom del paquete nnet. ¿Qué puede decir sobre el coeficiente de años de educación en la alternativa “Casa”?\nUsamos multinom para estimar el modelo logit multinomial:\n\nmultilogit &lt;- nnet::multinom(ahorro~ eda + anios_esc + mujer,\n                              data=data.financiero)\n\n# weights:  15 (8 variable)\ninitial  value 2727.854313 \niter  10 value 2546.085070\nfinal  value 2545.712541 \nconverged\n\nsummary(multilogit)\n\nCall:\nnnet::multinom(formula = ahorro ~ eda + anios_esc + mujer, data = data.financiero)\n\nCoefficients:\n     (Intercept)          eda   anios_esc       mujer\nCasa    3.026880 -0.052310196 -0.14829719  0.09265405\nOtro    0.206704 -0.003501367 -0.04628175 -0.06459305\n\nStd. Errors:\n     (Intercept)         eda  anios_esc      mujer\nCasa   0.2487107 0.005207439 0.01355319 0.09956544\nOtro   0.2476498 0.004964123 0.01285100 0.09995715\n\nResidual Deviance: 5091.425 \nAIC: 5107.425 \n\n\nEn el logit multinominal (regresores invariantes) el coeficiente se interpreta con respecto a una categoría base. En este caso, la categoría base es Banco. El modelo implica que la probabilidad de ahorrar en casa disminuye con un año más de educación, en comparación con la probabilidad de ahorrar en el banco. En particular, sabemos que podemos escribir el log del cociente de la probabilidad de las categorías \\(j\\) y \\(k\\) sean escogidas, normalizando \\(k\\) a ser la base, como:\n\\[\\ln\\left(\\frac{P(y=Casa)}{P(y=Banco)}\\right)=x'\\beta=\\beta_0+\\beta_1 edad + \\beta_2 educación + \\beta_3 mujer \\]\nEs decir, un año más de educación se asocia con una reducción en el log de la razón de momios de 0.15.\n[4 puntos] Calcule los efectos marginales promedio sobre la probabilidad de ahorrar en el banco. Al considerar el cambio en la probabilidad para el caso de las mujeres (cuando la variable mujer pasa de 0 a 1), ¿de qué tamaño es el efecto predicho en la probabilidad de ahorrar en el banco?\nUsamos avg_slopes:\n\navg_slopes(multilogit)\n\n\n Group      Term Contrast Estimate Std. Error       z Pr(&gt;|z|)    S    2.5 %\n Banco anios_esc    dY/dX  0.02285   0.002381   9.595   &lt;0.001 70.0  0.01818\n Banco eda          dY/dX  0.00657   0.000935   7.027   &lt;0.001 38.8  0.00474\n Banco mujer        1 - 0 -0.00343   0.019432  -0.177    0.860  0.2 -0.04152\n Casa  anios_esc    dY/dX -0.02512   0.002231 -11.262   &lt;0.001 95.3 -0.02949\n Casa  eda          dY/dX -0.00982   0.000860 -11.422   &lt;0.001 98.0 -0.01151\n Casa  mujer        1 - 0  0.02271   0.017662   1.286    0.199  2.3 -0.01191\n Otro  anios_esc    dY/dX  0.00228   0.002174   1.046    0.295  1.8 -0.00199\n Otro  eda          dY/dX  0.00325   0.000842   3.863   &lt;0.001 13.1  0.00160\n Otro  mujer        1 - 0 -0.01927   0.017549  -1.098    0.272  1.9 -0.05367\n   97.5 %\n  0.02751\n  0.00840\n  0.03465\n -0.02075\n -0.00814\n  0.05732\n  0.00654\n  0.00490\n  0.01512\n\nColumns: term, group, contrast, estimate, std.error, statistic, p.value, s.value, conf.low, conf.high \nType:  probs \n\n\nEl efecto de ser mujer es de una reducción de 0.3 puntos en la probabilidad de ahorrar en el banco al estimar el promedio de los efectos marginales.\n[3 puntos] Calcule los cocientes de riesgo relativo (relative risk ratios o RRR). ¿Qué significa el hecho de que el RRR asociado a ser mujer sea mayor que 1 en la alternativa “Casa”?\n\n(multilogit_rrr = exp(coef(multilogit)))\n\n     (Intercept)       eda anios_esc     mujer\nCasa   20.632752 0.9490344 0.8621748 1.0970821\nOtro    1.229619 0.9965048 0.9547729 0.9374489\n\n\nLos coeficientes en forma de RRR tienen la interpretación del cambio en el riesgo relativo que una categoría sea elegida con relación al riesgo de escoger la categoría base. En este caso, el ser mujer está asociado con una probabilidad de ahorrar en “Casa” 1.097 veces mayor de que la de ahorrar en “Banco”.\n[2 puntos] Estime nuevamente el modelo, pero ahora, especifique que la alternativa “Casa” sea la alternativa base. ¿Cómo es el RRR de la edad en la alternativa “Banco”? ¿Es esto congruente con lo que obtuvo en la parte d. de esta pregunta?\nPrimero tenemos que cambiar la base. Para esto hacemos uso de que ahorro es una variable de factores. Luego estimamos:\n\ndata.financiero &lt;- data.financiero %&gt;% \n  mutate(ahorro = relevel(ahorro, ref = \"Casa\"))\n\nmultilogit2 &lt;- nnet::multinom(ahorro ~ eda + anios_esc + mujer,\n                              data=data.financiero)\n\n# weights:  15 (8 variable)\ninitial  value 2727.854313 \niter  10 value 2552.696634\nfinal  value 2545.712541 \nconverged\n\n\nObtenemos el RRR:\n\n(multilogit2_rrr = exp(coef(multilogit2)))\n\n      (Intercept)      eda anios_esc     mujer\nBanco  0.04846638 1.053703  1.159857 0.9115111\nOtro   0.05959489 1.050020  1.107401 0.8544952\n\n\nAl cambiar la categoría base a Casa solo se modifica la interpretación relativa. En la parte d. el RRR de la edad para la opción de Casa era 0.949, es decir, si la edad se incrementa en una unidad, la probabilidad de ahorrar en Casa es 0.949 veces la de ahorrar en Banco. Con la nueva categoría base, el RRR de la edad para ahorrar en Banco es 1.054, es decir, si la edad se incrementa en un año, la probabilidad de ahorrar en Banco es 1.054 veces más probable que la probabilidad de ahorrar en Casa. La parte d. implica que \\(P(Casa)=0.949(Banco)\\). Mientras que estimando el modelo con la nueva categoría, \\(P(Banco)=1.054(Casa)\\), o \\(P(Casa)=1/1.054(Banco)\\). Empleando todos los decimales en R se puede notar que 1/1.054≅0.949 Ambos resultados son consistentes."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-3-modelo-poisson-inflado-en-cero",
    "href": "tareas/tarea-2-respuestas.html#pregunta-3-modelo-poisson-inflado-en-cero",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "Otra manera de resolver el problema del exceso de ceros que a veces nos molesta en los modelos Poisson es usar un modelo Poisson inflado en cero (CT, p. 681). La idea es introducir un proceso binario con densidad \\(f_1(\\cdot)\\) para modelar la probabilidad de que \\(y=0\\) y luego una densidad de conteo \\(f_2(\\cdot)\\). Si el proceso binario toma el valor de 0, con probabilidad \\(f_1(0)\\), entonces \\(y=0\\), pero si el proceso binario toma el valor de 1, entonces \\(y={0,1,2,\\ldots}\\). Note que podemos entonces observar ceros por dos razones, por el proceso binomial o por el conteo.\nUn modelo inflado en cero tendrá como densidad:\n\\[\ng(y)=\n\\begin{cases}\nf_1(0)+(1-f_1(0))f_2(0) & \\text{si }y=0 \\\\\n(1-f_1(0))f_2(y)& \\text{si }y\\geq 1\n\\end{cases}\n\\]\nConsidere la variable aleatoria \\(Y\\) con observaciones iid que sigue una distribución Poisson con parámetro \\(\\lambda\\). Y considere una variable un proceso binomial tal que \\(\\pi\\) es la probabilidad de que el conteo no se realice. Entonces:\n\\[\ng(y)=\n\\begin{cases}\n\\pi+(1-\\pi)f_2(0) & \\text{si }y=0 \\\\\n(1-\\pi)f_2(y)& \\text{si }y\\geq 1\n\\end{cases}\n\\]\n\n[4 puntos] Termine de especializar la expresión anterior unsando la distribución Poisson para \\(f_2(\\cdot)\\) para obtener la función de masa de probabilidad del modelo Poisson inflado en cero \\(g(y|\\lambda, \\pi)\\).\nEn el caso particular de un modelo Poisson, sabemos que \\(f_2(0)=P(Y=0)=exp(-\\lambda)\\). Definiendo la probabilidad de observar un conteo cero como \\(\\pi\\), la función de masa de probabilidad del modelo inflado en cero es:\n\\[g(y)=\n\\begin{cases}\n\\pi+(1-\\pi)exp(-\\lambda) \\quad\\text{si }y=0 \\\\\n(1-\\pi)\\frac{\\lambda^y exp(-\\lambda)}{y!} \\quad\\text{si } y \\geq1 \\\\\n\\end{cases}\n\\]\n[5 puntos] Provea una expresión para la función de verosimilitud \\(L(\\lambda,\\pi)=\\prod_{i=1}^N g(y_i|\\lambda, \\pi)\\). Una sugerencia para simplificar sus cálculos es definir una variable \\(X\\) igual al numero de veces que \\(Y_i\\) que toma el valor de cero.\nLa función de verosimilitud del problema es:\n\\[L(\\pi,\\lambda,y_i)=\\prod_i P(Y_i=y_i)\\]\nCon las formas específicas para el modelo Poisson inflado en cero:\n\\[L(\\pi,\\lambda,y_i)=\\prod_{i\\in y_i=0}\\left(\\pi+(1-\\pi)exp(-\\lambda) \\right) \\prod_{i\\in y_i&gt;0}\\left((1-\\pi)\\frac{\\lambda^{y_i} exp(-\\lambda)}{y!}\\right)\\]\nHaciendo \\(X\\) el número de veces que \\(y_i\\) toma el valor de cero, el primer producto es \\(\\left(\\pi+(1-\\pi)exp(-\\lambda) \\right)\\) elevado a la potencia \\(X\\).\n¿Cuántos términos distintos de cero quedan? Quedan \\(n-X\\). El segundo producto en la verosimilitud es:\n\\[\\left((1-\\pi)exp(-\\lambda)\\right)^{n-X}\\frac{\\lambda^{\\sum_i y_i}}{\\prod_{i\\in y_i&gt;0} y!}\\]\nLa verosimilitud es por tanto:\n\\[L(\\pi,\\lambda,y_i)=\\left(\\pi+(1-\\pi)exp(-\\lambda) \\right)^X \\left((1-\\pi)exp(-\\lambda)\\right)^{n-X}\\frac{\\lambda^{\\sum_i y_i}}{\\prod_{i\\in y_i&gt;0} y!}\\]\n[3 puntos] Provea una expresión para la log verosimilitud del problema, \\(\\mathcal{L}(\\lambda,\\pi)\\).\nDada la verosimilitud planteada en la parte anterior, la log verosimilitud es:\n\\[\\mathcal{L}(\\pi,\\lambda,y_i)=X\\ln \\left(\\pi+(1-\\pi)exp(-\\lambda) \\right)+(n-X)\\ln(1-\\pi)-(n-X)\\lambda+n\\bar{Y}\\ln (\\lambda)- \\ln\\left(\\prod_{i\\in y_i&gt;0} y! \\right)\\]\n[3 puntos] Obtenga las condiciones de primer orden que caracterizan la solución del problema de máxima verosimilitud, derivando la log verosimilitud con respecto a \\(\\lambda\\) y a \\(\\pi\\).\nTenemos dos parámetros, así que tenemos dos condiciones de primer orden. Derivando la log verosimilitud con respecto a \\(\\pi\\) obtenemos:\n\\[\\frac{\\partial \\mathcal{L}}{\\partial \\pi}=\\frac{X}{\\pi+(1-\\pi)exp(-\\lambda)}(1-exp(-\\lambda))-\\frac{n-X}{1-\\pi}=0\\]\nLa primer condición (A) es:\n\\[\\frac{X(1-exp(-\\lambda))(1-\\pi)}{\\pi+(1-\\pi)exp(-\\lambda)}=n-X\\quad\\quad\\ldots(A)\\]\nAhora derivando la log verosimilitud con respecto a \\(\\lambda\\):\n\\[\\frac{\\partial \\mathcal{L}}{\\partial \\lambda}=-\\frac{X}{\\pi+(1-\\pi)exp(-\\lambda)}(1-\\pi)exp(-\\lambda)-(n-X)+\\frac{n\\bar{Y}}{\\lambda}=0\\]\nLa segunda condición (B) es:\n\\[\\frac{X(1-\\pi)exp(-\\lambda)}{\\pi+(1-\\pi)exp(-\\lambda)}+(n-X)=\\frac{n\\bar{Y}}{\\lambda}\\quad\\quad\\ldots(B)\\]\n\\((\\hat{\\pi}_{MV},\\hat{\\lambda}_{MV})\\) son los valores de los parámetros que resulven el sistema dado por (A) y (B)."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-4",
    "href": "tareas/tarea-2-respuestas.html#pregunta-4",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "Use los datos phd_articulos.csv, los cuales contienen información sobre el número de artículos publicados para una muestra de entonces estudiantes de doctorado. Nuestra variable de interés será el número de artículos art.\n\n[4 puntos] Estime un modelo Poisson que incluya variables dicotómicas para estudiantes mujeres (female) y para estudiantes casadas o casados (married), el número de hijos mejores de cinco años (kid5), el ranking de prestigio del doctorado (phd) y el número de artículos publicados por su mentor (mentor). Realice la estimación de la matriz de varianzas primero a partir de la varianza teórica que resulta de la igualdad de la matriz de información y luego usando una matriz de sándwich. Interprete los coeficientes estimados.\n\ndata.phd&lt;-read_csv(\"../files/phd_articulos.csv\",\n                          locale = locale(encoding =                \"latin1\"))\n\ndata.phd &lt;- data.phd %&gt;% \n  mutate(female=factor(female,\n                       levels=c('Male','Female')))\n\nmpoisson &lt;- glm(art ~ factor(female) + factor(married) + kid5 + phd + mentor,\n                family=\"poisson\",\n                data=data.phd)\n\nsummary(mpoisson)\n\n\nCall:\nglm(formula = art ~ factor(female) + factor(married) + kid5 + \n    phd + mentor, family = \"poisson\", data = data.phd)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            0.459860   0.093335   4.927 8.35e-07 ***\nfactor(female)Female  -0.224594   0.054613  -4.112 3.92e-05 ***\nfactor(married)Single -0.155243   0.061374  -2.529   0.0114 *  \nkid5                  -0.184883   0.040127  -4.607 4.08e-06 ***\nphd                    0.012823   0.026397   0.486   0.6271    \nmentor                 0.025543   0.002006  12.733  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 1817.4  on 914  degrees of freedom\nResidual deviance: 1634.4  on 909  degrees of freedom\nAIC: 3314.1\n\nNumber of Fisher Scoring iterations: 5\n\n\nPresentamos errores heterocedásticos y robustos a la heterocedasticidad. Aquí les muestro otro paquete que puede servirles para presentar resultados en trabajos y tesinas, alterntivo a stargazer, modelsummary:\n\nmodelsummary(list(mpoisson, mpoisson),\n             vcov = list('classical', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n \n\n  \n    \n    \n    tinytable_c69u71kdxs6dya8b76p9\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n                (2)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)          \n                  0.460*** \n                  0.460*** \n                \n                \n                                       \n                  (0.093)  \n                  (0.151)  \n                \n                \n                  factor(female)Female \n                  -0.225***\n                  -0.225***\n                \n                \n                                       \n                  (0.055)  \n                  (0.072)  \n                \n                \n                  factor(married)Single\n                  -0.155** \n                  -0.155*  \n                \n                \n                                       \n                  (0.061)  \n                  (0.083)  \n                \n                \n                  kid5                 \n                  -0.185***\n                  -0.185***\n                \n                \n                                       \n                  (0.040)  \n                  (0.057)  \n                \n                \n                  phd                  \n                  0.013    \n                  0.013    \n                \n                \n                                       \n                  (0.026)  \n                  (0.044)  \n                \n                \n                  mentor               \n                  0.026*** \n                  0.026*** \n                \n                \n                                       \n                  (0.002)  \n                  (0.004)  \n                \n                \n                  Num.Obs.             \n                  915      \n                  915      \n                \n                \n                  AIC                  \n                  3314.1   \n                  3314.1   \n                \n                \n                  BIC                  \n                  3343.0   \n                  3343.0   \n                \n                \n                  Log.Lik.             \n                  -1651.056\n                  -1651.056\n                \n                \n                  F                    \n                  43.333   \n                  14.855   \n                \n                \n                  RMSE                 \n                  1.84     \n                  1.84     \n                \n                \n                  Std.Errors           \n                  IID      \n                  HC3      \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nPara las variables continuas, como el número de artículos publicados por el mentor, la interpretación es el cambio en el log conteo esperado. En este caso, un artículo más publicado por el mentor incrementa el log conteo esperado en 0.026. También sabemos que los coeficientes tienen una interpretación de semielasticidad; en este caso, la semielasticidad del conteo con respecto al número de artículos publicados es 0.026. Para las variables dicotómicas, por ejemplo female, la interpretación es la diferencia entre el log conteo esperado entre mujeres y la categoría base (hombres).\n[3 puntos] Obtenga la razón de tasas de incidencia (IRR) para los coeficientes e interprete los resultados.\n\nexp(summary(mpoisson)$coef)\n\n                       Estimate Std. Error      z value Pr(&gt;|z|)\n(Intercept)           1.5838526   1.097829 1.379638e+02 1.000001\nfactor(female)Female  0.7988403   1.056132 1.636793e-02 1.000039\nfactor(married)Single 0.8562068   1.063297 7.970295e-02 1.011490\nkid5                  0.8312018   1.040943 9.977222e-03 1.000004\nphd                   1.0129051   1.026749 1.625407e+00 1.872246\nmentor                1.0258718   1.002008 3.386456e+05 1.000000\n\n\nAunque esto también puede hacerse directamente en modelsummary:\n\nmodelsummary(list(mpoisson, mpoisson),\n             exponentiate = TRUE,\n             vcov = list('classical', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n \n\n  \n    \n    \n    tinytable_i0mpf849vz0u3zucc4t9\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n                (2)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)          \n                  1.584*** \n                  1.584*** \n                \n                \n                                       \n                  (0.148)  \n                  (0.240)  \n                \n                \n                  factor(female)Female \n                  0.799*** \n                  0.799*** \n                \n                \n                                       \n                  (0.044)  \n                  (0.058)  \n                \n                \n                  factor(married)Single\n                  0.856**  \n                  0.856*   \n                \n                \n                                       \n                  (0.053)  \n                  (0.071)  \n                \n                \n                  kid5                 \n                  0.831*** \n                  0.831*** \n                \n                \n                                       \n                  (0.033)  \n                  (0.047)  \n                \n                \n                  phd                  \n                  1.013    \n                  1.013    \n                \n                \n                                       \n                  (0.027)  \n                  (0.045)  \n                \n                \n                  mentor               \n                  1.026*** \n                  1.026*** \n                \n                \n                                       \n                  (0.002)  \n                  (0.004)  \n                \n                \n                  Num.Obs.             \n                  915      \n                  915      \n                \n                \n                  AIC                  \n                  3314.1   \n                  3314.1   \n                \n                \n                  BIC                  \n                  3343.0   \n                  3343.0   \n                \n                \n                  Log.Lik.             \n                  -1651.056\n                  -1651.056\n                \n                \n                  F                    \n                  43.333   \n                  14.855   \n                \n                \n                  RMSE                 \n                  1.84     \n                  1.84     \n                \n                \n                  Std.Errors           \n                  IID      \n                  HC3      \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nLa interpretación de los coeficientes se vuelve más sencilla usando irr. Para la variable continua mentor, un artículo más publicado por el mentor está asociado con 1.026 veces más artículos publicados por el estudiante, es decir, un 2.6% más artículos. En cambio, la variable dicotómica para mujeres indica que las mujeres publican 0.8 veces el número de artículos que los hombres.\n[2 puntos] Considere ahora que las mujeres han tenido carreras profesionales más cortas que los hombres, es decir, han estado menos expuestas a la ocurrencia de los eventos publicar. Incorpore esto al análisis y reinterprete los resultados. Pista: explore la opción offeset en glm de R. La columna profage mide la duración efectiva de las carreras profesionales de cada individuo.\nEl razonamiento es que ahora queremos conocer cuál es la tasa de publicación, es decir, \\(art/profage\\). Pero como nuestro podemos Poisson solo puede manejar conteos, podemos modificar el modelo para pasar la edad de la carrera del lado derecho:\n\\[\\begin{aligned}ln(art/profage)&=x'\\beta \\\\ ln(art)&=x'\\beta+\\ln(profage) \\end{aligned}\\]\n\nmpoisson_duracion &lt;- glm(art ~\n                  factor(female) + factor(married) + kid5 + phd + mentor,\n                  offset = log(profage),\n                  family=\"poisson\",\n                  data=data.phd)\n\nsummary(mpoisson_duracion)$coef\n\n                         Estimate  Std. Error     z value      Pr(&gt;|z|)\n(Intercept)           -2.95404558 0.093812104 -31.4889600 1.230266e-217\nfactor(female)Female   0.45874678 0.054721432   8.3833109  5.145931e-17\nfactor(married)Single -0.15598278 0.061347334  -2.5426171  1.100257e-02\nkid5                  -0.18643454 0.040135522  -4.6451256  3.398696e-06\nphd                    0.01801602 0.026428953   0.6816773  4.954430e-01\nmentor                 0.02573493 0.002001731  12.8563329  7.924799e-38\n\n\nHasta ahora hemos asumido que cada individuo ha estado “en riesgo” de publicar por el mismo periodo de tiempo, lo cual puede ser no cierto si, por ejemplo, algunos estudiantes se graduaron antes, o si otros han tenido pausas en sus carreras. Al controlar por el hecho de que las mujeres han tenido carreras más cortas, la variable female deja de ser negativa y se convierte en positiva. Las mujeres publican más que los hombres al tomar en cuenta la duración de las carreras.\nComparando los tres modelos:\n\nmodelsummary(list(mpoisson, mpoisson, mpoisson_duracion),\n             vcov = list('classical', 'robust', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n \n\n  \n    \n    \n    tinytable_7in89qhwdzqgpbrgu8d0\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n                (2)\n                (3)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)          \n                  0.460*** \n                  0.460*** \n                  -2.954***\n                \n                \n                                       \n                  (0.093)  \n                  (0.151)  \n                  (0.155)  \n                \n                \n                  factor(female)Female \n                  -0.225***\n                  -0.225***\n                  0.459*** \n                \n                \n                                       \n                  (0.055)  \n                  (0.072)  \n                  (0.073)  \n                \n                \n                  factor(married)Single\n                  -0.155** \n                  -0.155*  \n                  -0.156*  \n                \n                \n                                       \n                  (0.061)  \n                  (0.083)  \n                  (0.083)  \n                \n                \n                  kid5                 \n                  -0.185***\n                  -0.185***\n                  -0.186***\n                \n                \n                                       \n                  (0.040)  \n                  (0.057)  \n                  (0.057)  \n                \n                \n                  phd                  \n                  0.013    \n                  0.013    \n                  0.018    \n                \n                \n                                       \n                  (0.026)  \n                  (0.044)  \n                  (0.045)  \n                \n                \n                  mentor               \n                  0.026*** \n                  0.026*** \n                  0.026*** \n                \n                \n                                       \n                  (0.002)  \n                  (0.004)  \n                  (0.005)  \n                \n                \n                  Num.Obs.             \n                  915      \n                  915      \n                  915      \n                \n                \n                  AIC                  \n                  3314.1   \n                  3314.1   \n                  3322.8   \n                \n                \n                  BIC                  \n                  3343.0   \n                  3343.0   \n                  3351.7   \n                \n                \n                  Log.Lik.             \n                  -1651.056\n                  -1651.056\n                  -1655.393\n                \n                \n                  F                    \n                  43.333   \n                  14.855   \n                  20.311   \n                \n                \n                  RMSE                 \n                  1.84     \n                  1.84     \n                  1.85     \n                \n                \n                  Std.Errors           \n                  IID      \n                  HC3      \n                  HC3      \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n[2 puntos] Implemente la prueba de dispersión de Cameron y Trivedi (1990) usando una regresión auxiliar y los coeficientes estimados en la parte a. ¿Qué concluye?\nSeguimos a CT, p671 y construimos:\n\\[\\frac{(y_i-\\hat{\\mu}_i)^2}{\\hat{\\mu}_i}=\\alpha\\frac{ g(\\hat{\\mu}_i)}{\\hat{\\mu}_i}+u_i\\] Creamos el lado izquierdo:\n\ndata.phd &lt;- data.phd %&gt;% \n  mutate(xb_hat = predict(mpoisson),\n         mu_hat = exp(xb_hat),\n         lado_izq = (art-mu_hat)^2/mu_hat)\n\nNoten que si especificamos \\(g(\\hat{\\mu}_i)=\\hat{\\mu}^2_i\\), el lado derecho simplemente es \\(\\alpha \\hat{\\mu}_i+u_i\\). Estimamos entonces la regresión, sin constante:\nCorremos la regresión:\n\nsummary(lm(lado_izq ~ -1 + mu_hat,\n    data = data.phd))\n\n\nCall:\nlm(formula = lado_izq ~ -1 + mu_hat, data = data.phd)\n\nResiduals:\n   Min     1Q Median     3Q    Max \n-5.570 -1.431 -0.798 -0.027 69.967 \n\nCoefficients:\n       Estimate Std. Error t value Pr(&gt;|t|)    \nmu_hat  1.02020    0.08866   11.51   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 4.881 on 914 degrees of freedom\nMultiple R-squared:  0.1265, Adjusted R-squared:  0.1256 \nF-statistic: 132.4 on 1 and 914 DF,  p-value: &lt; 2.2e-16\n\n\nEl coeficiente sobre \\(\\alpha\\) es estadísticamente significativo, sugiriendo una relación entre la media y la varianza.\n[5 puntos] Emplee ahora un modelo negativo binomial con sobredispersión cuadrática en la media para estimar la relación entre el número de artículos publicados y las variables explicativas antes enumeradas. Interprete el coeficiente asociado al número de hijos y a la variable dicotómica para estudiantes mujeres. ¿Qué puede decir sobre la significancia del \\(\\alpha\\) estimado?\n\nmnb2 &lt;- MASS::glm.nb(art ~\n                 factor(female) + factor(married) + kid5 + phd + mentor,\n                 data = data.phd)\nsummary(mnb2)\n\n\nCall:\nMASS::glm.nb(formula = art ~ factor(female) + factor(married) + \n    kid5 + phd + mentor, data = data.phd, init.theta = 2.264387695, \n    link = log)\n\nCoefficients:\n                       Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)            0.406633   0.125778   3.233 0.001225 ** \nfactor(female)Female  -0.216418   0.072636  -2.979 0.002887 ** \nfactor(married)Single -0.150489   0.082097  -1.833 0.066791 .  \nkid5                  -0.176415   0.052813  -3.340 0.000837 ***\nphd                    0.015271   0.035873   0.426 0.670326    \nmentor                 0.029082   0.003214   9.048  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(2.2644) family taken to be 1)\n\n    Null deviance: 1109.0  on 914  degrees of freedom\nResidual deviance: 1004.3  on 909  degrees of freedom\nAIC: 3135.9\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  2.264 \n          Std. Err.:  0.271 \n\n 2 x log-likelihood:  -3121.917 \n\n\nPonemos todo junto:\n\nmodelsummary(list(mpoisson, mpoisson, mpoisson_duracion, mnb2),\n             vcov = list('classical', 'robust', 'robust', 'robust'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n \n\n  \n    \n    \n    tinytable_nh2hlt04ma8cy8muhchn\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n                (2)\n                (3)\n                (4)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)          \n                  0.460*** \n                  0.460*** \n                  -2.954***\n                  0.407*** \n                \n                \n                                       \n                  (0.093)  \n                  (0.151)  \n                  (0.155)  \n                  (0.135)  \n                \n                \n                  factor(female)Female \n                  -0.225***\n                  -0.225***\n                  0.459*** \n                  -0.216***\n                \n                \n                                       \n                  (0.055)  \n                  (0.072)  \n                  (0.073)  \n                  (0.071)  \n                \n                \n                  factor(married)Single\n                  -0.155** \n                  -0.155*  \n                  -0.156*  \n                  -0.150*  \n                \n                \n                                       \n                  (0.061)  \n                  (0.083)  \n                  (0.083)  \n                  (0.081)  \n                \n                \n                  kid5                 \n                  -0.185***\n                  -0.185***\n                  -0.186***\n                  -0.176***\n                \n                \n                                       \n                  (0.040)  \n                  (0.057)  \n                  (0.057)  \n                  (0.053)  \n                \n                \n                  phd                  \n                  0.013    \n                  0.013    \n                  0.018    \n                  0.015    \n                \n                \n                                       \n                  (0.026)  \n                  (0.044)  \n                  (0.045)  \n                  (0.038)  \n                \n                \n                  mentor               \n                  0.026*** \n                  0.026*** \n                  0.026*** \n                  0.029*** \n                \n                \n                                       \n                  (0.002)  \n                  (0.004)  \n                  (0.005)  \n                  (0.003)  \n                \n                \n                  Num.Obs.             \n                  915      \n                  915      \n                  915      \n                  915      \n                \n                \n                  AIC                  \n                  3314.1   \n                  3314.1   \n                  3322.8   \n                  3135.9   \n                \n                \n                  BIC                  \n                  3343.0   \n                  3343.0   \n                  3351.7   \n                  3169.6   \n                \n                \n                  Log.Lik.             \n                  -1651.056\n                  -1651.056\n                  -1655.393\n                  -1560.958\n                \n                \n                  F                    \n                  43.333   \n                  14.855   \n                  20.311   \n                  20.935   \n                \n                \n                  RMSE                 \n                  1.84     \n                  1.84     \n                  1.85     \n                  1.86     \n                \n                \n                  Std.Errors           \n                  IID      \n                  HC3      \n                  HC3      \n                  HC3      \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\nA diferencia de otros paquetes, glm.nb reporta \\(\\theta=1/\\alpha\\):\n\n(alpha &lt;- 1/summary(mnb2)$theta)        \n\n[1] 0.4416205\n\n\nEste es el modelo NB2 visto en clase y la forma más usada para implementar un modelo negativo binomial. Se asume una sobredispersión cuadrática en la media, con la varianza parametrizada usando \\(\\alpha\\). La interpretación de los coeficientes se mantiene con respecto al modelo Poisson. Los coeficientes tienen magnitudes similares, pero se prefiere el modelo NB2 si el propósito es pronóstico pues toma en cuenta la sobredispersión y le da suficiente flexibilidad a la varianza para depender de manera cuadrática de la media.\nUn poco más cuidado hay que poner en \\(\\alpha\\). En este caso, \\(\\hat{\\alpha}=0.44\\). Pero noten que lo que se reporta es el error estándar de \\(\\theta\\). Como platicamos en clase, con un estadístico podemos hacer un test y obtener un valor \\(p\\), pero una función no lineal del mismo puede que no tenga el mismo valor \\(p\\). Esto ocurre aquí, deberíamos recurrir al método delta para calcular el error estándar de \\(\\alpha\\)."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-5",
    "href": "tareas/tarea-2-respuestas.html#pregunta-5",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "Retome los datos del archivo motral2012.csv usado en la Tarea 1. Estimará un modelo Tobit para explicar los factores que afectan la oferta laboral femenina. En este archivo de datos la variable hrsocup registra las horas trabajadas a la semana.\n\n[2 punto] ¿Qué proporción de la muestra femenina reporta horas trabajadas iguales a cero?\nSi hacemos una dummy de horas positivas, al sacarle la media obtenemos la proporción.\n\ndata.salarios&lt;-read_csv(\"../files/motral2012.csv\",\n                          locale = locale(encoding = \"latin1\")) \n\ndata.salarios &lt;- data.salarios %&gt;% \n  filter(sex==2) %&gt;% \n  mutate(zerohrs=ifelse(hrsocup==0,1,0))\n\nsummary(data.salarios$zerohrs)\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  0.0000  0.3528  1.0000  1.0000 \n\n\nEl 35% de las observaciones tienen cero horas trabajadas.\n[3 puntos] Se desea estimar el efecto de los años de educación (anios_esc) sobre la oferta laboral femenina controlando por el estado marital (casada), la edad (eda) y el número de hijos (n_hij) como una variable continua. En la base, e_con toma el valor de 5 para las personas casadas. Genere la variable dummy casada que tome el valor de 1 para las mujeres casadas y cero en otro caso. Estime un modelo de MCO para hrsocup mayor que cero, usando solo la población femenina. Reporte errores robustos. ¿Cuál es la interpretación sobre el coeficiente de los años de escolaridad?\nEl estimar por MCO, un año más de escolaridad se asocia con 0.17 horas trabajadas más a la semana. Sin embargo, este efecto no es estadísticamente significativo.\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(casada=ifelse(e_con==5,1,0))\n\nreg_mco &lt;- lm(hrsocup ~ anios_esc+casada+eda+n_hij,\n          data=filter(data.salarios,hrsocup&gt;0))\n\ncoeftest(reg_mco,\n         vcov = vcovHC(reg_mco, \"HC1\"))[1:4,]\n\n               Estimate Std. Error   t value     Pr(&gt;|t|)\n(Intercept) 36.70129720 1.99116828 18.432042 2.742336e-69\nanios_esc    0.17465627 0.10353350  1.686954 9.179628e-02\ncasada      -3.52571327 0.89724706 -3.929479 8.855253e-05\neda          0.06949593 0.04914655  1.414055 1.575295e-01\n\n\nCon modelsummary podemos hacer pedir la tabla de coeficientes. Podemos especificar qué tipo de errores robustos queremos en la opción vcov:\n\nmodelsummary(list(reg_mco, reg_mco),\n             vcov = list('classical', 'HC1'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n \n\n  \n    \n    \n    tinytable_fkg31zfvygblu6l68nv4\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n                (2)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)\n                  36.701***\n                  36.701***\n                \n                \n                             \n                  (1.959)  \n                  (1.991)  \n                \n                \n                  anios_esc  \n                  0.175*   \n                  0.175*   \n                \n                \n                             \n                  (0.104)  \n                  (0.104)  \n                \n                \n                  casada     \n                  -3.526***\n                  -3.526***\n                \n                \n                             \n                  (0.862)  \n                  (0.897)  \n                \n                \n                  eda        \n                  0.069    \n                  0.069    \n                \n                \n                             \n                  (0.047)  \n                  (0.049)  \n                \n                \n                  n_hij      \n                  -1.149***\n                  -1.149***\n                \n                \n                             \n                  (0.336)  \n                  (0.372)  \n                \n                \n                  Num.Obs.   \n                  1699     \n                  1699     \n                \n                \n                  R2         \n                  0.030    \n                  0.030    \n                \n                \n                  R2 Adj.    \n                  0.028    \n                  0.028    \n                \n                \n                  AIC        \n                  14234.8  \n                  14234.8  \n                \n                \n                  BIC        \n                  14267.4  \n                  14267.4  \n                \n                \n                  Log.Lik.   \n                  -7111.383\n                  -7111.383\n                \n                \n                  F          \n                  13.171   \n                  12.526   \n                \n                \n                  RMSE       \n                  15.91    \n                  15.91    \n                \n                \n                  Std.Errors \n                  IID      \n                  HC1      \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n[3 puntos] ¿Qué problema existe con el modelo planteado en el punto anterior en términos de la selección? ¿Considera que se trata de un caso de censura o de truncamiento?\nPodemos racionalizar las horas trabajadas en un modelo microeconómico de oferta laboral. Las horas trabajadas observadas son positivas cuando la solución óptima es una cantidad positiva de horas. Sin embargo, si la solución óptima implicara horas negativas, las horas observadas serían cero. En este caso tenemos datos censurados en cero. Si existe una relación positiva entre educación y horas trabajadas, al estimar un modelo por MCO usando solo los datos con horas positivas estamos sobreestimando la media condicional pues se habrán omitido del análisis aquellas mujeres cuya solución a su problema de optimización eran horas iguales a cero o negativas.\n[8 puntos] Estime un modelo Tobit de datos censurados. ¿Qué resuelve el modelo Tobit en este caso? Interprete nuevamente el coeficiente sobre los años de escolaridad.\nLa función tobit permite hacer esto muy fácilmente. Noten que left especifica dónde está la censura. La opción gaussian pone explícito uno de los supuestos críticos del modelo tobit visto en clase: errores normales. Además, se asume homocedasticidad.\n\nreg_tobit &lt;- tobit(hrsocup ~ anios_esc+casada+eda+n_hij,\n               left = 0,\n               right = Inf,\n               dist = \"gaussian\",\n               data = data.salarios)\n\nsummary(reg_tobit)\n\n\nCall:\ntobit(formula = hrsocup ~ anios_esc + casada + eda + n_hij, left = 0, \n    right = Inf, dist = \"gaussian\", data = data.salarios)\n\nObservations:\n         Total  Left-censored     Uncensored Right-censored \n          2625            926           1699              0 \n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)   0.88236    3.19905   0.276  0.78269    \nanios_esc     0.85530    0.17509   4.885 1.04e-06 ***\ncasada      -10.99515    1.43025  -7.688 1.50e-14 ***\neda           0.41621    0.07665   5.430 5.64e-08 ***\nn_hij        -1.73840    0.55887  -3.111  0.00187 ** \nLog(scale)    3.44512    0.01887 182.608  &lt; 2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nScale: 31.35 \n\nGaussian distribution\nNumber of Newton-Raphson Iterations: 3 \nLog-likelihood: -9086 on 6 Df\nWald-statistic: 127.9 on 4 Df, p-value: &lt; 2.22e-16 \n\n\nEl modelo tobit para datos censurados toma en cuenta que hay una masa de ceros en las horas trabajadas para individuos para los que disponemos de sus características en la base de datos. El modelo tobit ajusta la probabilidad de observar esta masa de ceros. El coeficiente estimado será ahora consistente si el modelo está bien especificado, es decir, si el proceso subyacente es lineal en los parámetros y con un error normal homoscedástico (los supuestos de tobit básico). En este caso, un año más de educación se asocia con 0.85 más horas semanales trabajadas, un efecto estadísticamente significativo. Usar MCO subestimaba el efecto de la escolaridad.\nmodelsummary acepta la salida de la función tobit:\n\nmodelsummary(list(reg_mco, reg_mco, reg_tobit),\n             vcov = list('classical', 'HC1', 'classical'),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n \n\n  \n    \n    \n    tinytable_debf4qfj2125rxkkyzt5\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n                (2)\n                (3)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)\n                  36.701***\n                  36.701***\n                  0.882     \n                \n                \n                             \n                  (1.959)  \n                  (1.991)  \n                  (3.199)   \n                \n                \n                  anios_esc  \n                  0.175*   \n                  0.175*   \n                  0.855***  \n                \n                \n                             \n                  (0.104)  \n                  (0.104)  \n                  (0.175)   \n                \n                \n                  casada     \n                  -3.526***\n                  -3.526***\n                  -10.995***\n                \n                \n                             \n                  (0.862)  \n                  (0.897)  \n                  (1.430)   \n                \n                \n                  eda        \n                  0.069    \n                  0.069    \n                  0.416***  \n                \n                \n                             \n                  (0.047)  \n                  (0.049)  \n                  (0.077)   \n                \n                \n                  n_hij      \n                  -1.149***\n                  -1.149***\n                  -1.738*** \n                \n                \n                             \n                  (0.336)  \n                  (0.372)  \n                  (0.559)   \n                \n                \n                  Num.Obs.   \n                  1699     \n                  1699     \n                  2625      \n                \n                \n                  R2         \n                  0.030    \n                  0.030    \n                            \n                \n                \n                  R2 Adj.    \n                  0.028    \n                  0.028    \n                            \n                \n                \n                  AIC        \n                  14234.8  \n                  14234.8  \n                  18184.9   \n                \n                \n                  BIC        \n                  14267.4  \n                  14267.4  \n                  18220.1   \n                \n                \n                  Log.Lik.   \n                  -7111.383\n                  -7111.383\n                            \n                \n                \n                  F          \n                  13.171   \n                  12.526   \n                            \n                \n                \n                  RMSE       \n                  15.91    \n                  15.91    \n                  23.02     \n                \n                \n                  Std.Errors \n                  IID      \n                  HC1      \n                  IID       \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n[4 puntos] ¿Cuál es el efecto marginal de un incremento de un año de educación en la oferta laboral? ¿Cómo cambia su respuesta si, en lugar de considerar la variable latente, considera la variable censurada?\nEl efecto marginal en la variable latente es directamente el coficiente estimado en la parte d., es decir 0.855.\nEl efecto marginal en la media censurada está dado por:\n\\[\\frac{\\partial E(y|x)}{\\partial x_j}=\\beta_j\\Phi(x_i'\\beta)\\]\nLo que hice aquí fue calcular este efecto marginal para cada individuo y luego obtener el promedio de los efectos marginales en aquellos individuos con horas positivas.\n\ndata.salarios &lt;- data.salarios %&gt;%\n  mutate(index1=predict(reg_tobit,.)) %&gt;% \n  mutate(phi=pnorm(index1/reg_tobit$scale)) %&gt;% \n  mutate(mfx_anis_esc=reg_tobit$coefficients[2]*phi,\n         mfx_eda=reg_tobit$coefficients[4]*phi,\n         mfx_n_hij=reg_tobit$coefficients[5]*phi)\n\ndata.salarios %&gt;%\n  filter(hrsocup&gt;0) %&gt;% \n  summarise(mfx_anis_esc=mean(mfx_anis_esc)) \n\n# A tibble: 1 × 1\n  mfx_anis_esc\n         &lt;dbl&gt;\n1        0.612"
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#pregunta-6",
    "href": "tareas/tarea-2-respuestas.html#pregunta-6",
    "title": "Respuestas a la tarea 2",
    "section": "",
    "text": "Usando los mismos datos del archivo motral2012.csv implementará un ejercicio en el mismo espíritu del famoso estudio de Mroz (1987)1 sobre la oferta laboral femenina. El propósito es estimar la relación entre el salario y el número de horas trabajadas, concentrándonos en la muestra de mujeres.\n\n[5 puntos] El primer problema al que nos enfrentamos es que el salario no se observa para las mujeres que no trabajan. Estime un modelo lineal para el log del salario por hora, ing_x_hrs, usando las variables anios_esc, eda, n_hij, el cuadrado de n_hij, busqueda y casada, usando la submuestra de mujeres con salario por hora positivo. Dichas variables representan los años de escolaridad, la edad, el número de hijos, el cuadrado del número de hijos, si la persona buscó trabajo recientemente y si la persona es casada, respectivamente. Use los coeficientes estimados para imputar el ingreso por hora, faltante para las mujeres que reportan 0 en las horas trabajadas.\nImputamos el salario faltante:\n\ndata.salarios&lt;-read_csv(\"../files/motral2012.csv\",\n                        locale = locale(encoding = \"latin1\")) %&gt;%\n  filter(sex==2) %&gt;% \n  mutate(casada=ifelse(e_con==5,1,0))\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(ly=ifelse(ing_x_hrs&gt;0,log(ing_x_hrs),NA)) \n\nreg_imput &lt;- lm(ly ~ anios_esc+casada+eda+n_hij+n_hij^2+busqueda,\n              data = data.salarios)\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(lyhat = predict(reg_imput, .)) %&gt;% \n  mutate(ly = ifelse(is.na(ly), lyhat, ly))\n\nAquí tomé en cuenta que hay personas con horas trabajadas positivas e ingreso cero. En ese caso puse un NA al log del salario. Luego, en la imputación, le asigné el valor ajustado a estas observaciones junto con todas las que tienen el log del salario faltante.\n[5 puntos] Use heckit de la librería sampleSelection para estimar por máxima verosimilitud un heckit para las horas trabajadas hrsocup. En la ecuación de selección (si la persona trabaja o no) incluya como variable explicativa el salario por hora (imputado para las mujeres que no trabajan), además de anios_esc, eda, n_hij, el cuadrado de n_hij, casada y busqueda (esta última es un indicador de si se buscó trabajo en la última semana). En la ecuación de horas, incluya los mismos regresores, excepto n_hij, su cuadrado y busqueda.\nLa función heckit permite estimar el modelo de Heckman por máxima verosimilitud de manera muy simple. Hay que especificar method=“ml” para que la estimación sea por máxima verosimilitud:\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(trabaja = ifelse(hrsocup&gt;0,1,0)) %&gt;% \n  mutate(trabaja = factor(trabaja,levels=c(0,1)))\n\nreg_heckit_mv &lt;- heckit(trabaja ~ anios_esc+casada+eda+ly+n_hij+n_hij^2+busqueda,\n                hrsocup ~ anios_esc+casada+eda+ly,\n                method=\"ml\",\n                data = data.salarios)\n\nsummary(reg_heckit_mv)\n\n--------------------------------------------\nTobit 2 model (sample selection model)\nMaximum Likelihood estimation\nNewton-Raphson maximisation, 3 iterations\nReturn code 8: successive function values within relative tolerance limit (reltol)\nLog-Likelihood: -7181.675 \n2625 observations (926 censored and 1699 observed)\n14 free parameters (df = 2611)\nProbit selection equation:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -2.583614   0.448320  -5.763 9.24e-09 ***\nanios_esc    0.005346   0.020341   0.263    0.793    \ncasada      -0.213125   0.145135  -1.468    0.142    \neda         -0.003391   0.008137  -0.417    0.677    \nly          -0.004236   0.133344  -0.032    0.975    \nn_hij        0.023985   0.058900   0.407    0.684    \nbusqueda     2.406669   0.104595  23.009  &lt; 2e-16 ***\nOutcome equation:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 55.62469    2.17656  25.556  &lt; 2e-16 ***\nanios_esc    1.04819    0.09995  10.487  &lt; 2e-16 ***\ncasada      -3.58856    0.77967  -4.603 4.37e-06 ***\neda          0.11614    0.03902   2.977  0.00294 ** \nly          -9.83418    0.60389 -16.285  &lt; 2e-16 ***\n   Error terms:\n      Estimate Std. Error t value Pr(&gt;|t|)    \nsigma  14.8579     0.2591  57.350   &lt;2e-16 ***\nrho    -0.1606     0.1964  -0.818    0.414    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n--------------------------------------------\n\n\nPodemos reportar con modelsummary, aunque realmente lo hace muy mal:\n\nmodelsummary(list(reg_heckit_mv),\n             stars = c('***' = 0.01, '**' = 0.05, '*' = 0.1))\n\n \n\n  \n    \n    \n    tinytable_f2bjcgh5lnpm3l91yxqa\n    \n    \n    \n    \n  \n\n  \n    \n      \n        \n\n              \n                 \n                (1)\n              \n        \n        * p &lt; 0.1, ** p &lt; 0.05, *** p &lt; 0.01\n        \n                \n                  (Intercept)\n                  -2.584***\n                \n                \n                             \n                  55.625***\n                \n                \n                             \n                  (0.448)  \n                \n                \n                             \n                  (2.177)  \n                \n                \n                  anios_esc  \n                  0.005    \n                \n                \n                             \n                  1.048*** \n                \n                \n                             \n                  (0.020)  \n                \n                \n                             \n                  (0.100)  \n                \n                \n                  casada     \n                  -0.213   \n                \n                \n                             \n                  -3.589***\n                \n                \n                             \n                  (0.145)  \n                \n                \n                             \n                  (0.780)  \n                \n                \n                  eda        \n                  -0.003   \n                \n                \n                             \n                  0.116*** \n                \n                \n                             \n                  (0.008)  \n                \n                \n                             \n                  (0.039)  \n                \n                \n                  ly         \n                  -0.004   \n                \n                \n                             \n                  -9.834***\n                \n                \n                             \n                  (0.133)  \n                \n                \n                             \n                  (0.604)  \n                \n                \n                  n_hij      \n                  0.024    \n                \n                \n                             \n                  (0.059)  \n                \n                \n                  busqueda   \n                  2.407*** \n                \n                \n                             \n                  (0.105)  \n                \n                \n                  sigma      \n                  14.858***\n                \n                \n                             \n                  (0.259)  \n                \n                \n                  rho        \n                  -0.161   \n                \n                \n                             \n                  (0.196)  \n                \n                \n                  Num.Obs.   \n                  2625     \n                \n                \n                  AIC        \n                  14391.4  \n                \n                \n                  BIC        \n                  14473.6  \n                \n                \n                  RMSE       \n                  14.84    \n                \n        \n      \n    \n\n    \n\n  \n\n\n\n\n[10 puntos] Estime ahora el heckit en dos pasos, a mano. Es decir, siga los siguientes pasos: i) estime un probit para la ecuación de selección y obtenga el índice \\(x_i'\\hat{\\beta}\\); ii) calcule el inverso de la razón de Mills \\(\\lambda_i(x_i'\\hat{\\beta})\\); y iii) estime por MCO la ecuación para las horas trabajadas con la submuestra que tiene horas trabajadas positivas, incluyendo como regresor el inverso de la razón de Mills estimado y el resto de los regresores. Compare los coeficientes y los errores estándar obtenidos en esta parte con los de la parte b. ¿Por qué son iguales o por qué difieren?\nEstimamos ahora el heckit a mano. Estimamos el probit y obtenemos el valor ajustado del IMR:\n\nreg_heckit_pe &lt;- glm(trabaja ~ anios_esc+casada+eda+ly+n_hij+n_hij^2+busqueda,\n                  family = binomial(link = \"probit\"),\n                  data = data.salarios)\n\ndata.salarios &lt;- data.salarios %&gt;% \n  mutate(index = predict(reg_heckit_pe, .)) %&gt;% \n  mutate(imr = dnorm(index)/pnorm(index))\n\n\nreg_heckit_se &lt;- lm(hrsocup ~ anios_esc+casada+eda+ly+imr,\n            data=filter(data.salarios,trabaja==1))\n\nsummary(reg_heckit_se)\n\n\nCall:\nlm(formula = hrsocup ~ anios_esc + casada + eda + ly + imr, data = filter(data.salarios, \n    trabaja == 1))\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-46.172 -10.085   1.915   9.253  57.689 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 55.68676    2.17948  25.550  &lt; 2e-16 ***\nanios_esc    1.04814    0.10000  10.481  &lt; 2e-16 ***\ncasada      -3.56927    0.78057  -4.573 5.17e-06 ***\neda          0.11621    0.03904   2.977  0.00296 ** \nly          -9.82971    0.60406 -16.273  &lt; 2e-16 ***\nimr         -3.94669    3.62684  -1.088  0.27667    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 14.86 on 1693 degrees of freedom\nMultiple R-squared:  0.1563, Adjusted R-squared:  0.1539 \nF-statistic: 62.75 on 5 and 1693 DF,  p-value: &lt; 2.2e-16\n\n\nComparamos coeficientes (aquí stargazer lo hace mejor):\nstargazer(reg_heckit_mv, reg_heckit_se,\n          type=\"html\", \n          df=FALSE,\n          digits=4)\n\n\n\n\n\n\n\n\n\nDependent variable:\n\n\n\n\n\n\n\n\n\n\n\n\nhrsocup\n\n\n\n\n\n\nHeckman\n\n\nOLS\n\n\n\n\n\n\nselection\n\n\n\n\n\n\n\n\n\n(1)\n\n\n(2)\n\n\n\n\n\n\n\n\nanios_esc\n\n\n1.0482***\n\n\n1.0481***\n\n\n\n\n\n\n(0.0999)\n\n\n(0.1000)\n\n\n\n\n\n\n\n\n\n\n\n\ncasada\n\n\n-3.5886***\n\n\n-3.5693***\n\n\n\n\n\n\n(0.7797)\n\n\n(0.7806)\n\n\n\n\n\n\n\n\n\n\n\n\neda\n\n\n0.1161***\n\n\n0.1162***\n\n\n\n\n\n\n(0.0390)\n\n\n(0.0390)\n\n\n\n\n\n\n\n\n\n\n\n\nly\n\n\n-9.8342***\n\n\n-9.8297***\n\n\n\n\n\n\n(0.6039)\n\n\n(0.6041)\n\n\n\n\n\n\n\n\n\n\n\n\nimr\n\n\n\n\n-3.9467\n\n\n\n\n\n\n\n\n(3.6268)\n\n\n\n\n\n\n\n\n\n\n\n\nConstant\n\n\n55.6247***\n\n\n55.6868***\n\n\n\n\n\n\n(2.1766)\n\n\n(2.1795)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nObservations\n\n\n2,625\n\n\n1,699\n\n\n\n\nR2\n\n\n0.1563\n\n\n\n\n\n\nAdjusted R2\n\n\n0.1539\n\n\n\n\n\n\nResidual Std. Error\n\n\n\n\n14.8614\n\n\n\n\nF Statistic\n\n\n\n\n62.7490***\n\n\n\n\n\n\n\n\nNote:\n\n\np&lt;0.1; p&lt;0.05; p&lt;0.01\n\n\n\nLa magnitud de los coeficientes es práctiamente la misma entre el modelo estimado por máxima verosimilitud y con un procedimiento en dos etapas a mano. En este ejemplo las diferencias son sutiles, aunque recordemos que en general la estimación por MV es más eficiente si la verosimilitud está bien planteada."
  },
  {
    "objectID": "tareas/tarea-2-respuestas.html#footnotes",
    "href": "tareas/tarea-2-respuestas.html#footnotes",
    "title": "Respuestas a la tarea 2",
    "section": "Notas",
    "text": "Notas\n\n\nMroz, T. A. (1987). The sensitivity of an empirical model of married women’s hours of work to economic and statistical assumptions. Econometrica: Journal of the econometric society, 765-799.↩︎"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#cuestiones-prácticas-de-vi-1",
    "href": "diapositivas/variables-instrumentales-practica.html#cuestiones-prácticas-de-vi-1",
    "title": "Variables instrumentales en R",
    "section": "Cuestiones prácticas de VI",
    "text": "Cuestiones prácticas de VI\n\nHemos aprendido que la forma general del estimador de MGMes:\n\n\\[\\hat{\\beta}_{GMM}=(X'ZW_NZ'X)^{-1}X'ZW_NZ'y\\]\n\nY vimos también la forma general del estimador de la varianza:\n\n\\[\\hat{V}(\\hat{\\beta}_{GMM})=N(X'ZW_NZ'X)^{-1}(X'ZW_N\\hat{S}W_NZ'X)(X'ZW_NZ'X)^{-1}\\]"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#estimador-óptimo-de-mgm",
    "href": "diapositivas/variables-instrumentales-practica.html#estimador-óptimo-de-mgm",
    "title": "Variables instrumentales en R",
    "section": "Estimador óptimo de MGM",
    "text": "Estimador óptimo de MGM\nPara obtener el estimador óptimo escogemos una forma particular para la matriz de pesos:\n\\[W=\\hat{S}^{-1}\\]\nY entonces el estimador de MGM se vuelve:\n\\[\\hat{\\beta}_{GMM,O}=(X'Z\\hat{S}^{-1}Z'X)^{-1}X'Z\\hat{S}^{-1}Z'y\\]\nY el estimador de varianza se simplifica a:\n\\[\\hat{V}(\\hat{\\beta}_{GMM,O})=N(X'Z\\hat{S}^{-1}Z'X)^{-1}\\]\nHasta aquí no asumimos nada sobre la forma de los errores\nLo único que nos permitió pasar de la forma general al estimador óptimo es la elección de \\(W\\)\nCon esto obtenemos el estimador más eficiente"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#álgebra-de-matrices",
    "href": "diapositivas/variables-instrumentales-practica.html#álgebra-de-matrices",
    "title": "Variables instrumentales en R",
    "section": "Álgebra de matrices",
    "text": "Álgebra de matrices\nUsaremos los datos del estudio de Card (1995) sobre rendimientos a la educación para mostrar cómo funcionan las expresiones para estimar el vector de coeficientes y los errores estándar de los distintos estimadores de VI.\nCard usa la proximidad a una institución de educación superior como instrumento de los años de educación acumulados.\n\ndata.ingresos &lt;- read_csv(\"ingresos_iv.csv\",\n                          locale = locale(encoding = \"latin1\"))"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado",
    "href": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado",
    "title": "Variables instrumentales en R",
    "section": "Modelo exactamente identificado",
    "text": "Modelo exactamente identificado\nPara tener una referencia, veamos lo que obtenemos con ivreg del paquete AER. Nuestro modelo tiene cinco regresores más una constante:\n\n\niv_ei &lt;- ivreg(lwage ~ educ + exper + expersq + black + south |\n                 . - educ + nearc4, data = data.ingresos)\n\nmodelsummary(list(iv_ei),\n          output=\"gt\",\n          coef_map = c(\"educ\", \"exper\"),\n          fmt = 4)\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\neduc\n0.2214\n\n\n\n(0.0409)\n\n\nexper\n0.1439\n\n\n\n(0.0187)\n\n\nNum.Obs.\n3010\n\n\nR2\n-0.134\n\n\nR2 Adj.\n-0.136\n\n\nAIC\n4043.8\n\n\nBIC\n4085.9\n\n\nRMSE\n0.47"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado-1",
    "href": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado-1",
    "title": "Variables instrumentales en R",
    "section": "Modelo exactamente identificado",
    "text": "Modelo exactamente identificado\nRepliquemos lo anterior con matrices. Primero construimos \\(X\\), \\(Y\\) y \\(Z\\):\n\ndata.ingresos &lt;- data.ingresos %&gt;% \n  mutate(constant=1)\n\nX &lt;- data.matrix(select(data.ingresos, constant, educ, exper, expersq, black,\n              south),\n       rownames.force = T)\n\nY &lt;- data.matrix(select(data.ingresos,lwage),\n       rownames.force = T)\n\nZ &lt;- data.matrix(select(data.ingresos, constant, nearc4, exper, expersq, black,\n              south),\n       rownames.force = T)\n\nN &lt;- nrow(X)\nk &lt;- ncol(X) # incluyendo la constante"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado-2",
    "href": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado-2",
    "title": "Variables instrumentales en R",
    "section": "Modelo exactamente identificado",
    "text": "Modelo exactamente identificado\nEstimamos beta\n\nb &lt;- solve(t(Z) %*% X) %*% t(Z) %*% Y\nb\n\n                lwage\nconstant  2.324805209\neduc      0.221390289\nexper     0.143933017\nexpersq  -0.002401759\nblack    -0.036938558\nsouth    -0.088888463"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado-3",
    "href": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado-3",
    "title": "Variables instrumentales en R",
    "section": "Modelo exactamente identificado",
    "text": "Modelo exactamente identificado\nLa matriz de varianzas, asumiendo homocedasticidad:\n\nu_hat &lt;- Y-X%*%b\nsigma2 &lt;- as.numeric((1/N)*t(u_hat)%*%u_hat)\n\nConstruimos la matriz de proyección\n\nP &lt;- Z%*%(solve(t(Z)%*%Z))%*%t(Z)\n\nLa matriz de varianzas que construye R por defecto multiplica por \\(N/N-k\\):\n\nV=sigma2*solve(t(X)%*%P%*%X)*(N/(N-k))\nsqrt(diag(V))\n\n    constant         educ        exper      expersq        black        south \n0.7071765685 0.0409013368 0.0186980191 0.0004020113 0.0458381726 0.0257238774"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado-4",
    "href": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado-4",
    "title": "Variables instrumentales en R",
    "section": "Modelo exactamente identificado",
    "text": "Modelo exactamente identificado\nComparamos el coeficiente y el de educación con lo obtenido con ivreg:\n\n\nmodelsummary(list(iv_ei),\n          output=\"gt\",\n          coef_map = c(\"educ\", \"exper\"),\n          gof_map = c(\"nobs\"),\n          fmt = 4)\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\neduc\n0.2214\n\n\n\n(0.0409)\n\n\nexper\n0.1439\n\n\n\n(0.0187)\n\n\nNum.Obs.\n3010"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado-5",
    "href": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado-5",
    "title": "Variables instrumentales en R",
    "section": "Modelo exactamente identificado",
    "text": "Modelo exactamente identificado\nSi permitimos una heterocedasticidad arbitraria:\n\n\nmodelsummary(list(\"Clásicos\"=iv_ei, \"HC0\"=iv_ei, \"HC3 (default)\"=iv_ei),\n          output=\"gt\",\n          coef_map = c(\"educ\", \"exper\"),\n          gof_map = c(\"nobs\"),\n          vcov = c(\"iid\",\"HC0\", \"robust\"),\n          fmt = 4)\n\n\n\n\n\n\n\n\n\nClásicos\nHC0\nHC3 (default)\n\n\n\n\neduc\n0.2214\n0.2214\n0.2214\n\n\n\n(0.0409)\n(0.0403)\n(0.0404)\n\n\nexper\n0.1439\n0.1439\n0.1439\n\n\n\n(0.0187)\n(0.0185)\n(0.0186)\n\n\nNum.Obs.\n3010\n3010\n3010"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#modelo-sobreidentificado",
    "href": "diapositivas/variables-instrumentales-practica.html#modelo-sobreidentificado",
    "title": "Variables instrumentales en R",
    "section": "Modelo sobreidentificado",
    "text": "Modelo sobreidentificado\nConsideremos ahora el modelo sobreidentificado con dos instrumentos:\n\n\niv_si &lt;- ivreg(lwage ~ educ + exper + expersq + black + south |\n                 . - educ + nearc4 + nearc2, data = data.ingresos)\n\nmodelsummary(list(\"Clásicos\"=iv_si),\n          output=\"gt\",\n          coef_map = c(\"educ\", \"exper\"),\n          gof_map = c(\"nobs\"),\n          fmt = 4)\n\n\n\n\n\n\n\n\n\nClásicos\n\n\n\n\neduc\n0.2403\n\n\n\n(0.0406)\n\n\nexper\n0.1517\n\n\n\n(0.0188)\n\n\nNum.Obs.\n3010"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#modelo-sobreidentificado-1",
    "href": "diapositivas/variables-instrumentales-practica.html#modelo-sobreidentificado-1",
    "title": "Variables instrumentales en R",
    "section": "Modelo sobreidentificado",
    "text": "Modelo sobreidentificado\nConstruyamos la nueva matriz de instrumentos y la nueva matriz de proyección para obtener el vector de coeficientes:\n\nZ &lt;- data.matrix(select(data.ingresos, constant, nearc4, nearc2, exper, expersq, black,\n                        south),\n                 rownames.force = T)\n\nP &lt;- Z%*%(solve(t(Z)%*%Z))%*%t(Z)\n\nb &lt;- solve(t(X)%*%P%*%X) %*% t(X)%*%P%*%Y\nb\n\n                lwage\nconstant  1.998075910\neduc      0.240315358\nexper     0.151707063\nexpersq  -0.002409864\nblack    -0.018284247\nsouth    -0.080744611"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#modelo-sobreidentificado-2",
    "href": "diapositivas/variables-instrumentales-practica.html#modelo-sobreidentificado-2",
    "title": "Variables instrumentales en R",
    "section": "Modelo sobreidentificado",
    "text": "Modelo sobreidentificado\nLa matriz de varianzas se estima igual que en el caso exactamente identificado:\n\nu_hat &lt;- Y-X%*%b\nsigma2 &lt;- as.numeric((1/N)*t(u_hat)%*%u_hat)\n\nNoten que R hace correción de muestras finitas:\n\nV=sigma2*solve(t(X)%*%P%*%X)*(N/(N-k))\nsqrt(diag(V))\n\n    constant         educ        exper      expersq        black        south \n0.7015640369 0.0405697227 0.0187547264 0.0004214487 0.0460663648 0.0262991839"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#modelo-sobreidentificado-3",
    "href": "diapositivas/variables-instrumentales-practica.html#modelo-sobreidentificado-3",
    "title": "Variables instrumentales en R",
    "section": "Modelo sobreidentificado",
    "text": "Modelo sobreidentificado\nComparamos:\n\n\nmodelsummary(list(\"Clásicos\"=iv_si),\n          output=\"gt\",\n          coef_map = c(\"educ\", \"exper\"),\n          gof_map = c(\"nobs\"),\n          fmt = 4)\n\n\n\n\n\n\n\n\n\nClásicos\n\n\n\n\neduc\n0.2403\n\n\n\n(0.0406)\n\n\nexper\n0.1517\n\n\n\n(0.0188)\n\n\nNum.Obs.\n3010"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#estimador-de-mgm-óptimo",
    "href": "diapositivas/variables-instrumentales-practica.html#estimador-de-mgm-óptimo",
    "title": "Variables instrumentales en R",
    "section": "Estimador de MGM óptimo",
    "text": "Estimador de MGM óptimo\nPara estimar por el MGM usaremos la librería gmm y la función del mismo nombre. La opción vcov indica que queremos una matriz robusta a heterocedasticidad y wmatrix especifica el estimador óptimo, es decir, donde \\(W=S^{-1}\\).\n\ngmm_opt &lt;- gmm(lwage ~ educ + exper + expersq + black + south,\n               ~ nearc4 + nearc2 + exper + expersq + black + south,\n               vcov = \"HAC\",\n               wmatrix = \"optimal\",\n               type = \"twoStep\",\n               data = data.ingresos)"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#estimador-de-mgm-óptimo-1",
    "href": "diapositivas/variables-instrumentales-practica.html#estimador-de-mgm-óptimo-1",
    "title": "Variables instrumentales en R",
    "section": "Estimador de MGM óptimo",
    "text": "Estimador de MGM óptimo\nRepliquemos esto con matrices. Obtenemos el vector de parámetros con alguna matriz subóptima, por ejemplo, la identidad:\n\nr &lt;- k -1 + 2 # 1 endógena y 2 instrumentos\nI &lt;- data.matrix(diag(r))\n\nb1 &lt;- solve(t(X)%*%Z%*%I%*%t(Z)%*%X)%*%t(X)%*%Z%*%I%*%t(Z)%*%Y\n\nUsemos este vector de parámetros para estimar \\(\\hat{S}\\):\n\nD &lt;- diag(as.vector((Y-X%*%b1)^2))\nS_hat &lt;- (1/N) * t(Z) %*% D %*% Z \n\nY volvamos a estimar el vector de parámetros, ahora usando \\(W=\\hat{S}^{-1}\\):\n\nbo &lt;- solve(t(X)%*%Z%*%solve(S_hat)%*%t(Z)%*%X)%*%\n  t(X)%*%Z%*%solve(S_hat)%*%t(Z)%*%Y\nbo\n\n                lwage\nconstant  2.022002957\neduc      0.238977697\nexper     0.150984069\nexpersq  -0.002402233\nblack    -0.021611174\nsouth    -0.081455256"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#iv-es-el-estimador-de-mgm-para-cualquier-w",
    "href": "diapositivas/variables-instrumentales-practica.html#iv-es-el-estimador-de-mgm-para-cualquier-w",
    "title": "Variables instrumentales en R",
    "section": "IV es el estimador de MGM para cualquier W",
    "text": "IV es el estimador de MGM para cualquier W\nUsemos gmm para estimar el modelo exactamente identificado, usando diferentes matrices \\(W\\):\n\n\ngmm_iv_opt &lt;- gmm(lwage ~ educ + exper + expersq + black + south,\n               ~ nearc4 + exper + expersq + black + south,\n               vcov = \"iid\",\n               wmatrix = \"optimal\",\n               type = \"twoStep\",\n               data = data.ingresos)\n\ngmm_iv_ident &lt;- gmm(lwage ~ educ + exper + expersq + black + south,\n                  ~ nearc4 + exper + expersq + black + south,\n                  vcov = \"iid\",\n                  wmatrix = \"ident\",\n                  type = \"twoStep\",\n                  data = data.ingresos)\n\n\nmodelsummary(list(\"Mátriz óptima\"=gmm_iv_opt,\"Identidad\"= gmm_iv_ident),\n          output=\"gt\",\n          coef_map = c(\"educ\", \"exper\"),\n          gof_map = c(\"nobs\"),\n          fmt = 4)\n\n\n\n\n\n\n\n\n\nMátriz óptima\nIdentidad\n\n\n\n\neduc\n0.2214\n0.2214\n\n\n\n(0.0409)\n(0.0409)\n\n\nexper\n0.1439\n0.1439\n\n\n\n(0.0187)\n(0.0187)\n\n\nNum.Obs.\n3010\n3010"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado-6",
    "href": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado-6",
    "title": "Variables instrumentales en R",
    "section": "Modelo exactamente identificado",
    "text": "Modelo exactamente identificado\nRepliquemos esto con matrices, obteniendo primero la matriz \\(D\\), que colecciona los errores ajustados, y luego la matriz \\(S\\):\n\nD &lt;- diag(as.vector((Y-X%*%b)^2))\nS_hat &lt;- (1/(N)) * t(Z) %*% D %*% Z \n\nNoten que HC0 no hace corrección por muestras pequeñas:\n\nVr= N*solve(t(X)%*%Z%*%solve(t(Z)%*%Z)%*%t(Z)%*%X)%*%(t(X)%*%Z%*%solve(t(Z)%*%Z)%*%S_hat%*%solve(t(Z)%*%Z)%*%t(Z)%*%X)%*%solve(t(X)%*%Z%*%solve(t(Z)%*%Z)%*%t(Z)%*%X)\nsqrt(diag(Vr))\n\n    constant         educ        exper      expersq        black        south \n0.6957801830 0.0403033738 0.0185093210 0.0004295362 0.0442735580 0.0253631935"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado-7",
    "href": "diapositivas/variables-instrumentales-practica.html#modelo-exactamente-identificado-7",
    "title": "Variables instrumentales en R",
    "section": "Modelo exactamente identificado",
    "text": "Modelo exactamente identificado\nComparamos:\n\n\nmodelsummary(list(\"Clásicos\"=iv_ei, \"HC0\"=iv_ei, \"HC3 (default)\"=iv_ei),\n          output=\"gt\",\n          coef_map = c(\"educ\", \"exper\"),\n          gof_map = c(\"nobs\"),\n          vcov = c(\"iid\",\"HC0\", \"robust\"),\n          fmt = 4)\n\n\n\n\n\n\n\n\n\nClásicos\nHC0\nHC3 (default)\n\n\n\n\neduc\n0.2214\n0.2214\n0.2214\n\n\n\n(0.0409)\n(0.0403)\n(0.0404)\n\n\nexper\n0.1439\n0.1439\n0.1439\n\n\n\n(0.0187)\n(0.0185)\n(0.0186)\n\n\nNum.Obs.\n3010\n3010\n3010"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#iv-es-el-estimador-de-mgm-para-cualquier-w-1",
    "href": "diapositivas/variables-instrumentales-practica.html#iv-es-el-estimador-de-mgm-para-cualquier-w-1",
    "title": "Variables instrumentales en R",
    "section": "IV es el estimador de MGM para cualquier W",
    "text": "IV es el estimador de MGM para cualquier W\nRegresamos a la matriz \\(Z\\) con un solo instrumento y estimamos el vector de parámetros:\n\nZ &lt;- data.matrix(select(data.ingresos, constant, nearc4, exper, expersq, black,\n                        south),\n                 rownames.force = T)\n\nEstimamos el vector de coeficientes:\n\nb &lt;- solve(t(Z) %*% X) %*% t(Z) %*% Y\nb\n\n                lwage\nconstant  2.324805209\neduc      0.221390289\nexper     0.143933017\nexpersq  -0.002401759\nblack    -0.036938558\nsouth    -0.088888463"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#iv-es-el-estimador-de-mgm-para-cualquier-w-2",
    "href": "diapositivas/variables-instrumentales-practica.html#iv-es-el-estimador-de-mgm-para-cualquier-w-2",
    "title": "Variables instrumentales en R",
    "section": "IV es el estimador de MGM para cualquier W",
    "text": "IV es el estimador de MGM para cualquier W\nEl estimador de VI es el estimador de GMM para cualquier matriz \\(W\\) cuando \\(r=q\\):\n\n\nmodelsummary(list(\"Mátriz óptima\"=gmm_iv_opt,\"Identidad\"= gmm_iv_ident),\n          output=\"gt\",\n          coef_map = c(\"educ\", \"exper\"),\n          gof_map = c(\"nobs\"),\n          fmt = 4)\n\n\n\n\n\n\n\n\n\nMátriz óptima\nIdentidad\n\n\n\n\neduc\n0.2214\n0.2214\n\n\n\n(0.0409)\n(0.0409)\n\n\nexper\n0.1439\n0.1439\n\n\n\n(0.0187)\n(0.0187)\n\n\nNum.Obs.\n3010\n3010"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#estimador-de-mgm-óptimo-2",
    "href": "diapositivas/variables-instrumentales-practica.html#estimador-de-mgm-óptimo-2",
    "title": "Variables instrumentales en R",
    "section": "Estimador de MGM óptimo",
    "text": "Estimador de MGM óptimo\nCon este vector de parámetros, obtenemos la matriz de varianzas:\n\nD &lt;- diag(as.vector((Y-X%*%bo)^2))\nS_tilde &lt;- (1/N) * t(Z) %*% D %*% Z \n\nVr &lt;- (N)*solve(t(X) %*% Z %*% solve(S_tilde) %*% t(Z) %*% X)\nsqrt(diag(Vr))\n\n    constant         educ        exper      expersq        black        south \n0.6925828141 0.0401027981 0.0186490442 0.0004500697 0.0448916940 0.0258844828"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#estimador-de-mgm-óptimo-3",
    "href": "diapositivas/variables-instrumentales-practica.html#estimador-de-mgm-óptimo-3",
    "title": "Variables instrumentales en R",
    "section": "Estimador de MGM óptimo",
    "text": "Estimador de MGM óptimo\nComparamos:\n\n\nmodelsummary(list(gmm_opt),\n          output=\"gt\",\n          coef_map = c(\"educ\", \"exper\"),\n          gof_map = c(\"nobs\"),\n          fmt = 4)\n\n\n\n\n\n\n\n\n\n(1)\n\n\n\n\neduc\n0.2391\n\n\n\n(0.0446)\n\n\nexper\n0.1506\n\n\n\n(0.0205)\n\n\nNum.Obs.\n3010"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#prueba-de-hausman",
    "href": "diapositivas/variables-instrumentales-practica.html#prueba-de-hausman",
    "title": "Variables instrumentales en R",
    "section": "Prueba de Hausman",
    "text": "Prueba de Hausman\n\nEn general, las pruebas que comparan dos estimadores distintos se conocen como pruebas de Hausman, Wu-Hausman o Durbin-Wu-Hausman\nConsideremos dos estimadores \\(\\tilde{\\theta}\\) y \\(\\hat{\\theta}\\) que tienen la misma probabilidad límite bajo la \\(H_0\\) pero que difieren bajo la \\(H_a\\)\n\n\\[\n\\begin{aligned}\nH_0:\\quad\\quad p\\lim(\\tilde{\\theta}-\\hat{\\theta})=0 \\\\\nH_a:\\quad\\quad p\\lim(\\tilde{\\theta}-\\hat{\\theta})\\neq 0 \\\\\n\\end{aligned}\n\\]\n\nConstruimos el estadístico de prueba \\(H\\):\n\n\\[H=(\\tilde{\\theta}-\\hat{\\theta})'(\\hat{V}(\\tilde{\\theta}-\\hat{\\theta}))^{-1}(\\tilde{\\theta}-\\hat{\\theta})\\stackrel{a}{\\sim}\\chi^2(q)\\]\n\nSe rechaza la \\(H_0\\) si \\(H&gt;\\chi^2_{\\alpha}(q)\\)\nLa implementación es un poco complicada dado que\n\n\\[\\hat{V}(\\tilde{\\theta}-\\hat{\\theta})=\\hat{V}(\\tilde{\\theta})-\\hat{V}(\\hat{\\theta})-2cov(\\tilde{\\theta},\\hat{\\theta})\\]"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#prueba-de-hausman-1",
    "href": "diapositivas/variables-instrumentales-practica.html#prueba-de-hausman-1",
    "title": "Variables instrumentales en R",
    "section": "Prueba de Hausman",
    "text": "Prueba de Hausman\n\nCon errores homocedásticos, el estimador de MCO es eficiente\nEn ese caso, se puede mostrar que\n\n\\[H_{h}=(\\tilde{\\theta}-\\hat{\\theta})'(\\hat{V}(\\tilde{\\theta})-\\hat{V}(\\hat{\\theta}))^{-1}(\\tilde{\\theta}-\\hat{\\theta})\\stackrel{a}{\\sim}\\chi^2(q)\\] que es fácil de calcular en el software\n\nSi no estamos dispuestos a asumir homocedasticidad, se requiere estimar \\(cov(\\tilde{\\theta},\\hat{\\theta})\\), que se implementa en R y otros paquetes\nLa prueba de Hausman puede usarse para comparar dos estimadores, uno más eficiente que otro\nLa estimación de la prueba robusta puede complicarse en algunas aplicaciones, aunque como prueba de endogeneidad casi todo está disponible como funciones en R y otros paquetes"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#prueba-de-sobreidentificación",
    "href": "diapositivas/variables-instrumentales-practica.html#prueba-de-sobreidentificación",
    "title": "Variables instrumentales en R",
    "section": "Prueba de sobreidentificación",
    "text": "Prueba de sobreidentificación\n\nTambién conocida como prueba de Hansen, quien propuso la forma general de la prueba, o prueba de Sargan, quien propuso la forma particular para el modelo lineal de VI\nEs una prueba sobre qué tan cerca está de cumplirse la hipótesis nula de que \\(E(h(w,\\theta_0))=0\\)\nHansen (1982) define el estadístico de prueba como\n\n\\[J=\\left(\\frac{1}{N}\\sum_i \\hat{h}_i\\right)'\\hat{S}^{-1}\\left(\\frac{1}{N}\\sum_i \\hat{h}_i\\right)\\stackrel{a}{\\sim}\\chi^2(r-q)\\]\n\nEl estadístico \\(J\\) es la función objetivo de MGM evaluada en \\(\\hat{\\theta}_{MGM}\\)\nSi el estadístico es grande en magnitud, rechazamos la hipótesis de que las condiciones de momentos poblacionales se cumplen y se concluye que el estimador de MGM es inconsistente"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#prueba-de-sobreidentificación-1",
    "href": "diapositivas/variables-instrumentales-practica.html#prueba-de-sobreidentificación-1",
    "title": "Variables instrumentales en R",
    "section": "Prueba de sobreidentificación",
    "text": "Prueba de sobreidentificación\n\nEn el caso de variables instrumentales, el estadístico tiene la forma específica:\n\n\\[J=\\hat{u}'Z\\hat{S}^{-1}Z'\\hat{u}\\] donde \\(\\hat{u}=y-X'\\hat{\\beta}_{MGM}\\)\n\nSi se rechaza \\(H_0\\), hay evidencia de que los instrumentos \\(z\\) son endógenos (aunque también podría ser que haya una mala especificación del modelo)\nRechazar la \\(H0\\) indica que debemos replantear el modelo, aunque no nos dice cómo"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#instrumentos-débiles-1",
    "href": "diapositivas/variables-instrumentales-practica.html#instrumentos-débiles-1",
    "title": "Variables instrumentales en R",
    "section": "Instrumentos débiles",
    "text": "Instrumentos débiles\n\nDiscusión intuitiva en Angrist & Pischke (MHE, 2009)\nEl estimador de MCO tiene las propiedades de ser consistente e insesgado\n\nEn una muestra de tamaño arbitrario, la distribución del coeficiente de MCO está centrada en el coeficiente de poblacional\n\nEn cambio, el estimador de MC2E, aunque consistente, es sesgado\n\nEn muestras grandes el estimador está cerca del coeficiente poblacional\n\nEsto tiene importantes consecuencias para la estimación y la inferencia"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#sesgo-del-estimador-de-mc2e",
    "href": "diapositivas/variables-instrumentales-practica.html#sesgo-del-estimador-de-mc2e",
    "title": "Variables instrumentales en R",
    "section": "Sesgo del estimador de MC2E",
    "text": "Sesgo del estimador de MC2E\n\nConsideremos el modelo simple con un solo regresor endógeno \\(y=\\beta x+ \\eta\\)\nSupongamos que tenemos una matriz de instrumentos \\(Z\\), por lo que la primera etapa es:\n\n\\[x=Z\\pi+\\xi\\]\n\nEl estimador de MCE es:\n\n\\[\\hat{\\beta}_{MC2E}=\\beta+(x'P_Z x)^{-1}x'P_Z\\eta\\]\n\nSustituyendo \\(x\\):\n\n\\[\\hat{\\beta}_{MC2E}-\\beta=(x'P_z x)^{-1}\\pi'Z'\\eta+(x'P_z x)^{-1}\\xi'P_z\\eta=sesgo_{Mc2E}\\]\n\nNo podemos calcular directamente el sesgo pues el operador esperanza es un operador lineal\nAngrist & Pischke (2009) aproximan el sesgo como.\n\n\\[E(\\hat{\\beta}_{MC2E}-\\beta)\\approx(E(x'P_z x))^{-1}E(\\pi'Z'\\eta)+(E(x'P_z x))^{-1}\\xi'P_z\\eta\\]"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#sesgo-del-estimador-de-mc2e-1",
    "href": "diapositivas/variables-instrumentales-practica.html#sesgo-del-estimador-de-mc2e-1",
    "title": "Variables instrumentales en R",
    "section": "Sesgo del estimador de MC2E",
    "text": "Sesgo del estimador de MC2E\n\nLa expresión del sesgo puede reescribirse como\n\n\\[E(\\hat{\\beta}_{MC2E}-\\beta)\\approx\\frac{\\sigma_{\\eta\\xi}}{\\sigma_{xi}^2}\\frac{1}{F+1}\\]\ndonde \\(\\frac{\\sigma_{\\eta \\xi}}{\\sigma_{xi}^2}\\) es el sesgo del estimador de MCO\n\nCuando \\(\\pi=0\\), el sesgo de MC2E es el mismo que el de MCO\nEs decir, cuando \\(F\\) es pequeña, el sesgo de MC2E se acerca al sesgo de MCO: el estimador de MC2E está sesgado hacia el de MCO cuando la primera etapa es débil\nStaiger & Stock (1997) mostraron con simulaciones que cuando \\(F&gt;10\\), el sesgo máximo en el estimador de MC2E es de 10%\nDe aquí viene la regla de dedo frecuentemente usada para juzgar instrumentos débiles"
  },
  {
    "objectID": "diapositivas/variables-instrumentales-practica.html#recomendaciones-prácticas",
    "href": "diapositivas/variables-instrumentales-practica.html#recomendaciones-prácticas",
    "title": "Variables instrumentales en R",
    "section": "Recomendaciones prácticas",
    "text": "Recomendaciones prácticas\n\nReportar la primera etapa y ver si los coeficientes tienen sentido económico\nReportar el estadístico \\(F\\) de la primera etapa para los instrumentos excluidos\nReportar los resultados usando un modelo exactamente identificado usando el mejor instrumento\nPoner atención a la forma reducida, recordando que la forma reducida es proporcional al efecto causal de interés\n\n\n“Si no puedes ver la relación causal de interés en la forma reducida es porque probablemente no haya nada ahí.”\n— Angrist & Krueger (2001)"
  },
  {
    "objectID": "diapositivas/index.html",
    "href": "diapositivas/index.html",
    "title": "Diapositivas",
    "section": "",
    "text": "Muestra seleccionada\nVariables instrumentales\nMétodo generalizado de momentos\nVariables instrumentales en la práctica",
    "crumbs": [
      "Diapositivas"
    ]
  }
]