---
title: "Método generalizado de momentos"
author: "Irvin Rojas"
format: 
  revealjs:
    slide-number: c/t
    width: 1600
    height: 900
---

```{r setup}
#| echo: false
#| warning: false 
#| message: false
knitr::opts_chunk$set(echo = FALSE,
                      warning = FALSE,
                      message = FALSE)
library(tidyverse)
library(knitr)
library(stargazer)
library(janitor)
library(sandwich)
library(nnet)
library(marginaleffects)
library(foreign)
library(AER)
library(sampleSelection)
library(modelsummary)

```
# Método generalizado de momentos

## Introducción

El GMM generaliza una serie de estimadores comúnmente usados en econometría (incluyendo MCO, MV, VI, etc)

Asumimos que existen $r$ condiciones de momentos independientes para $q$ parámetros $$E(h(w_i,\theta_0))=0$$

donde $\theta$ es un vector de $q\times 1$, $h(\cdot)$ es una función vector de $r \times 1$ con $r\geq q$

$w_i$ son los datos observables, incluyendo las variables dependientes, los regresores exógenos, potenciales regresores endógenos, así como instrumentos


## Método generalizado de momentos

La forma de $h(\cdot)$ es equivalente a escoger el modelo


Por ejemplo:

| $h(\cdot)$ | Método de estimación |
|:---:|:---:|
| $x(y-x'\beta)$ | MCO |
| $\partial\mathcal{L}/\partial\theta$ | MV |
| $z(y-x'\beta)$ | VI |



## Método de momentos

Cuando $r=q$, tenemos un modelo **exactamente identificado**, es decir, tenemos tantos momentos como parámetros a estimar

Podemos obtener el **estimador de método de momentos** $\hat{\theta}_{MM}$ como la solución a

$$\frac{1}{N}h(w_i,\hat{\theta})=0$$

## Método de momentos

Los momentos poblacionales dan lugar a momentos muestrales que pueden ser usados para estimar los parámetros

Ejemplo: estimación de la media poblacional con observaciones iid y media $\mu$

El momento poblacional es:

$$E(y-\mu)=0$$

Si sustituimos con el momento poblacional, es decir, sustituyendo la esperanza con el operador del promedio obtenemos el momento muestral correspondiente:

$$\frac{1}{N}\sum_{i=1}^N (y_i-\mu)=0$$

Al resolver para $\mu$ obtenemos $\mu_{MM}=\frac{1}{N}\sum_i y_i =\bar{y}$ 


El estimador de MM de a media poblacional es la media muestral

## Método generalizado de momentos

El caso que nos ocupa más en el contexto de MC2E es cuando $r>q$, es decir, un **modelo sobreidentificado**

En este caso, tenemos más ecuaciones que incógnitas en la condición de momentos

El **estimador de método generalizado de momentos** $\hat{\theta}_{GMM}$ se define como el vector de parámetros que minimiza la forma cuadrática

$$Q_N(\theta)=\left(\frac{1}{N}\sum_ih(w_i,\theta)\right)'W_N\left(\frac{1}{N}\sum_ih(w_i,\theta)\right)$$

donde $W_N$ es una matriz simétrica y positiva definida que no depende de $\theta$

Diferentes matrices $W_N$ dan origen a distintos estimadores


## Método generalizado de momentos

Las COP son:

$$\left(\frac{1}{N}\sum_{i=1}^N\frac{\partial h_i(\hat{\theta})'}{\partial\theta}\right)W_N\left(\frac{1}{N}\sum_{i=1}^Nh_i(\hat{\theta})\right)=\mathbf{0}$$
donde para acotar la notación $h_i(\theta)=h_i(w_i,\theta)$


Esto es un sistema de ecuaciones en general no lineal y complicado de resolver

Recurrimos a métodos numéricos para encontrar $\hat{\theta}_{MGM}$

Podemos establecer teoría asintótica para mostrar las propiedades asintóticas del estimador de MGM


## Estimador de MGM

**Proposición 6.1 en CT**: bajo una serie de supuestos para poder establecer LGN y TLC, $\hat{\theta}_{GMM}$, definido como una raíz de las condiciones de primer orden $\partial Q_N(\theta) / \partial \theta=0$, es tal que:

$$\sqrt{N}\left(\hat{\theta}_{GMM}-\theta_0\right)\stackrel{a}{\sim}\mathcal{N}\left(0,(G_0'W_0G_0)^{-1}(G_0'W_0S_0W_0G_0)(G_0'W_0G_0)^{-1}\right)$$

donde $W_0$ es una matriz finita, simétrica y positiva definida, y

$$
\begin{aligned}
G_0&=p\lim\frac{1}{N}\sum_{i=1}^N \left(\frac{\partial h_i}{\partial\theta'}\Bigg|_{\theta_0}\right) \\
S_0&=p\lim \frac{1}{N} \sum_{i=1}^N \sum_{j=1}^N \left(h_i h_j \Bigg|_{\theta_0} \right)
\end{aligned}
$$

La derivación es un poco más complicada que la usada para los estimadores extremos, pero pueden ver una propuesta en la sección 6.3.9 de CT


## Matriz de varianzas óptima

Para implementar MGM debemos especificar las condiciones de momentos y la matriz $W_N$

En el caso de modelos sobreidentificados y con $S_0$ conocida, el estimador de MGM más eficiente se obtiene al especificar $W_N=S_0^{-1}$

Con esta elección, la expresión para la varianza de $\hat{\beta}_{MGM}$ se simplifica a
 
$$\sqrt{N}\left(\hat{\theta}_{GMM}-\theta_0\right)\stackrel{a}{\sim}\mathcal{N}\left(0,(G_0'S_0^{-1}G_0)^{-1}\right)$$

En la práctica, $S_0$ es desconocida, así que la sustituimos por un estimador consistente $\hat{S}$

## Matriz de varianzas óptima

**Importante**: el que la elección de la matriz de varianzas óptima sea $W_N=S_0^{-1}$ no ocurre por que $(G_0'S_0^{-1}G_0)$ se escribe mucho más corto que $(G_0'W_0G_0)^{-1}(G_0'W_0S_0W_0G_0)(G_0'W_0G_0)$

Más bien, es óptima porque se puede mostrar que

$$(G_0'W_0G_0)^{-1}(G_0'W_0S_0W_0G_0)(G_0'W_0G_0)^{-1}\geq (G_0'S_0^{-1}G_0)^{-1}$$

para cualquier $W_0$ positiva definida


## MGM óptimo

En la práctica, no se conoce $S_0$ sino que se sustituye por un estimador consistente $\hat{S}$

La matriz de varianzas se estima siguiendo un procedimiento de dos etapas

1. Obtener el estimador de MGM usando una matriz subóptima, generalmente $W_N=I_r$ y con estos coeficientes obtener un estimador para $S_0$: $$\hat{S}=\frac{1}{N}\sum_i h_i(\hat{\theta})h_j(\hat{\theta})'$$
  
1. Obtener un estimador de MGM óptimo o **estimador de MGM de dos etapas óptimo** $\hat{\theta}_{MGM,O}$ minimizando
  
$$Q_N(\theta)=\left(\frac{1}{N}\sum_ih(\theta)\right)'\hat{S}^{-1}\left(\frac{1}{N}\sum_ih(\theta)\right)$$

## MGM óptimo

La distribución límite de $hat{\theta}_{MGM,O}$ es normal, centrada en $\theta_0$ 

Para estimar la varianza de $\hat{\theta}_{MGM,O}$ usamos

$$\hat{V}(\hat{\theta}_{MGM,O})=N^{-1}(\hat{G}\tilde{S}^{-1}\hat{G})^{-1}$$

donde $\hat{G}$ y $\tilde{S}$ se evalúan en $\hat{\theta}_{MGM,O}$


# MGM para variables instrumentales


## Estimador lineal de MGM

Consideremos el modelo lineal

$$y_i=x_i'\beta + u_i$$

Supongamos que algún componente de $x$ es endógeno, por lo que recurrimos a un instrumento que cumple con:

$$E(u_i|z_i)=0$$

La restricción de exclusión nos especifica una condición de momentos

$$E(z_i(y_i-x_i'\beta))=0$$

## Estimador lineal de MGM

El estimador MGM minimiza la forma cuadrática siguiente


$$
\begin{aligned}
Q(\beta)&=\left(\frac{1}{N}\sum_i (y_i-x_i'\beta)z_i\right)'W_N\left(\frac{1}{N}\sum_i (y_i-x_i'\beta)z_i\right) \\
&=\left(\frac{1}{N}(y-X\beta)'Z\right)W_N\left(\frac{1}{N}Z'(y-X\beta)\right)
\end{aligned}
$$

Las condiciones de primer orden son

$$\frac{\partial Q_N(\beta)}{\partial\beta}=-2\left(\frac{1}{N}X'Z\right)W_N\Big(\frac{1}{N}Z'(y-X\beta)\Big)=0$$

Resolviendo para $\beta$ obtenemos el **estimador lineal de VI de GMM**:

$$\hat{\beta}_{GMM}=(X'ZW_NZ'X)^{-1}X'ZW_NZ'y$$

Las propiedades asintóticas de este estimador se pueden obtener de manera similar a como se obtuvieron las del estimador de MCO o usando las propiedades más generales para problemas de MGM



## Estimador de la varianza de $\hat{\beta}_{MGM}$

Podemos hacer un procedimiento similar al que hacíamos con MCO

$$
\begin{aligned}
\hat{\beta}_{GMM}&=(X'ZW_NZ'X)^{-1}X'ZW_NZ'(X\beta+u) \\
&=\beta + (X'ZW_NZ'X)^{-1}X'ZW_NZ'u 
\end{aligned}
$$
Por lo tanto, reescalando:


$$
\begin{aligned}
\sqrt{N}(\hat{\beta}_{GMM}-\beta)&=\sqrt{N}(X'ZW_NZ'X)^{-1}X'ZW_NZ'u \\
\end{aligned}
$$
Si podemos aplicar un TLC a $\frac{1}{\sqrt{N}}Z'u$ entonces

$$\frac{1}{\sqrt{N}}Z'u\xrightarrow{d}\mathcal{N}(0,S)$$

con $S=\lim\frac{1}{N}\sum_iE(u_i^2z_iz_i')$




## Estimador de la varianza de $\hat{\beta}_{MGM}$

El estimador $\hat{\beta}_{MGM}$ es asintóticamente normal, centrado en $\beta$ y con una varianza asintótica estimada dada por

$$\hat{V}(\hat{\beta}_{GMM})=N(X'ZW_NZ'X)^{-1}(X'ZW_N\hat{S}W_NZ'X)(X'ZW_NZ'X)^{-1}$$

donde $\hat{S}$ es un estimador consistente de $S$

Dependiendo de si estamos en un modelo exactamente identificado o sobreidentificado y de cómo especificamos la matriz $W_N$, los resultados anteriores sobre $\hat{\beta}_{GMM}$ y $\hat{V}(\hat{\beta}_{GMM})$ se especializan


## Estimador de la varianza de $\hat{\beta}_{MGM}$

¿Cómo estimamos $\hat{S}$

En el caso general, con posible heterocedasticidad:

$$\hat{S}=\frac{1}{N}\sum_i\hat{u}_i^2z_iz_i = \frac{1}{N}Z'DZ$$
con 

$$
D=
\begin{pmatrix}
\hat{u}_1^2 & 0 & 0 &\ldots 0 \\
0 & \hat{u}_2^2 & 0 &\ldots 0 \\
\vdots \\
0 & 0 & 0 &\ldots \hat{u}_n^2 \\
\end{pmatrix}
$$
Con homocedasticidad, se simplifica a:

$$\hat{S}=\frac{1}{N}s^2Z'Z$$

# Caso sobreidentificado

## Estimador óptimo de MGM

Para obtener el **estimador óptimo** escogemos una forma particular para la matriz de pesos

$$W=\hat{S}^{-1}$$
Y entonces el estimador de MGM se vuelve

$$\hat{\beta}_{GMM,O}=(X'Z\hat{S}^{-1}Z'X)^{-1}X'Z\hat{S}^{-1}Z'y$$
Si permitimos heterocedasticidad arbitraria, obtenemos $\hat{\beta}$ en una primera etapa con una matriz subóptima para calcular $\hat{S}$

Luego obtenemos $\hat{\beta}_{GMM,O}$ usando $\hat{S}^{-1}$ como matriz de pesos


#Matriz de varianzas

Y el estimador de varianza se simplifica a

$$
\begin{aligned}
\hat{V}(\hat{\beta}_{GMM,O})&=N(X'Z\hat{S}^{-1}Z'X)^{-1}X'Z\hat{S}^{-1}\hat{S}\hat{S}^{-1}Z'X(X'Z\hat{S}^{-1}Z'X)^{-1} \\
&=N(X'Z\hat{S}^{-1}Z'X)^{-1}
\end{aligned}
$$

Para estimar $\hat{S}$ usamos los residuales dados por $\hat{u}_i=y_i-X\hat{\beta}_{GMM,O}$

## Mínimos cuadrados en dos etapas

Si estamos dispuestos a asumir errores homocedásticos

$$\hat{S}^{-1}=\left(\frac{1}{N}s^2Z'Z\right)^{-1}$$

Y entonces hacemos

$$W=\left(\frac{1}{N}Z'Z\right)^{-1}$$

Con esta simplificación, el estimador de MGM es

$$
\begin{aligned}
\hat{\beta}_{MC2E}&=(X'Z(Z'Z)^{-1}Z'X)^{-1}X'ZZ(Z'Z)^{-1}Z'y \\
&=(X'P_ZX)^{-1}X'P_Zy
\end{aligned}
$$

Este es el **estimador de MC2E**, también llamado **estimador de variables instrumentales generalizado**

## Mínimos cuadrados en dos etapas

A $P_Z=Z(Z'Z)^{-1}Z'$ se le conoce como matriz de proyección

Y la matriz de varianzas se simplifica a

$$\hat{V}(\hat{\beta}_{MC2E})=s^2\left(X'P_z X\right)^{-1}$$

Este estimador también se conoce como **estimador de variables instrumentales generalizado** porque generaliza el estimador de VI al caso sobreidentificado

Tambien se conoce como **estimador de MGM de una etapa** por obvias razones


# Caso exactamente identificado


## Estimador de variables instrumentales

En el caso cuando $r=q$, es decir, tantos instrumentos como variables endógenas, $X'Z$ es una matriz cuadrada que puede ser invertida, resultando que

$$(X'ZW_NZ'X)^{-1}=(Z'X)^{-1}W_N^{-1}(X'Z)^{-1}$$


Sustituyendo esto en la forma general del estimador de MGM obtenemos:

$$
\begin{aligned}
\hat{\beta}_{VI}&=(X'ZW_NZ'X)^{-1}X'ZW_NZ'y \\
&=(Z'X)^{-1}W_N^{-1}(X'Z)^{-1} X'ZW_NZ'y\\
&=(Z'X)^{-1}Z'y \\
\end{aligned}
$$

Este es el estimador de **variables instrumentales**

En otras palabras, el estimador de MGM es igual al de VI para cualquier matriz $W_N$


## Modelo exactamente identificado

Con posible heterocedasticidad, tenemos una matriz de varianzas de la forma

$$\begin{align}\hat{V}(\hat{\beta}_{VI})&=N(Z'X)^{-1}\hat{S}(X'Z)^{-1}\end{align}$$

con $\hat{S}=Z'DZ/N$, y donde $D=diag[\hat{u}_i^2]$
 

Y con homocedasticidad, la matriz de varianzas de nuevo es:

$$\hat{V}(\hat{\beta}_{VI})=s ^2\left(X'P_z X\right)^{-1}$$


## Recapitulando

Siguiendo las convenciones de Camerony Trivedi (2005)

El **estimador de MGM** es el estimador para el caso general de método de momentos, cuales quiera que sean las formas de los momentos especificados

El **estimador óptimo de MGM** ocurre cuando asumimos una forma particular para la matriz de pesos, $W=\hat{S}^{-1}$

El **estimador óptimo de MGM** se emplea en el caso más general de modelos de variables instrumentales sobreidentificados con heterocedasticidad

El **estimador de variables instrumentales generalizado** se obtiene cuando asumimos homocedasticidad en el modelo sobreidentificado y lleva el *apellido* generalizado porque es la generalización del estimador IV para el caso sobreidentificado

El **estimador de variables instrumentales** surge en el modelo exactamente identificado